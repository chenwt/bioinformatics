<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 2?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id><journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id><journal-title-group><journal-title>BMC Bioinformatics</journal-title></journal-title-group><issn pub-type="epub">1471-2105</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">4539887</article-id><article-id pub-id-type="pmid">26283178</article-id><article-id pub-id-type="publisher-id">680</article-id><article-id pub-id-type="doi">10.1186/s12859-015-0680-3</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>MVDA: a multi-view genomic data integration methodology</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Serra</surname><given-names>Angela</given-names></name><address><email>aserra@unisa.it</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Fratello</surname><given-names>Michele</given-names></name><address><email>michele.fratello@unina2.it</email></address><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Fortino</surname><given-names>Vittorio</given-names></name><address><email>vittorio.fortino@ttl.fi</email></address><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Raiconi</surname><given-names>Giancarlo</given-names></name><address><email>gianni@unisa.it</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Tagliaferri</surname><given-names>Roberto</given-names></name><address><email>rtagliaferri@unisa.it</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Greco</surname><given-names>Dario</given-names></name><address><email>dario.greco@ttl.fi</email></address><xref ref-type="aff" rid="Aff3">3</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1937 0335</institution-id><institution-id institution-id-type="GRID">grid.11780.3f</institution-id><institution>NeuRoNe Lab, Department of Computer Science, </institution><institution>University of Salerno, </institution></institution-wrap>Fisciano, Italy </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2200 8888</institution-id><institution-id institution-id-type="GRID">grid.9841.4</institution-id><institution>Department of Medical, Surgical, Neurological, Metabolic and Ageing Sciences, </institution><institution>Second University of Napoli, </institution></institution-wrap>Napoli, Italy </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 0410 5926</institution-id><institution-id institution-id-type="GRID">grid.6975.d</institution-id><institution>Unit of Systems Toxicology and Nanosafety Research Centre, </institution><institution>Finnish Institute of Occupational Health, FIOH, </institution></institution-wrap>Helsinki, Finland </aff></contrib-group><pub-date pub-type="epub"><day>19</day><month>8</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>16</volume><elocation-id>261</elocation-id><history><date date-type="received"><day>2</day><month>2</month><year>2015</year></date><date date-type="accepted"><day>20</day><month>7</month><year>2015</year></date></history><permissions><copyright-statement>&#x000a9; Serra et al. 2015</copyright-statement><license license-type="OpenAccess"><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p>Multiple high-throughput molecular profiling by omics technologies can be collected for the same individuals. Combining these data, rather than exploiting them separately, can significantly increase the power of clinically relevant patients subclassifications.</p></sec><sec><title>Results</title><p>We propose a multi-view approach in which the information from different data layers (views) is integrated at the levels of the results of each single view clustering iterations. It works by factorizing the membership matrices in a late integration manner. We evaluated the effectiveness and the performance of our method on six multi-view cancer datasets. In all the cases, we found patient sub-classes with statistical significance, identifying novel sub-groups previously not emphasized in literature. Our method performed better as compared to other multi-view clustering algorithms and, unlike other existing methods, it is able to quantify the contribution of single views on the final results.</p></sec><sec><title>Conclusion</title><p>Our observations suggest that integration of prior information with genomic features in the subtyping analysis is an effective strategy in identifying disease subgroups. The methodology is implemented in R and the source code is available online at <ext-link ext-link-type="uri" xlink:href="http://neuronelab.unisa.it/a-multi-view-genomic-data-integration-methodology/">http://neuronelab.unisa.it/a-multi-view-genomic-data-integration-methodology/</ext-link>.</p></sec><sec><title>Electronic supplementary material</title><p>The online version of this article (doi:10.1186/s12859-015-0680-3) contains supplementary material, which is available to authorized users.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Clustering</kwd><kwd>Multi-view</kwd><kwd>Subclasses</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2015</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background</title><p>Stratifying patients into distinct subgroups can lead to more accurate diagnostic and treatment strategies. Current methods for patient stratification are usually based on gene expression data and apply cluster algorithms to identify groups of patients having similar expression profiles [<xref ref-type="bibr" rid="CR1">1</xref>&#x02013;<xref ref-type="bibr" rid="CR3">3</xref>]. For example, multivariate gene expression signatures have been shown to discriminate between disease subtypes, such as recurrent and non-recurrent cancer types or tumour progression stages [<xref ref-type="bibr" rid="CR4">4</xref>]. In addition to gene expression data other omics data types, such as miRNA (microRNA) expression, methylation or copy number alterations, can be used to improve the model accuracy for patient stratification. For example, somatic copy number alterations provide good biomarkers for cancer subtype classification [<xref ref-type="bibr" rid="CR5">5</xref>]. Data integration approaches to efficiently identify subtypes among existing samples has recently gained attention. The main idea is to identify groups of samples that share relevant molecular characteristics. Strategies of data integration of multiple omics data types poses several computational challenges, as they deal with data having generally a small number of samples and different pre-processing strategies for each data source. Moreover, they have to cope with redundant data as well as the retrieval of the most relevant information contained in the different data sources.</p><p>Methods for clustering multiple data layers can be grouped into three main categories, namely early, intermediate, and late integration. Early integration methods directly combine all features into a single dataset [<xref ref-type="bibr" rid="CR6">6</xref>&#x02013;<xref ref-type="bibr" rid="CR8">8</xref>]; intermediate integration methods build joint representations of data given the views [<xref ref-type="bibr" rid="CR9">9</xref>]; late integration methods preprocess separately each individual view, subsequently combining the results [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR11">11</xref>]. Late integration methods are often preferred when combining continuous and discrete data together, such as CNV and mRNA. Omics data are highly dimensional data and subject to non-Gaussian noise. Therefore, integrating them with an early or intermediate integration techniques may lead to highly noisy patterns unless appropriate regularization techniques are used which, however, lead to a very complex multi-view learning process.</p><p>A number of data integration approaches for patients subgroups discovery were recently proposed, based on supervised classification, unsupervised clustering or biclustering. These methodologies are called multi-view learning [<xref ref-type="bibr" rid="CR12">12</xref>]. Examples of supervised approaches are [<xref ref-type="bibr" rid="CR13">13</xref>, <xref ref-type="bibr" rid="CR14">14</xref>]. Multi-view biclustering has been used in a cocaine user subtyping [<xref ref-type="bibr" rid="CR15">15</xref>]. Finally multi-view clustering methodologies have been intensively used also if in few cases on omics data. Multi-view clustering applied to biological data includes iCluster [<xref ref-type="bibr" rid="CR16">16</xref>] and SNF [<xref ref-type="bibr" rid="CR9">9</xref>]. iCluster uses a joint latent-variable model to identify the grouping structure in multi omics data. On the other hand, SNF uses a network-based approach to combine different omics data (e.g., mRNA expression, DNA methylation and microRNA expression data) to identify relevant patient subtypes. However, the contribution of the individual data sources to the classification output is not quantified in any of these multi-view clustering methods.</p><p>In this study, we propose a new computational framework for multi-view clustering that aims to combine dimensional reduction, variable selection, clustering (for each available data type) and data integration methods to find patient subtypes, as described in Fig. <xref rid="Fig1" ref-type="fig">1</xref>.
<fig id="Fig1"><label>Fig. 1</label><caption><p>The proposed approach: The computational approach is composed of four steps. First, the data is pre-processed. In each view feature with low variance are filtered out. Furthermore, the features are clustered in order to reduce the input dimension. From each cluster prototype are extracted. These prototypes are the only features used in following steps (<bold>a</bold>). Second, the prototypes are ranked by the patient class separability and the most significant ones are selected (<bold>b</bold>). Third, the patients are clustered and the membership matrices are obtained (<bold>c</bold>). Fourth, a late integration approach is utilized to integrate clustering results (<bold>d</bold>).</p></caption><graphic xlink:href="12859_2015_680_Fig1_HTML" id="MO1"/></fig>
</p><p>First, the cluster-based correlation analysis is used to reduce the number of features for each data type (genes, miRNAs, protein, etc.). Second, a ranked-based method is employed to select the features based on their ability to separate patient subtypes. Third, clustering is used to identify patient subtypes independently from each reduced dataset. Fourth, integrative clustering methods are exploited to find more robust patient subtypes and assess the contributions of different data types used for the identification of all the patient subtypes. Detailed information on each step can be found in Additional files <xref rid="MOESM1" ref-type="media">1</xref> and <xref rid="MOESM2" ref-type="media">2</xref>. We tested our method on large genomic data sets including different omics data types, such as the Cancer Genome Atlas (TCGA) data sets (<ext-link ext-link-type="uri" xlink:href="http://cancergenome.nih.gov/">http://cancergenome.nih.gov/</ext-link>). Our comparison experiments suggest that our method outperforms other existing integration methods, such as Tw-Kmeans [<xref ref-type="bibr" rid="CR7">7</xref>] and SNF [<xref ref-type="bibr" rid="CR9">9</xref>].</p></sec><sec id="Sec2"><title>Results and Discussion</title><p>We developed a novel methodology for cluster analysis of multiple genomic data types.</p><p>We compared it with recently developed methods: the integrative clustering algorithm, namely SNF [<xref ref-type="bibr" rid="CR9">9</xref>]. and the Tw-Kmeans [<xref ref-type="bibr" rid="CR7">7</xref>], an early integration multi-view clustering model. Using TCGA datasets from 4 different tumor types (Table <xref rid="Tab1" ref-type="table">1</xref>), we evaluated the cluster impurity error, the Normalized Mutual Information [<xref ref-type="bibr" rid="CR17">17</xref>] and the cluster stability of all the considered algorithms.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Datasets: Description of the datasets used in this study</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">Response</th><th align="left">N(0)</th><th align="left">N(1)</th><th align="left">N(2)</th><th align="left">N(3)</th><th align="left">Gene</th><th align="left">RNASeq</th><th align="left">microRNA</th><th align="left">miRNASeq</th><th align="left">Protein</th><th align="left">Copy</th><th align="left">Clinical</th></tr><tr><th align="left"/><th align="left"/><th align="left"/><th align="left"/><th align="left"/><th align="left"/><th align="left">expression</th><th align="left"/><th align="left">expression</th><th align="left"/><th align="left">expression</th><th align="left">number</th><th align="left">data</th></tr></thead><tbody><tr><td align="left" colspan="2">Breast Cancer from The Cancer genome Atlas, N = 151</td><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td align="left">TCGA.BRC</td><td align="left">Pam50 (Her2,Basal,LumA,LumB)</td><td align="center">24</td><td align="center">13</td><td align="center">55</td><td align="center">59</td><td align="center"/><td align="center">x</td><td align="center"/><td align="center">x</td><td align="center"/><td align="center"/><td align="center"/></tr><tr><td align="left" colspan="2">Breast Cancer from The Gene Expression Omnibus, N = 201</td><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td align="left">OXF.BRC.1</td><td align="left">Pam50 (Her2,Basal,LumA,LumB)</td><td align="center">26</td><td align="center">6</td><td align="center">117</td><td align="center">52</td><td align="center">x</td><td align="center"/><td align="center">x</td><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td align="left">OXF.BRC.2</td><td align="left">Clinical (Level1, Level2, Level3, Level4)</td><td align="center">73</td><td align="center">54</td><td align="center">42</td><td align="center">32</td><td align="center">x</td><td align="center"/><td align="center">x</td><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td align="left" colspan="2">Prostate Cancer from Memorial Sloan-Kettering Cancer Center, N = 88</td><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td align="left">MSKCC.PRCA</td><td align="left">Tumor stages T1 vs. T2, T3, T4</td><td align="center">53</td><td align="center">35</td><td align="center"/><td align="center"/><td align="center">x</td><td align="center"/><td align="center">x</td><td align="center"/><td align="center"/><td align="center">x</td><td align="center">x</td></tr><tr><td align="left" colspan="2">Ovarian Cancer from The Cancer Genome Atlas, N = 398</td><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td align="left">TCGA.OVG</td><td align="left">Tumor stage I,II, Tumor stage III, Tumor stage IV</td><td align="center">33</td><td align="center">315</td><td align="center">50</td><td align="center"/><td align="center">x</td><td align="center"/><td align="center">x</td><td align="center"/><td align="center">x</td><td align="center"/><td align="center"/></tr><tr><td align="left" colspan="2">Glioblastoma Multiforme from The Cancer genome Atlas, N = 167</td><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr><tr><td align="left">from TCGA.GBM</td><td align="left">(Classical, Mesechymal, Neural, Proneural)</td><td align="center">37</td><td align="center">54</td><td align="center">24</td><td align="center">52</td><td align="center">x</td><td align="center"/><td align="center">x</td><td align="center"/><td align="center"/><td align="center"/><td align="center"/></tr></tbody></table><table-wrap-foot><p>&#x0201c;N&#x0201d; is the number of subjects for each dataset. Ni is the number of samples in the i-th class. An x denotes if that view (column) is available for a specific dataset (row)</p></table-wrap-foot></table-wrap>
</p><p>The evaluation metrics computed for each dataset are summarized in Table <xref rid="Tab3" ref-type="table">3</xref>. Our unsupervised method shows a mean error of 27,47 %, normalized mutual information (NMI) of 28 % and stability of 85 %. Moreover, the error can significantly decrease when using prior information. Indeed, our method with prior information reduces the error to 6,30 %. The other methods used in the comparison study show a higher mean error from the lowest 30,83 % of SNF to the highest 30,93 % of Kmeans. They also show a lower NMI (the maximum value reached is 26 % of Ward&#x02019;s method) and variable stability from the lowest 51 % of the Kmeans to the highest 96 % of the partitioning around medoids (pamk).
</p><p>The class label and the p-value for each cluster obtained after the integrative step is reported in Fig. <xref rid="Fig2" ref-type="fig">2</xref>, where the label indicates the subclass to which patients in the cluster belong, while the p-value measures the statistical significance of a cluster. In the case of the dataset OXF.BRC.1, the patients are divided into four classes: LumA, LumB, Her2 and Basal. We observed eight relevant clusters, four of which are subclasses of class LumA (cluster 4 - pvalue 2.50 &#x000d7;10<sup>&#x02212;4</sup>; cluster 5 - pvalue 8.71 &#x000d7;10<sup>&#x02212;8</sup>; cluster 6 - pvalue 2:92 &#x000d7;10<sup>&#x02212;3</sup>; cluster 11 - pvalue 1.97 &#x000d7;10<sup>&#x02212;3</sup>) and two are subclasses of class LumB (cluster 2 - pvalue 3:93 &#x000d7;10<sup>&#x02212;14</sup>; cluster 10 - pvalue 5:14 &#x000d7;10<sup>&#x02212;3</sup>). We also report the influence of each data on the final cluster. While it is obvious that the clusters are obtained considering all the genomic data views, the information needed to identify a specific subclass can be more relevant in a particular data type instead over the others. For example, the clusters 3, 6 and 11 of the OXF.BRC.1 dataset are both labeled as LumA. miRNA expression contributes for the 100 % to define the cluster 11, the gene expression is mainly determining the cluster 3 (57 %), while for cluster 6 they are equally important. This could mean, for example, that patients in cluster 11 are particularly characterized by miRNA expression while patients in cluster 3 by gene expression.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Multi-View Clusters Statistics: For each cluster class label, the p-value and the view contribution are reported. For all the six datasets, the results showed that the matrix factorization method gives lower classification error and better accuracy than the approach with general linear integration</p></caption><graphic xlink:href="12859_2015_680_Fig2_HTML" id="MO2"/></fig>
</p><p>As shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>, the integrative clustering performed generally better that the clustering on each single data view. In the TCGA.BRCA dataset, the mean cluster impurity is about 26 % when patients are grouped by the gene expression and 43 % when they are grouped by their miRNA expression profiles. However, combining the gene and the miRNA expression profiles, 26,50 % of error in unsupervised mode and 9 % in semi-supervised mode are obtained, respectively. Only in a few cases, the patient grouping based on a single data view performs better than the one obtained with multiple data types.
<fig id="Fig3"><label>Fig. 3</label><caption><p>Cluster Impurity difference between single view and integration analysis: Cluster impurity was evaluated as the fraction of objects that were inconsistent with the label of the cluster. It was calculated using each data type alone and by integrating them. Errors decreased with the integration approach in particular when the semi-supervised methodologies were used</p></caption><graphic xlink:href="12859_2015_680_Fig3_HTML" id="MO3"/></fig>
</p><p>Figure <xref rid="Fig4" ref-type="fig">4</xref> depicts the comparison between the two integration methods, either with or without prior information. The matrix factorization based method reaches the higher stability (about 85 %) in all the cases. With respect to the cluster impurity, the difference is almost always negligible. The greatest difference occurs when passing from the unsupervised to the semi-supervised approach. The cluster impurity for the unsupervised clustering is about 30 % and about 7 % for semi-supervised. Therefore, for more accurate sub-typing of classes semi-supervised integration was used, which maintains high stability and reduces the classification error compared to the classes. However, in case of unbalanced patient classes, the prior information is needed to increase the prediction.
<fig id="Fig4"><label>Fig. 4</label><caption><p>Difference between alternative integration methods: The mean cluster stability is reported, as calculated on four covariates represented by the type of experiment executed. Clustering stability was calculated by comparing the unsupervised and the semi-supervised mode, both using either all the features or only the selected prototypes</p></caption><graphic xlink:href="12859_2015_680_Fig4_HTML" id="MO4"/></fig>
</p><p>Since we tested different algorithms at each step of our methodology, we aimed at understanding if a common pipeline for all the datasets could be applied. After the execution of all the analyses, we observed that the best algorithms for the first and second steps strongly depend on the data. We found that K-means is the best algorithm for step 3 for the TCGA.BRACA, OXF.BRCA.1 and OXF.BRCA.2 datasets (Table <xref rid="Tab2" ref-type="table">2</xref>). At the last step, the matrix factorization approach provided lower errors and greater stability as compared with the general linear integration methods on the majority of the datasets. This result corroborates our hypothesis that a late integration approach is better for it allows using the best algorithms for each data type.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Best combination of methods for each step: Summary of the best combination of algorithms for each view used to obtain the best grouping of patients that identifies significant sub-classes</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left"/><th align="left">(a)</th><th align="left">(b)</th><th align="left">(c)</th><th align="left">(d)</th></tr><tr><th align="left">Dataset</th><th align="left">Views</th><th align="left">Feature</th><th align="left">Feature</th><th align="left">Patients</th><th align="left">Late</th></tr><tr><th align="left"/><th align="left"/><th align="left">clustering</th><th align="left">selection</th><th align="left">clustering</th><th align="left">integration</th></tr></thead><tbody><tr><td align="left">TCGA.BRCA</td><td align="left">RNASeq</td><td align="left">Pam</td><td align="left">CAT-score</td><td align="left">Kmeans</td><td align="left">MF</td></tr><tr><td align="left"/><td align="left">miRNASeq</td><td align="left">Pam</td><td align="left">CAT-score</td><td align="left">Pam</td><td align="left"/></tr><tr><td align="left">TCGA.OV</td><td align="left">Gene Expression</td><td align="left">Pam</td><td align="left">Random Forest</td><td align="left">DM</td><td align="left">MF</td></tr><tr><td align="left"/><td align="left">Protein Expression</td><td align="left">Pam</td><td align="left">-</td><td align="left">DM</td><td align="left"/></tr><tr><td align="left"/><td align="left">miRNA Expression</td><td align="left">Pam</td><td align="left">-</td><td align="left">DM</td><td align="left"/></tr><tr><td align="left">TCGA.GBM</td><td align="left">Gene Expressions</td><td align="left">Spectral</td><td align="left">CAT-score</td><td align="left">Kmeans</td><td align="left">MF</td></tr><tr><td align="left"/><td align="left">miRNA Expression</td><td align="left">Ward</td><td align="left">-</td><td align="left">Kmeans</td><td align="left"/></tr><tr><td align="left">OXF.BRCA.1</td><td align="left">Gene Expressions</td><td align="left">Pam</td><td align="left">Random Forest</td><td align="left">Ward</td><td align="left">GLI</td></tr><tr><td align="left"/><td align="left">miRNA Expression</td><td align="left">Pam</td><td align="left">Random Forest</td><td align="left">Kmeans</td><td align="left"/></tr><tr><td align="left">OXF.BRCA.2</td><td align="left">Gene Expressions</td><td align="left">Pvcluster</td><td align="left">CAT-score</td><td align="left">Kmeans</td><td align="left">MF</td></tr><tr><td align="left"/><td align="left">miRNA Expressions</td><td align="left">Pam</td><td align="left">Random Forest</td><td align="left">Kmeans</td><td align="left"/></tr><tr><td align="left">MSKCC</td><td align="left">Gene Expressions</td><td align="left">Pam</td><td align="left">CAT-score</td><td align="left">Kmeans</td><td align="left">MF</td></tr><tr><td align="left"/><td align="left">miRNA Expressions</td><td align="left">Pam</td><td align="left">-</td><td align="left">Pam</td><td align="left"/></tr><tr><td align="left"/><td align="left">CNV</td><td align="left">Spectral</td><td align="left">CAT-score</td><td align="left">Kmeans</td><td align="left"/></tr><tr><td align="left"/><td align="left">Clinical</td><td align="left">-</td><td align="left">-</td><td align="left">Pam</td><td align="left"/></tr></tbody></table><table-wrap-foot><p>In the feature selection column the symbol (-) means that feature selection was not executed because the number of features was small. Symbol (DM) in Patient clustering column means that same classification error was obtained with all the algorithms used</p></table-wrap-foot></table-wrap>
</p><p>In order to evaluate the performance of the proposed method, we systematically compared it with Tw-Kmeans and SNF algorithms (Table <xref rid="Tab3" ref-type="table">3</xref>). Anyhow, we did not compare our method with iClust, as it has been show to have worse performance than SNF, with which we deal in this study [<xref ref-type="bibr" rid="CR9">9</xref>]. We confirmed that late integration works more efficiently in integrating different views of genomic data. This is due to the large complexity and difference between the views. When views have different numerical and statistical characterizations, it is more convenient to individually analyze single data types and then combine the results in a multi-view analysis. This becomes more and more important as the number of views involved in the analysis increases.</p><table-wrap id="Tab3"><label>Table 3</label><caption><p>Validation Results: The mean classification error, normalized mutual information (NMI) and stability, on all datasets, are shown, measuring the agreement between the clusters resulting from an approach and the real patient classification</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Feature</th><th align="left">Integration</th><th align="left">Algorithm</th><th align="left">Error</th><th align="left">NMI</th><th align="left">Stability</th></tr></thead><tbody><tr><td align="left">Single View</td><td align="left">All Feature</td><td align="left">-</td><td align="left">Ward</td><td align="left">30,08 %</td><td align="left">26 %</td><td align="left">86 %</td></tr><tr><td align="left"/><td align="left"/><td align="left">-</td><td align="left">Kmeans</td><td align="left">30,93 %</td><td align="left">25 %</td><td align="left">51 %</td></tr><tr><td align="left"/><td align="left"/><td align="left">-</td><td align="left">Pamk</td><td align="left">30,75 %</td><td align="left">24 %</td><td align="left">94 %</td></tr><tr><td align="left"/><td align="left">Selected Prototype</td><td align="left">-</td><td align="left">Ward</td><td align="left">30,72 %</td><td align="left">26 %</td><td align="left">89 %</td></tr><tr><td align="left"/><td align="left"/><td align="left">-</td><td align="left">Kmeans</td><td align="left">30,36 %</td><td align="left">25 %</td><td align="left">52 %</td></tr><tr><td align="left"/><td align="left"/><td align="left">-</td><td align="left">Pamk</td><td align="left">30,78 %</td><td align="left">24 %</td><td align="left">96 %</td></tr><tr><td align="left">Multi-View</td><td align="left">All Feature</td><td align="left">Early Integration</td><td align="left">Tw-kmeans</td><td align="left">37,10 %</td><td align="left">24 %</td><td align="left">69 %</td></tr><tr><td align="left"/><td align="left">All Feature</td><td align="left">Intermediate Integration</td><td align="left">SNF</td><td align="left">30,83 %</td><td align="left">22 %</td><td align="left">83 %</td></tr><tr><td align="left"/><td align="left">All Feature in Cluster of Selected Prototype</td><td align="left">Intermediate Integration</td><td align="left">SNF</td><td align="left">31,31 %</td><td align="left">18 %</td><td align="left">82 %</td></tr><tr><td align="left"/><td align="left">Selected Prototype</td><td align="left">Late Integration unsupervised</td><td align="left">MF/GLI</td><td align="left">
<bold>27,47 %</bold>
</td><td align="left">
<bold>28 %</bold>
</td><td align="left">
<bold>85 %</bold>
</td></tr><tr><td align="left"/><td align="left">Selected Prototype</td><td align="left">Late Integration semi-supervised</td><td align="left">MF/GLI</td><td align="left">
<bold>6,30 %</bold>
</td><td align="left">
<bold>63 %</bold>
</td><td align="left">
<bold>84 %</bold>
</td></tr></tbody></table><table-wrap-foot><p>Bold font in percentage indicates best performance in the experiments</p></table-wrap-foot></table-wrap></sec><sec id="Sec3"><title>Evaluation of genes in breast cancer datasets</title><p>We selected a robust set of features from each analyzed dataset in order to find common features (Fig. <xref rid="Fig5" ref-type="fig">5</xref>
<xref rid="Fig5" ref-type="fig">a</xref>) and highlight shared patterns by enrichment analysis (Fig. <xref rid="Fig5" ref-type="fig">5</xref>
<xref rid="Fig5" ref-type="fig">b</xref>). Each list of features was obtained by using the Borda-count rule across the leave-one-out replicates. The enrichment analysis was performed by using the DAVID functional annotation tool [<xref ref-type="bibr" rid="CR18">18</xref>, <xref ref-type="bibr" rid="CR19">19</xref>] and graphically displayed with the R package BACA [<xref ref-type="bibr" rid="CR20">20</xref>]. Figure <xref rid="Fig5" ref-type="fig">5</xref>
<xref rid="Fig5" ref-type="fig">b</xref> reports a chart indicating unique and common Gene Ontology (GO) terms found by using DAVID on the different lists. It is possible observe that the three lists of features highlight similar GO annotations, involved for instance in regulation of kinase activity and regulation of cellcycle. The list of genes shared between the three breast cancer datasets can be found in Additional file <xref rid="MOESM3" ref-type="media">3</xref>.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Breast Cancer Gene Analysis: (<bold>a</bold>) the Venn diagram shows the number of common relevant genes between the three datasets. The analysis highlights 45 common genes between the three lists. (<bold>b</bold>) The bubble plot displays the enriched GO terms found by using DAVID. A transparent bubble indicates a set of significant genes, a dark bubble indicates a set of highly significant genes. The diameter of the bubble indicates the number of genes related to the same GO term</p></caption><graphic xlink:href="12859_2015_680_Fig5_HTML" id="MO5"/></fig>
</p></sec><sec id="Sec4" sec-type="conclusion"><title>Conclusions</title><p>In this study, we proposed a methodology for multiple genomic data type analysis aiming at patients subtyping. The methodology is composed of four steps using state of the art algorithms. Furthermore we systematically searched for the best algorithm for each step on six of benchmark datasets. We performed experiments in a late integration fashion, with two different algorithms. Since we were interested in high accuracy in class patient subtyping, we used prior information as a new view in the integration process. We found that the integrative clustering outperforms the single view approaches on all the datasets. We also showed that our method is stable by executing clustering on perturbed datasets removing one patient at a time and evaluating the normalized mutual information between all the resulting clusterings.</p></sec><sec id="Sec5"><title>Methods</title><p>The proposed methodology for the analysis of multi-view biological datasets takes in input <italic>n</italic> matrices <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$M_{i} \in R^{F_{i} \times P}\; for \;i=1, \ldots, n \phantom {\dot {i}\!}$\end{document}</tex-math><mml:math id="M2"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:msup><mml:mspace width="2.77626pt"/><mml:mtext mathvariant="italic">for</mml:mtext><mml:mspace width="2.77626pt"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="12859_2015_680_IEq1.gif"/></alternatives></inline-formula>, where <italic>F</italic>
<sub><italic>i</italic></sub> is the number of features (genes, miRNAs, CNV, methylation, clinical information, etc.) and <italic>P</italic> is the number of patients and a vector <italic>cl</italic> of classes labels, and yields a multi-view partitioning <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$G = \bigcup _{i=1}^{k}(G_{i})$\end{document}</tex-math><mml:math id="M4"><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mrow><mml:mo>&#x022c3;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munderover><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><inline-graphic xlink:href="12859_2015_680_IEq2.gif"/></alternatives></inline-formula> of patients. The multi-view integration methods also return a matrix <italic>C</italic> where <italic>c</italic>[ <italic>i</italic>,<italic>j</italic>] is the contribution of view <italic>i</italic> to the final multi-view cluster <italic>j</italic>.</p><p>The approach consists of four main steps as shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>:
<list list-type="order"><list-item><p>Prototype Extraction: for each view, the features were filtered by variance and clustered in order to find prototypes, reducing the input data dimension.</p></list-item><list-item><p>Prototype ranking: the prototypes found in the step 1 were ranked based on their ability to separate the classes.</p></list-item><list-item><p>Single view clustering: in each view, the samples were clustered using the prototypes created in the steps 1 and 2 as features</p></list-item><list-item><p>Integration: single view clustering results were integrated with a late integration approach, in order to obtain the k final multi-view meta-clusters</p></list-item></list>
</p><p>The late integration methodology can be considered as a further step of the proposed data mining pipeline, in which the clustering results of each single view are unified. This approach offers a number of significant advantages: (i) clustering algorithms can be optimally chosen with respect to each single view; (ii) it can be naturally parallelized; (iii) representation issues are avoided since clustering results are the inputs to the integration algorithms.</p><sec id="Sec6"><title>Prototype extraction</title><p>The features with low variance across the samples were eliminated. Therefore the data were clustered with respect to the patients and the cluster centroids were selected as the prototype patterns. The centroid of each cluster was selected as the most correlated element with respect to the other elements in that cluster. Different clustering algorithms were used: Pvclust [<xref ref-type="bibr" rid="CR21">21</xref>], SOM [<xref ref-type="bibr" rid="CR22">22</xref>], hierarchical clustering with Ward&#x02019;s method [<xref ref-type="bibr" rid="CR23">23</xref>], K-means [<xref ref-type="bibr" rid="CR24">24</xref>], Partitional Around Medoids [<xref ref-type="bibr" rid="CR25">25</xref>] and Spectral clustering [<xref ref-type="bibr" rid="CR26">26</xref>].</p><p>The idea is to evaluate several popular clustering techniques and compare their behaviour on the different views with respect to the hierarchical method that is the standard algorithm used to cluster genes. As noted in [<xref ref-type="bibr" rid="CR27">27</xref>], cluster analysis is a complex and interactive process and results change based on its parameters. Therefore, each algorithm was executed for different values of K. For each algorithm and for each K, clustering performance was evaluated according to the following evaluation function:
<disp-formula id="Equ1"><label>(1)</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{@{}rcl@{}}  VAL = \frac{1}{4}\left(\frac{IC+1}{2} + 1-\frac{EC+1}{2} + (1-S) + CG\right) \end{array} $$ \end{document}</tex-math><mml:math id="M6"><mml:mtable class="eqnarray" columnalign="left center right"><mml:mtr><mml:mtd class="eqnarray-1"><mml:mspace width="-10.0pt"/><mml:mtext mathvariant="italic">VAL</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:mfrac><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mfrac><mml:mrow><mml:mtext mathvariant="italic">IC</mml:mtext><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:mtext mathvariant="italic">EC</mml:mtext><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mtext mathvariant="italic">CG</mml:mtext></mml:mrow></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2015_680_Equ1.gif" position="anchor"/></alternatives></disp-formula>
</p><p>where <italic>IC</italic> is the complete diameter measure, representing the average sample correlation of the less similar objects in the same cluster; <italic>EC</italic> is the complete linkage measure, representing the average sample correlation of the less similar objects for each pair of clusters; <italic>S</italic> is the singleton factor and <italic>CG</italic> is the compression gain. The evaluation function was defined in order to obtain the output value normalized between 0 and 1. The complete diameter and the complete linkage measures were calculated with the R &#x0201c;clv&#x0201d; package [<xref ref-type="bibr" rid="CR28">28</xref>]. The number of singleton was normalized in a range (0,1) in order to be comparable with the correlation measure. It was defined as <italic>S</italic>=<italic>N</italic>/(<italic>K</italic>&#x02212;1). The compression gain was defined as <italic>C</italic>
<italic>G</italic>=1&#x02212;(<italic>K</italic>/<italic>N</italic>
<sub><italic>elem</italic></sub>), where <italic>K</italic> is the number of clusters and <italic>N</italic> is the number of elements to be clustered.</p><p>Each clustering algorithm was executed on n different values of K and the corresponding results were evaluated with the function VAL. Values close to 1 indicate a clustering with similar objects in the clusters, weakly linked clusters, with few singletons and with a good compression rate. A numeric score was then assigned to each K value by considering the average values of the VAL function compiled over the clustering results obtained with the different algorithms. Then, the K showing the highest score was chosen and subsequently used to identify the best clustering algorithms having the first two highest scores with respect to the selected k value. In Algorithm 1 is reported the computational procedure followed to fine-tuned the k-values for the cluster analysis.</p><p>
<graphic xlink:href="12859_2015_680_Figa_HTML.gif" id="MO6"/>
</p></sec><sec id="Sec7"><title>Feature ranking</title><p>If the number of prototypes, after the fist step, was still high, further dimensional reduction by feature selection was done. Feature ranking was performed by computing the CAT-score [<xref ref-type="bibr" rid="CR29">29</xref>] and the Mean Decreasing Accuracy index calculated by Random Forests [<xref ref-type="bibr" rid="CR30">30</xref>]. The parameters of RF-based classifiers were fine-tuned by using the R package rminer [<xref ref-type="bibr" rid="CR31">31</xref>]. It provides a function that first tunes the hyper parameter(s) of a selected model by using bootstrap methods and subsequently builds the corresponding supervised data-mining model. For each rank, the cumulative sum of the ranking score was computed and four different cuts based on the cumulative values were taken. Cuts took into account all the features needed to maintain 60 %, 70 %, 80 % and 90 % of the cumulative value. An example is shown in section Prototype Extraction of Additional file <xref rid="MOESM1" ref-type="media">1</xref>. These different groups of features were used to cluster patients in each single view, with the same single view clustering algorithms used in the previous step. The number of clusters <italic>K</italic> was considered as the number of classes. For each clustering, the error was calculated as the dispersion obtained in the confusion matrix between class labels and clustering assignments. The clustering algorithm that reached the minimum error for each view was then selected. These clustering results were used as the input to the late integration step.</p></sec><sec id="Sec8"><title>Integration</title><p>Two late integration methods were used: the matrix factorization approach [<xref ref-type="bibr" rid="CR11">11</xref>] and a general model for multi-view integration [<xref ref-type="bibr" rid="CR10">10</xref>]. The first method [<xref ref-type="bibr" rid="CR11">11</xref>] combines information by factorizing the membership matrix of patient single-view clusterings. The method starts by transposing all the membership matrices and stacking them vertically obtaining the matrix of cluster <italic>X</italic>&#x02208;<italic>R</italic>
<sup><italic>l</italic><italic>X</italic><italic>n</italic></sup> where <italic>l</italic> is the total number of cluster in <italic>C</italic>. The objective is to find the best approximation of <italic>X</italic> such that
<disp-formula id="Equ2"><label>(2)</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ X = PH \; and \; P &#x0003e;= 0, H &#x0003e;= 0  $$ \end{document}</tex-math><mml:math id="M8"><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">PH</mml:mtext><mml:mspace width="2.77626pt"/><mml:mtext mathvariant="italic">and</mml:mtext><mml:mspace width="2.77626pt"/><mml:mi>P</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>H</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math><graphic xlink:href="12859_2015_680_Equ2.gif" position="anchor"/></alternatives></disp-formula>
</p><p>The results of the factorization are two matrices: <italic>P</italic>&#x02208;<italic>R</italic>
<sup><italic>l</italic><italic>X</italic><italic>k</italic></sup> that projects the clusters in a new set of <italic>k</italic> meta-clusters and <italic>H</italic>&#x02208;<italic>R</italic>
<sup><italic>k</italic><italic>X</italic><italic>n</italic></sup> whose columns can be viewed as the membership of the original objects in the new set of meta-clusters. Based on the values in the projection matrix <italic>P</italic>, we can calculate a matrix <italic>T</italic>&#x02208;<italic>R</italic>
<sup><italic>v</italic><italic>X</italic><italic>k</italic></sup>. <italic>T</italic>
<sub><italic>hf</italic></sub> indicates the contribution of the view <italic>V</italic>
<sub><italic>h</italic></sub> to the f-th meta-cluster. Based on values in <italic>P</italic> it is also possible to find the optimal value of <italic>k</italic> for the number of multi-view clusters we want in output. The matrix factorization was run with a range of values for <italic>k</italic> as input and the algorithm returns the factorization for the best value of <italic>k</italic>.</p><p>The second method exploits the intuition that the optimal clustering is the consensus clustering shared by as many views as possible. This can be reformulated as an optimization problem where the optimal clustering is the closest to all the single view clusterings under a certain distance or dissimilarity measure. Clusterings are again represented as membership matrices.</p><p>Formally the model can be described as follow: given a set of clustering membership matrices <inline-formula id="IEq3"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$M=\;[\!M_{1},\ldots, M_{h}] \in R_{+}^{n \times l}$\end{document}</tex-math><mml:math id="M10"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mspace width="2.77626pt"/><mml:mo>[</mml:mo><mml:mspace width="0.3em"/><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo><mml:mo>&#x02208;</mml:mo><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2015_680_IEq3.gif"/></alternatives></inline-formula> and a positive integer <italic>k</italic>, the optimal clustering membership matrix <inline-formula id="IEq4"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$B \in R_{+}^{n \times k}$\end{document}</tex-math><mml:math id="M12"><mml:mi>B</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2015_680_IEq4.gif"/></alternatives></inline-formula> and the optimal mapping matrices <inline-formula id="IEq5"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$P = \,[\!P_{1},\ldots,P_{h}] \in R_{+}^{k \times l}$\end{document}</tex-math><mml:math id="M14"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mspace width="0.3em"/><mml:mo>[</mml:mo><mml:mspace width="0.3em"/><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo><mml:mo>&#x02208;</mml:mo><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2015_680_IEq5.gif"/></alternatives></inline-formula> are given by the minimization:
<disp-formula id="Equ3"><label>(3)</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \begin{aligned} &#x00026; \underset{B,P}{\text{min}} &#x00026; &#x00026; GI(M||BP) \\ &#x00026; \text{s. t.} &#x00026; &#x00026; P \geq 0\\ &#x00026; &#x00026; &#x00026; B \geq 0, B\mathbf{1}=\mathbf{1} \end{aligned}  $$ \end{document}</tex-math><mml:math id="M16"><mml:mtable><mml:mtr><mml:mtd><mml:munder><mml:mrow><mml:mtext>min</mml:mtext></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:munder></mml:mtd><mml:mtd><mml:mtext mathvariant="italic">GI</mml:mtext><mml:mo>(</mml:mo><mml:mi>M</mml:mi><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mtext mathvariant="italic">BP</mml:mtext><mml:mo>)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>s. t.</mml:mtext></mml:mtd><mml:mtd><mml:mi>P</mml:mi><mml:mo>&#x02265;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>B</mml:mi><mml:mo>&#x02265;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mn mathvariant="bold">1</mml:mn><mml:mo>=</mml:mo><mml:mn mathvariant="bold">1</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2015_680_Equ3.gif" position="anchor"/></alternatives></disp-formula>
</p><p>where <italic>G</italic>
<italic>I</italic>(<italic>M</italic>||<italic>B</italic>
<italic>P</italic>) is the generalized Kullback-Leibler divergence such that
<disp-formula id="Equa"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$GI(X||Y)=\sum_{ij}\left(logX_{ij} log \frac{X_{ij}}{Y_{ij}} - X_{ij} + Y_{ij}\right) $$ \end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:mtext mathvariant="italic">GI</mml:mtext><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi>Y</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big">&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:munder><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mtext mathvariant="italic">log</mml:mtext><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub><mml:mtext mathvariant="italic">log</mml:mtext><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2015_680_Equa.gif" position="anchor"/></alternatives></disp-formula>
</p><p>subject to the constraint that both <italic>P</italic> and <italic>B</italic> must be non-negative and that each row of <italic>B</italic> must sum to one.</p><p>By taking the membership matrix for each of the previous clusterings, and, using these two late integration methods, a multi-view clustering was obtained. Experiments were performed in two ways: the former uses all the prototypes for classification; the latter uses only the most relevant ones for class separability. Each one of these approaches were performed both in unsupervised and semi-supervised manners, respectively.</p><p>The semi-supervised approach consists of giving a priori information as input to the techniques of late integration via a membership matrix of patients with the exact information of their classes. This information is combined with the membership of the patients compared to the single view clustering and integrated in metaclusters. This can be a useful approach mainly when the data set is composed of unbalanced or under represented classes.</p></sec><sec id="Sec9"><title>Derivation of subclasses</title><p>Once the multi-view clusters were obtained, a subclass was assigned to each one. For each cluster, the number of objects of each class was calculated and the class with more representative patterns was assigned as the cluster label. Then, a p-value was calculated in order to verify the statistical significance of the subclass by the Fisher&#x02019;s exact test [<xref ref-type="bibr" rid="CR32">32</xref>].</p></sec><sec id="Sec10"><title>Validation</title><p>The method was compared with classical single view clustering algorithms, early and intermediate integration approaches. For each method clustering impurity, normalized mutual information (NMI) and cluster stability were evaluated. Cluster impurity was defined as the number of patients in the cluster whose label differs from that of the cluster. Given two clustering solutions <italic>C</italic>
<italic>l</italic>
<sub>1</sub> and <italic>C</italic>
<italic>l</italic>
<sub>2</sub> NMI was computed as the mutual information between the two clustering normalized by the cluster entropies. The NMI was computed between clustering results and real patient classifications.</p><p>Since prior information was introduced, the stability of the system was tested with leave-one-out technique. A test in itself was run on the first step to generate a stability index for the prototypes of the obtained clusters. Then, the steps 2, 3 and 4 were evaluated jointly to assess the stability of the selected features and to evaluate the robustness of the multi-view clustering results. Furthermore, a borda-count [<xref ref-type="bibr" rid="CR33">33</xref>] method was performed to find the final list of features selected over the leave-one-out experiments for the integration step.</p><p>At the end of this process, N different clustering assignments were obtained, one for each removed patient. An <italic>N</italic>&#x000d7;<italic>N</italic> matrix M was created, where <italic>M</italic>(<italic>i</italic>,<italic>j</italic>) was the normalized mutual information (NMI) between the clustering obtained removing patient i and the clustering obtained removing patient <italic>j</italic>. Then the mean of the matrix M was calculated, indicating the stability measure of the method.</p><p>The comparison study involved the following methods:
<list list-type="bullet"><list-item><p>Kmeans, Hierarchical and Pam single view clustering</p></list-item><list-item><p>Tw-Kmeans, an early integration multi-view clustering algorithm</p></list-item><list-item><p>SNF, an intermediate integration multi-view clustering algorithm</p></list-item></list>
</p><p>Experiments with single view clustering algorithms were executed in feature concatenation mode: data from views were concatenated and used as a new greater feature space. This kind of experiments were run both on the most variable features for each view and on the most relevant prototypes found after the first and second steps of our approach. Experiments with Tw-kmeans were executed on all the features without any manipulation of the initial datasets. Experiments with SNF were executed both using all the features and using all the features that belong to the clusters associated to the relevant prototypes.</p></sec><sec id="Sec11"><title>Dataset collection and preparation</title><p>Six datasets were downloaded from The Cancer Genome Atlas (TCGA) (<ext-link ext-link-type="uri" xlink:href="https://tcga-data.nci.nih.gov/tcga/">https://tcga-data.nci.nih.gov/tcga/</ext-link>), Memoral Sloan-Kettering Cancer Center (<ext-link ext-link-type="uri" xlink:href="http://cbio.mskcc.org/">http://cbio.mskcc.org/</ext-link>) and from NCBI GEO (<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/geo/">http://www.ncbi.nlm.nih.gov/geo/</ext-link>) (See Table <xref rid="Tab1" ref-type="table">1</xref>).</p><sec id="Sec12"><title>TCGA.BRC</title><p>Breast cancer dataset from the TCGA repository (<ext-link ext-link-type="uri" xlink:href="https://tcga-data.nci.nih.gov/tcga/">https://tcga-data.nci.nih.gov/tcga/</ext-link> - Breast invasive carcinoma [BRCA]). The samples in this dataset correspond to breast cancer patients with invasive tumors. Genomic data for two views were downloaded: RNASeq and miRNASeq (Level 3). Because level 3 data corresponds to already preprocessed data, only the batch effect was removed by the comBat method in the R &#x0201c;sva&#x0201d; package [<xref ref-type="bibr" rid="CR34">34</xref>]. Patients were subsequently divided into four classes (Her2, Basal, LumA, LumB), using PAM50 classifier [<xref ref-type="bibr" rid="CR35">35</xref>, <xref ref-type="bibr" rid="CR36">36</xref>].</p></sec><sec id="Sec13"><title>OXF.BRC.1</title><p>Breast cancer dataset from a study performed at Oxford University [<xref ref-type="bibr" rid="CR37">37</xref>]. Data were downloaded from Gene Expression Omnibus Dataset (<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/geo/">http://www.ncbi.nlm.nih.gov/geo/</ext-link>). Data were available for two views: mRNA and microRNA expression under the accession number GSE22219 and GSE22220. Patients were divided into four classes (Her2, Basal, LumA, LumB), using PAM50 classifier [<xref ref-type="bibr" rid="CR35">35</xref>, <xref ref-type="bibr" rid="CR36">36</xref>].</p></sec><sec id="Sec14"><title>OXF.BRC.2</title><p>Breast cancer dataset from a study performed at Oxford University [<xref ref-type="bibr" rid="CR37">37</xref>]. Data were downloaded from Gene Expression Omnibus Dataset (<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/geo/">http://www.ncbi.nlm.nih.gov/geo/</ext-link>). Data were available for two views: mRNA and microRNA expression under the accession number GSE22219 and GSE22220. Patients were divided into four classes (Level1, Level2, Level3, Level4) using clinical data also retrieved from the same source. See Table <xref rid="Tab4" ref-type="table">4</xref> for classes definition.
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Oxford Dataset: Oxford Dataset, class definition by clinical data</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Class</th><th align="left">Clinical information</th></tr></thead><tbody><tr><td align="left">Level1</td><td align="left">er = 1, node = 0, grade = 1&#x02013;2</td></tr><tr><td align="left"/><td align="left">er = 1, node = 0, grade = 3&#x02013;4</td></tr><tr><td align="left">Level2</td><td align="left">er = 1, node &#x0003e; 0, grade = 1&#x02013;2</td></tr><tr><td align="left"/><td align="left">er = 1, node &#x0003e; 0, grade = 3&#x02013;4</td></tr><tr><td align="left">Level3</td><td align="left">er = 0, node = 0, grade = 1&#x02013;2</td></tr><tr><td align="left"/><td align="left">er = 0, node = 0, grade = 3&#x02013;4</td></tr><tr><td align="left">Level4</td><td align="left">er = 0, node &#x0003e; 0, grade = 1&#x02013;2</td></tr><tr><td align="left"/><td align="left">er = 0, node &#x0003e; 0, grade = 3&#x02013;4</td></tr></tbody></table></table-wrap>
</p></sec><sec id="Sec15"><title>TCGA.GBM</title><p>Glioblastoma cancer dataset from the TCGA repository. The samples in this dataset correspond to glioblastoma patient with invasive tumors. TCGA website was accessed (<ext-link ext-link-type="uri" xlink:href="https://tcga-data.nci.nih.gov/tcga/">https://tcga-data.nci.nih.gov/tcga/</ext-link> - Glioblastoma multiforme [GBM]) and publicly available data for two views were downloaded: gene expression and miRNA expression. Also clinical data was retrieved. The patients were divided info four classes: Classical, Mesechymal, Neural and Proneural as described in [<xref ref-type="bibr" rid="CR38">38</xref>].</p></sec><sec id="Sec16"><title>TCGA.OVG</title><p>Ovarian cancer dataset from the TCGA repository (<ext-link ext-link-type="uri" xlink:href="https://tcga-data.nci.nih.gov/tcga/">https://tcga-data.nci.nih.gov/tcga/</ext-link> - Ovarian serous cystadenocarcinoma [OV]). The samples in this dataset correspond to patient affected by ovarian serous cystadenocarcinoma tumors. Publicly available data for three views were downloaded: gene expression, protein expression, and miRNA expression. Clinical data were downloaded in order to classify patients in three categories. In particular patients were classified by clinical stage: first class: stage IA, IB, IC, IIA, IIB and IIC, second class: IIIA, IIIB and IIIC, third class Stage IV.</p></sec><sec id="Sec17"><title>MSKCC.PRCA</title><p>Prostate cancer dataset from a study performed at the Memorial Sloan Kettering Cancer Center (<ext-link ext-link-type="uri" xlink:href="http://cbio.mskcc.org/">http://cbio.mskcc.org/</ext-link>). The samples in these datasets correspond to patient prostate cancer tumors. The MSKCC Cancer Genomics data portal (<ext-link ext-link-type="uri" xlink:href="http://cbio.mskcc.org/cancergenomics/prostate/data/">http://cbio.mskcc.org/cancergenomics/prostate/data/</ext-link>) was accessed and data for five views were downloaded: clinical data, gene expression, microRNA expression and copy number variation. Patients were classified in two classes by using clinical data by the tumor stage: class one is Tumor Stage I and class two is Tumor Stage II, III and IV. Classification of patient was done according to a previous study performed on the same dataset [<xref ref-type="bibr" rid="CR14">14</xref>].</p></sec></sec></sec></body><back><app-group><app id="App1"><sec id="Sec18"><title>Additional files</title><p>
<media position="anchor" xlink:href="12859_2015_680_MOESM1_ESM.pdf" id="MOESM1"><label>Additional file 1</label><caption><p>
<bold>It contains a section for each step of the methodology in which the tables and figures with the results for each dataset are reported.</bold> (PDF 1495 kb)</p></caption></media>
</p><p>
<media position="anchor" xlink:href="12859_2015_680_MOESM2_ESM.xlsx" id="MOESM2"><label>Additional file 2</label><caption><p>
<bold>Each sheet refers to each dataset analysed, reporting the results of the single-view clustering patients.</bold> Clustering errors for each algorithm and each cut of feature are also reported. (XLSX 54 kb)</p></caption></media>
</p><p>
<media position="anchor" xlink:href="12859_2015_680_MOESM3_ESM.docx" id="MOESM3"><label>Additional file 3</label><caption><p>
<bold>It contains the gene symbols and description for all shared genes between the tree breast cancer datasets highlighted by the analysis.</bold> (DOCX 14 kb)</p></caption></media>
</p></sec></app></app-group><glossary><title>Abbreviations</title><def-list><def-item><term>miRNA</term><def><p>MicroRNA</p></def></def-item><def-item><term>CNV</term><def><p>Copy number variation</p></def></def-item><def-item><term>NMI</term><def><p>Normalized mutual information</p></def></def-item><def-item><term>GO</term><def><p>Gene Ontology</p></def></def-item><def-item><term>SOM</term><def><p>Self-organizing map</p></def></def-item><def-item><term>Pam</term><def><p>Partitional around medoids</p></def></def-item><def-item><term>CAT-score</term><def><p>Correlation-adjusted t-score</p></def></def-item><def-item><term>DAVID</term><def><p>Database for annotation, visualization and integrated discovery</p></def></def-item><def-item><term>TCGA</term><def><p>The Cancer Genome Atlas</p></def></def-item><def-item><term>MSKCC</term><def><p>Memorial Sloan Kettering Cancer Center</p></def></def-item><def-item><term>GEO</term><def><p>Gene Expression Omnibus</p></def></def-item></def-list></glossary><fn-group><fn><p><bold>Competing interests</bold></p><p>The authors declare that they have no competing interests.</p></fn><fn><p><bold>Authors&#x02019; contributions</bold></p><p>DG and RT conceived and supervised the study. AS developed the methods, analysed and interpreted the data, and implemented the software. MF, VF and GR participated the development of the methods and the analysis of the data. All the authors have participated in drafting the manuscript. All authors read and approved the final manuscript.</p></fn></fn-group><ack><title>Acknowledgements</title><p>This work has been supported by the European Commission, under grant agreement FP7-309329 (NANOSOLUTIONS).</p><p>The results shown here are in part based upon data generated by the TCGA Research Network: <ext-link ext-link-type="uri" xlink:href="http://cancergenome.nih.gov/">http://cancergenome.nih.gov/</ext-link>.</p></ack><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>HY</given-names></name><name><surname>Nuyten</surname><given-names>DS</given-names></name><name><surname>Sneddon</surname><given-names>JB</given-names></name><name><surname>Hastie</surname><given-names>T</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name><name><surname>S&#x000f8;rlie</surname><given-names>T</given-names></name><etal/></person-group><article-title>Robustness, scalability, and integration of a wound-response gene expression signature in predicting breast cancer survival</article-title><source>Proc National Acad Sci U S A</source><year>2005</year><volume>102</volume><issue>10</issue><fpage>3738</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1073/pnas.0409462102</pub-id></element-citation></ref><ref id="CR2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>E</given-names></name><name><surname>Cheng</surname><given-names>SH</given-names></name><name><surname>Dressman</surname><given-names>H</given-names></name><name><surname>Pittman</surname><given-names>J</given-names></name><name><surname>Tsou</surname><given-names>MH</given-names></name><name><surname>Horng</surname><given-names>CF</given-names></name><etal/></person-group><article-title>Gene expression predictors of breast cancer outcomes</article-title><source>The Lancet</source><year>2003</year><volume>361</volume><issue>9369</issue><fpage>1590</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1016/S0140-6736(03)13308-9</pub-id></element-citation></ref><ref id="CR3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>West</surname><given-names>M</given-names></name><name><surname>Blanchette</surname><given-names>C</given-names></name><name><surname>Dressman</surname><given-names>H</given-names></name><name><surname>Huang</surname><given-names>E</given-names></name><name><surname>Ishida</surname><given-names>S</given-names></name><name><surname>Spang</surname><given-names>R</given-names></name><etal/></person-group><article-title>Predicting the clinical status of human breast cancer by using gene expression profiles</article-title><source>Proc National Acad Sci</source><year>2001</year><volume>98</volume><issue>20</issue><fpage>11462</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1073/pnas.201162998</pub-id></element-citation></ref><ref id="CR4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>S&#x000f8;rlie</surname><given-names>T</given-names></name><name><surname>Perou</surname><given-names>CM</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name><name><surname>Aas</surname><given-names>T</given-names></name><name><surname>Geisler</surname><given-names>S</given-names></name><name><surname>Johnsen</surname><given-names>H</given-names></name><etal/></person-group><article-title>Gene expression patterns of breast carcinomas distinguish tumor subclasses with clinical implications</article-title><source>Proc National Acad Sci</source><year>2001</year><volume>98</volume><issue>19</issue><fpage>10869</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1073/pnas.191367098</pub-id></element-citation></ref><ref id="CR5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vang Nielsen</surname><given-names>K</given-names></name><name><surname>Ejlertsen</surname><given-names>B</given-names></name><name><surname>M&#x000f8;ller</surname><given-names>S</given-names></name><name><surname>Tr&#x000f8;st J&#x000f8;rgensen</surname><given-names>J</given-names></name><name><surname>Knoop</surname><given-names>A</given-names></name><name><surname>Knudsen</surname><given-names>H</given-names></name><etal/></person-group><article-title>The value of top2a gene copy number variation as a biomarker in breast cancer: Update of dbcg trial 89d</article-title><source>Acta Oncologica</source><year>2008</year><volume>47</volume><issue>4</issue><fpage>725</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1080/02841860801995396</pub-id><pub-id pub-id-type="pmid">18465341</pub-id></element-citation></ref><ref id="CR6"><label>6</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kailing</surname><given-names>K</given-names></name><name><surname>Kriegel</surname><given-names>HP</given-names></name><name><surname>Pryakhin</surname><given-names>A</given-names></name><name><surname>Schubert</surname><given-names>M</given-names></name></person-group><article-title>Clustering multi-represented objects with noise</article-title><source>Advances in Knowledge Discovery and Data Mining</source><year>2004</year><publisher-loc>Berlin Heidelberg</publisher-loc><publisher-name>Springer</publisher-name></element-citation></ref><ref id="CR7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Xu</surname><given-names>X</given-names></name><name><surname>Huang</surname><given-names>JZ</given-names></name><name><surname>Ye</surname><given-names>Y</given-names></name></person-group><article-title>Tw- (<italic>k</italic>)-means: Automated two-level variable weighting clustering algorithm for multiview data</article-title><source>Knowl Data Eng IEEE Trans</source><year>2013</year><volume>25</volume><issue>4</issue><fpage>932</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1109/TKDE.2011.262</pub-id></element-citation></ref><ref id="CR8"><label>8</label><mixed-citation publication-type="other">Sa VRD. Spectral Clustering with Two Views. In: ICML workshop on learning with multiple views: 2005. p. 20&#x02013;27.</mixed-citation></ref><ref id="CR9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>B</given-names></name><name><surname>Mezlini</surname><given-names>AM</given-names></name><name><surname>Demir</surname><given-names>F</given-names></name><name><surname>Fiume</surname><given-names>M</given-names></name><name><surname>Tu</surname><given-names>Z</given-names></name><name><surname>Brudno</surname><given-names>M</given-names></name><name><surname>Haibe-Kains</surname><given-names>B</given-names></name><name><surname>Goldenberg</surname><given-names>A</given-names></name></person-group><article-title>Similarity network fusion for aggregating data types on a genomic scale</article-title><source>Nat methods</source><year>2014</year><volume>11</volume><issue>3</issue><fpage>333</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2810</pub-id><pub-id pub-id-type="pmid">24464287</pub-id></element-citation></ref><ref id="CR10"><label>10</label><mixed-citation publication-type="other">Long B, Yu PS, Zhang Z. A general model for multiple view unsupervised learning. In: Society for Industrial and Applied Mathematics - 8th SIAM International Conference on Data Mining 2008, Proceedings in Applied Mathematics: 2008. p. 822&#x02013;33.</mixed-citation></ref><ref id="CR11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greene</surname><given-names>D</given-names></name></person-group><article-title>A Matrix Factorization Approach for Integrating Multiple Data Views</article-title><source>Mach Learn Knowl Discov Databases</source><year>2009</year><volume>5781</volume><fpage>423</fpage><lpage>38</lpage></element-citation></ref><ref id="CR12"><label>12</label><mixed-citation publication-type="other">Xu C, Tao D, Xu C. A survey on multi-view learning. 2013. arXiv preprint arXiv:1304.5634.</mixed-citation></ref><ref id="CR13"><label>13</label><mixed-citation publication-type="other">Wasito I, Istiqlal A, Budi I. Data integration model for cancer subtype identification using Kernel Dimensionality Reduction-Support Vector Machine (KDR-SVM). In: Computing and Convergence Technology (ICCCT), 2012 7th International Conference On. IEEE: 2012. p. 876&#x02013;80.</mixed-citation></ref><ref id="CR14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ray</surname><given-names>B</given-names></name><name><surname>Henaff</surname><given-names>M</given-names></name><name><surname>Ma</surname><given-names>S</given-names></name><name><surname>Efstathiadis</surname><given-names>E</given-names></name><name><surname>Peskin</surname><given-names>ER</given-names></name><name><surname>Picone</surname><given-names>M</given-names></name><etal/></person-group><article-title>Information content and analysis methods for multi-modal high-throughput biomedical data</article-title><source>Sci Rep</source><year>2014</year><volume>4</volume><fpage>4411</fpage><pub-id pub-id-type="pmid">24651673</pub-id></element-citation></ref><ref id="CR15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>J</given-names></name><name><surname>Bi</surname><given-names>J</given-names></name><name><surname>Kranzler</surname><given-names>HR</given-names></name></person-group><article-title>Multi-view singular value decomposition for disease subtyping and genetic associations</article-title><source>BMC Genet</source><year>2014</year><volume>15</volume><issue>1</issue><fpage>73</fpage><pub-id pub-id-type="doi">10.1186/1471-2156-15-73</pub-id><pub-id pub-id-type="pmid">24938865</pub-id></element-citation></ref><ref id="CR16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>R</given-names></name><name><surname>Mo</surname><given-names>Q</given-names></name><name><surname>Schultz</surname><given-names>N</given-names></name><name><surname>Seshan</surname><given-names>VE</given-names></name><name><surname>Olshen</surname><given-names>AB</given-names></name><name><surname>Huse</surname><given-names>J</given-names></name><etal/></person-group><article-title>Integrative subtype discovery in glioblastoma using icluster</article-title><source>PLoS ONE</source><year>2012</year><volume>7</volume><issue>4</issue><fpage>35236</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0035236</pub-id></element-citation></ref><ref id="CR17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinh</surname><given-names>NX</given-names></name><name><surname>Epps</surname><given-names>J</given-names></name><name><surname>Bailey</surname><given-names>J</given-names></name></person-group><article-title>Information theoretic measures for clusterings comparison: Variants, properties, normalization and correction for chance</article-title><source>J Mach Learn Res</source><year>2010</year><volume>11</volume><fpage>2837</fpage><lpage>854</lpage></element-citation></ref><ref id="CR18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dennis Jr</surname><given-names>G</given-names></name><name><surname>Sherman</surname><given-names>BT</given-names></name><name><surname>Hosack</surname><given-names>DA</given-names></name><name><surname>Yang</surname><given-names>J</given-names></name><name><surname>Gao</surname><given-names>W</given-names></name><name><surname>Lane</surname><given-names>HC</given-names></name><etal/></person-group><article-title>David: database for annotation, visualization, and integrated discovery</article-title><source>Genome Biol</source><year>2003</year><volume>4</volume><issue>5</issue><fpage>3</fpage><pub-id pub-id-type="doi">10.1186/gb-2003-4-5-p3</pub-id></element-citation></ref><ref id="CR19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>DW</given-names></name><name><surname>Sherman</surname><given-names>BT</given-names></name><name><surname>Tan</surname><given-names>Q</given-names></name><name><surname>Kir</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>D</given-names></name><name><surname>Bryant</surname><given-names>D</given-names></name><etal/></person-group><article-title>David bioinformatics resources: expanded annotation database and novel algorithms to better extract biology from large gene lists</article-title><source>Nucleic Acids Res</source><year>2007</year><volume>35</volume><issue>suppl 2</issue><fpage>169</fpage><lpage>75</lpage><pub-id pub-id-type="doi">10.1093/nar/gkm415</pub-id></element-citation></ref><ref id="CR20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fortino</surname><given-names>V</given-names></name><name><surname>Alenius</surname><given-names>H</given-names></name><name><surname>Greco</surname><given-names>D</given-names></name></person-group><article-title>Baca: bubble chart to compare annotations</article-title><source>BMC Bioinformatics</source><year>2015</year><volume>16</volume><issue>1</issue><fpage>37</fpage><pub-id pub-id-type="doi">10.1186/s12859-015-0477-4</pub-id><pub-id pub-id-type="pmid">25652236</pub-id></element-citation></ref><ref id="CR21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suzuki</surname><given-names>R</given-names></name><name><surname>Shimodaira</surname><given-names>H</given-names></name></person-group><article-title>Pvclust: an R package for assessing the uncertainty in hierarchical clustering</article-title><source>Bioinformatics (Oxford England)</source><year>2006</year><volume>22</volume><issue>12</issue><fpage>1540</fpage><lpage>2</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btl117</pub-id></element-citation></ref><ref id="CR22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vesanto</surname><given-names>J</given-names></name><name><surname>Alhoniemi</surname><given-names>E</given-names></name></person-group><article-title>Clustering of the self-organizing map</article-title><source>Neural Netw IEEE Trans</source><year>2000</year><volume>11</volume><issue>3</issue><fpage>586</fpage><lpage>600</lpage><pub-id pub-id-type="doi">10.1109/72.846731</pub-id></element-citation></ref><ref id="CR23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ward</surname><given-names>JH</given-names></name></person-group><article-title>Hierarchical Grouping to Optimize an Objective Function</article-title><source>J Am Stat Assoc</source><year>1963</year><volume>58</volume><issue>301</issue><fpage>236</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1080/01621459.1963.10500845</pub-id></element-citation></ref><ref id="CR24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartigan</surname><given-names>JA</given-names></name><name><surname>Wong</surname><given-names>MA</given-names></name></person-group><article-title>Algorithm AS 136: A K-Means Clustering Algorithm</article-title><source>J R Stat Soc</source><year>1979</year><volume>28</volume><fpage>100</fpage><lpage>8</lpage></element-citation></ref><ref id="CR25"><label>25</label><mixed-citation publication-type="other">Kaufman L, Rousseeuw PJ. Clustering by means of medoids. In: Data analysis based on the L 1-Norm and related methods. North-Holland: 1987. p. 405&#x02013;416.</mixed-citation></ref><ref id="CR26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ng</surname><given-names>AY</given-names></name><name><surname>Jordan</surname><given-names>MI</given-names></name><name><surname>Weiss</surname><given-names>Y</given-names></name></person-group><article-title>On spectral clustering: Analysis and an algorithm</article-title><source>Adv Neural Inf Process Systs</source><year>2002</year><volume>2</volume><fpage>849</fpage><lpage>56</lpage></element-citation></ref><ref id="CR27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Handl</surname><given-names>J</given-names></name><name><surname>Knowles</surname><given-names>J</given-names></name><name><surname>Kell</surname><given-names>DB</given-names></name></person-group><article-title>Computational cluster validation in post-genomic data analysis</article-title><source>Bioinformatics (Oxford, England)</source><year>2005</year><volume>21</volume><issue>15</issue><fpage>3201</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/bti517</pub-id></element-citation></ref><ref id="CR28"><label>28</label><mixed-citation publication-type="other">Nieweglowski L. Clv: Cluster Validation Techniques. 2013. R package version 0.3-2.1. <ext-link ext-link-type="uri" xlink:href="http://CRAN.R-project.org/package=clv">http://CRAN.R-project.org/package=clv</ext-link>.</mixed-citation></ref><ref id="CR29"><label>29</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahdesm&#x000e4;ki</surname><given-names>M</given-names></name><name><surname>Strimmer</surname><given-names>K</given-names></name></person-group><article-title>Feature selection in omics prediction problems using cat scores and false nondiscovery rate control</article-title><source>Ann Appl Stat</source><year>2010</year><volume>4</volume><issue>1</issue><fpage>503</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1214/09-AOAS277</pub-id></element-citation></ref><ref id="CR30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breiman</surname><given-names>L</given-names></name></person-group><article-title>Random forests</article-title><source>Mach Learn</source><year>2001</year><volume>45</volume><issue>1</issue><fpage>5</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id></element-citation></ref><ref id="CR31"><label>31</label><mixed-citation publication-type="other">Cortez P. Rminer: Data Mining Classification and Regression Methods. 2014. R package version 1.4. <ext-link ext-link-type="uri" xlink:href="http://CRAN.R-project.org/package=rminer">http://CRAN.R-project.org/package=rminer</ext-link></mixed-citation></ref><ref id="CR32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>RA</given-names></name></person-group><source>JSTOR: J R Stat Soc</source><year>1922</year><volume>85</volume><issue>1</issue><fpage>87</fpage><lpage>94</lpage></element-citation></ref><ref id="CR33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>S</given-names></name></person-group><article-title>Space oriented rank-based data integration</article-title><source>Stat Appl Genet Mol Biol</source><year>2010</year><volume>9</volume><issue>1</issue><fpage>1544</fpage><lpage>6115</lpage></element-citation></ref><ref id="CR34"><label>34</label><mixed-citation publication-type="other">Leek JT, Johnson WE, Parker HS, Fertig EJ, Jaffe AE, Storey JD. Sva: Surrogate Variable Analysis. R package version 3.14.0.</mixed-citation></ref><ref id="CR35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tibshirani</surname><given-names>R</given-names></name><name><surname>Hastie</surname><given-names>T</given-names></name><name><surname>Narasimhan</surname><given-names>B</given-names></name><name><surname>Chu</surname><given-names>G</given-names></name></person-group><article-title>Diagnosis of multiple cancer types by shrunken centroids of gene expression</article-title><source>Proc Natl Acad Sci U S A</source><year>2002</year><volume>99</volume><issue>10</issue><fpage>6567</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1073/pnas.082099299</pub-id><pub-id pub-id-type="pmid">12011421</pub-id></element-citation></ref><ref id="CR36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parker</surname><given-names>JS</given-names></name><name><surname>Mullins</surname><given-names>M</given-names></name><name><surname>Cheang</surname><given-names>MCU</given-names></name><name><surname>Leung</surname><given-names>S</given-names></name><name><surname>Voduc</surname><given-names>D</given-names></name><name><surname>Vickery</surname><given-names>T</given-names></name><etal/></person-group><article-title>Supervised risk predictor of breast cancer based on intrinsic subtypes</article-title><source>J Clin Oncol Off J Am Soc Clin Oncol</source><year>2009</year><volume>27</volume><issue>8</issue><fpage>1160</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1200/JCO.2008.18.1370</pub-id></element-citation></ref><ref id="CR37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buffa</surname><given-names>FM</given-names></name><name><surname>Camps</surname><given-names>C</given-names></name><name><surname>Winchester</surname><given-names>L</given-names></name><name><surname>Snell</surname><given-names>CE</given-names></name><name><surname>Gee</surname><given-names>HE</given-names></name><name><surname>Sheldon</surname><given-names>H</given-names></name><etal/></person-group><article-title>microRNA-associated progression pathways and potential therapeutic targets identified by integrated mRNA and microRNA expression profiling in breast cancer</article-title><source>Cancer Res</source><year>2011</year><volume>71</volume><issue>17</issue><fpage>5635</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1158/0008-5472.CAN-11-0489</pub-id><pub-id pub-id-type="pmid">21737487</pub-id></element-citation></ref><ref id="CR38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Verhaak</surname><given-names>RGW</given-names></name><name><surname>Hoadley</surname><given-names>KA</given-names></name><name><surname>Purdom</surname><given-names>E</given-names></name><name><surname>Wang</surname><given-names>V</given-names></name><name><surname>Qi</surname><given-names>Y</given-names></name><name><surname>Wilkerson</surname><given-names>MD</given-names></name><etal/></person-group><article-title>Integrated genomic analysis identifies clinically relevant subtypes of glioblastoma characterized by abnormalities in PDGFRA, IDH1, EGFR, and NF1</article-title><source>Cancer Cell</source><year>2010</year><volume>17</volume><issue>1</issue><fpage>98</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1016/j.ccr.2009.12.020</pub-id><pub-id pub-id-type="pmid">20129251</pub-id></element-citation></ref></ref-list></back></article>