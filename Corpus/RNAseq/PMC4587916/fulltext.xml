<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 2?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id><journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id><journal-title-group><journal-title>BMC Bioinformatics</journal-title></journal-title-group><issn pub-type="epub">1471-2105</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">4587916</article-id><article-id pub-id-type="pmid">26415849</article-id><article-id pub-id-type="publisher-id">728</article-id><article-id pub-id-type="doi">10.1186/s12859-015-0728-4</article-id><article-categories><subj-group subj-group-type="heading"><subject>Software</subject></subj-group></article-categories><title-group><article-title>NetBenchmark: a bioconductor package for reproducible benchmarks of gene regulatory network inference</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Bellot</surname><given-names>Pau</given-names></name><address><email>pau.bellot@upc.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Olsen</surname><given-names>Catharina</given-names></name><address><email>colsen@ulb.ac.be</email></address><xref ref-type="aff" rid="Aff3">3</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author"><name><surname>Salembier</surname><given-names>Philippe</given-names></name><address><email>philippe.salembier@upc.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Oliveras-Verg&#x000e9;s</surname><given-names>Albert</given-names></name><address><email>albert.oliveras@upc.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Meyer</surname><given-names>Patrick E.</given-names></name><address><email>patrick.meyer@ulg.ac.be</email></address><xref ref-type="aff" rid="Aff2">2</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.6835.8</institution-id><institution>Universitat Politecnica de Catalunya BarcelonaTECH, </institution><institution>Department of Signal Theory and Communications, UPC-Campus Nord, </institution></institution-wrap>C/ Jordi Girona, 1-3, Barcelona, 08034 Spain </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0805 7253</institution-id><institution-id institution-id-type="GRID">grid.4861.b</institution-id><institution>Bioinformatics and Systems Biology (BioSys), </institution><institution>Faculty of Sciences, Universit&#x000e9; de Li&#x000e8;ge (ULg), </institution></institution-wrap>27 Blvd du Rectorat, Li&#x000e8;ge, 4000 Belgium </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2348 0746</institution-id><institution-id institution-id-type="GRID">grid.4989.c</institution-id><institution>Machine Learning Group, </institution><institution>Universit&#x000e9; Libre de Bruxelles, </institution></institution-wrap>Brussels, Belgium </aff><aff id="Aff4"><label>4</label>Interuniversity Institute of Bioinformatics Brussels, (IB)&#x000b2;, Brussels, Belgium </aff></contrib-group><pub-date pub-type="epub"><day>29</day><month>9</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>16</volume><elocation-id>312</elocation-id><history><date date-type="received"><day>18</day><month>3</month><year>2015</year></date><date date-type="accepted"><day>6</day><month>9</month><year>2015</year></date></history><permissions><copyright-statement>&#x000a9; Bellot et al. 2015</copyright-statement><license license-type="OpenAccess"><license-p>
<bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p>In the last decade, a great number of methods for reconstructing gene regulatory networks from expression data have been proposed. However, very few tools and datasets allow to evaluate accurately and reproducibly those methods. Hence, we propose here a new tool, able to perform a systematic, yet fully reproducible, evaluation of transcriptional network inference methods.</p></sec><sec><title>Results</title><p>Our open-source and freely available Bioconductor package aggregates a large set of tools to assess the robustness of network inference algorithms against different simulators, topologies, sample sizes and noise intensities.</p></sec><sec><title>Conclusions</title><p>The benchmarking framework that uses various datasets highlights the specialization of some methods toward network types and data. As a result, it is possible to identify the techniques that have broad overall performances.</p></sec><sec><title>Electronic supplementary material</title><p>The online version of this article (doi:10.1186/s12859-015-0728-4) contains supplementary material, which is available to authorized users.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Bioconductor package</kwd><kwd>Gene regulatory networks</kwd><kwd>Gene expression</kwd><kwd>Gene regulation network reconstruction</kwd><kwd>Synthetic genetic networks</kwd><kwd>Benchmark</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2015</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background</title><p>Despite extensive knowledge of individual genes, we are still far from understanding the regulation mechanisms happening inside biological cells. In order to gain a system-level understanding, it is necessary to examine how genes interact on a large-scale level.</p><p>Some specific genes called transcription factors (TF) bind to the promoter regions of target genes (TG) and can activate or inhibit a TG&#x02019;s expression. Therefore, genes do not work in isolation; they are connected in highly structured networks. Gene Regulatory Networks (GRNs) represent this set of relationships.</p><p>Reconstructing gene regulatory networks from expression data is a very difficult problem that has seen a continuously rising interest in the past decade, and presumably this trend will continue in the years to come due to the rich set of applications in biotechnological fields (biofuel, food, etc.) as well as in the biomedical field (drug design, cancer signatures, etc.). Several papers have compared and evaluated different network reconstruction methods [<xref ref-type="bibr" rid="CR1">1</xref>&#x02013;<xref ref-type="bibr" rid="CR5">5</xref>]. However, a free open-source tool providing a fully reproducible benchmark is yet missing. Furthermore, in each state-of-the-art study, only one synthetic data generator has been used: either the GeneNetWeaver (GNW) simulator [<xref ref-type="bibr" rid="CR3">3</xref>] in [<xref ref-type="bibr" rid="CR4">4</xref>] and [<xref ref-type="bibr" rid="CR5">5</xref>] or the SynTReN simulator [<xref ref-type="bibr" rid="CR1">1</xref>] in [<xref ref-type="bibr" rid="CR2">2</xref>]. As a result, different conclusions about the best performing methods have been obtained in each study. Finally, most reviews do not evaluate the changes of performances of the methods as a function of the number of genes, of the number of experiments or of the intensity of noise for multiple simulators and topologies (SynTReN, GNW, E.coli, S. cerevisae, etc.).</p><p>Hence, we propose a new extensive benchmarking framework that is fully reproducible with just one line of code and can also be easily modified to change the experimental setting or introduce a new inference algorithm. Our benchmarking strategy clearly shows that some methods perform very well on one of these artificial generators but can have poor results on another. This strongly suggests the importance of a tool that is able to test, both simply and broadly, any new proposed method. Some reviews such as [<xref ref-type="bibr" rid="CR6">6</xref>] and [<xref ref-type="bibr" rid="CR7">7</xref>] evaluate the behavior of different GRN reconstruction methods in real data corresponding to well known microbes in [<xref ref-type="bibr" rid="CR6">6</xref>] and to ovarian cancer cells in [<xref ref-type="bibr" rid="CR7">7</xref>]. Although real data represents a theoretically more interesting challenge than artificial data, they suffer from several drawbacks. First, the different algorithms are tested based on only partial knowledge of the underlying network [<xref ref-type="bibr" rid="CR8">8</xref>], where a false positive could be a still undiscovered true positive. Second, the intensity of noise is uncontrollable. Hence, assessing a method&#x02019;s robustness to varying intensities of noise cannot be done easily with real data. However, different noise intensities and distributions are observed from different measurement platforms (i.e. microarray vs RNAseq) as well as from different organisms. As a result, assessing the performance of any reverse-engineering algorithm on a few real datasets gives little information on its performance on other type of organisms and measurement platforms.</p><p>For this reason, we provide a Bioconductor package that, by default, compares 10 variations of 5 datasets having more than 100 expression-measurements each. In other words, the package compares methods on 50 datasets, each with very different samples and even different amounts of noise. Using realistic artificial data allows for large number of samples that in turn, allows for reliable statistical measures indicative of performances and robustness. So far, no consortium nor database focusing on real data has assembled several thousands of homogeneous expression samples (coming from the same experimental platform), that would allow for a similar benchmark. In this paper, we argue that a first step to support a new network inference method is to demonstrate its ability to recover regulatory networks from a broad set of realistic artificial datasets, where the truth is known and where the noise is controlled. Then, of course, a second step would be the analysis of the algorithms on real data (for example, coming from model organisms).</p><p>In this study we will show that our benchmarking strategy is highly informative for evaluating the performance and robustness of network reconstruction methods. Indeed, in this paper, we evaluate more than ten state-of-the-art reconstruction techniques using more than 50 datasets from different simulators in a high number of genes and low number of experiments scenario.</p><p>With this study we found that no single method is the best across different sources of data, but at the same time this study also shows that some techniques, such as CLR [<xref ref-type="bibr" rid="CR9">9</xref>], are rather good in average. We also tested the sensitivity of these methods with regard to different kinds of noise and to the number of experiments. Those experiments highlight which methods are more adapted to the common scenario (i.e. few samples and high noise). Although often overlooked, reproducibility is an important issue in the field of benchmarking. Hence, in order to provide the scientific community with tools allowing the full reproduction of the tests as well as their extension or modification, we provide our benchmarking tools in a Bioconductor package. Table <xref rid="Tab1" ref-type="table">1</xref> summarizes the most important aspects concerning benchmarking and compares the features included in previously published reviews and the one described here.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Reviews of GRN reconstruction methods and their characteristics</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Review</th><th align="left">[<xref ref-type="bibr" rid="CR2">2</xref>]</th><th align="left">[<xref ref-type="bibr" rid="CR4">4</xref>]</th><th align="left">[<xref ref-type="bibr" rid="CR5">5</xref>]</th><th align="left">This study</th></tr></thead><tbody><tr><td align="left">Number of variables</td><td align="left">100</td><td align="left">&#x02208; [1643,5950]</td><td align="left">&#x02208; [10,100]</td><td align="left">&#x02208; [300,2000]</td></tr><tr><td align="left">Topologies</td><td align="left">Yeast</td><td align="left">E. coli &#x00026; S. cerevisiae &#x00026; S. aureus</td><td align="left">Yeast &#x00026; E. coli</td><td align="left">Synthetic &#x00026; Yeast &#x00026; E. coli</td></tr><tr><td align="left">Number of methods compared</td><td align="left">4</td><td align="left">37</td><td align="left">29</td><td align="left">10</td></tr><tr><td align="left">Simulators</td><td align="left">SynTReN</td><td align="left">GNW</td><td align="left">GNW</td><td align="left">Rogers &#x00026; GNW &#x00026; SynTReN</td></tr><tr><td align="left">Number of experiments</td><td align="left">&#x02208; [20,200]</td><td align="left">&#x02208; [160,805]</td><td align="left">&#x02208; [10,100]</td><td align="left">&#x0223c;150</td></tr><tr><td align="left">Impact of number of experiments</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">
<inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\checkmark $\end{document}</tex-math><mml:math id="M2"><mml:mtext/><mml:mi>&#x02713;</mml:mi><mml:mtext/></mml:math><inline-graphic xlink:href="12859_2015_728_IEq1.gif"/></alternatives></inline-formula>
</td><td align="left">
<inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\checkmark $\end{document}</tex-math><mml:math id="M4"><mml:mtext/><mml:mi>&#x02713;</mml:mi><mml:mtext/></mml:math><inline-graphic xlink:href="12859_2015_728_IEq2.gif"/></alternatives></inline-formula>
</td></tr><tr><td align="left">Impact of noise</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">
<inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\checkmark $\end{document}</tex-math><mml:math id="M6"><mml:mtext/><mml:mi>&#x02713;</mml:mi><mml:mtext/></mml:math><inline-graphic xlink:href="12859_2015_728_IEq3.gif"/></alternatives></inline-formula>
</td></tr><tr><td align="left">Dataset availability</td><td align="left">&#x02013;</td><td align="left">
<inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\checkmark $\end{document}</tex-math><mml:math id="M8"><mml:mtext/><mml:mi>&#x02713;</mml:mi><mml:mtext/></mml:math><inline-graphic xlink:href="12859_2015_728_IEq4.gif"/></alternatives></inline-formula>
</td><td align="left">&#x02013;</td><td align="left">
<inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\checkmark $\end{document}</tex-math><mml:math id="M10"><mml:mtext/><mml:mi>&#x02713;</mml:mi><mml:mtext/></mml:math><inline-graphic xlink:href="12859_2015_728_IEq5.gif"/></alternatives></inline-formula>
</td></tr><tr><td align="left">Benchmark extension</td><td align="left">&#x02013;</td><td align="left">
<inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\checkmark $\end{document}</tex-math><mml:math id="M12"><mml:mtext/><mml:mi>&#x02713;</mml:mi><mml:mtext/></mml:math><inline-graphic xlink:href="12859_2015_728_IEq6.gif"/></alternatives></inline-formula>
</td><td align="left">&#x02013;</td><td align="left">
<inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\checkmark $\end{document}</tex-math><mml:math id="M14"><mml:mtext/><mml:mi>&#x02713;</mml:mi><mml:mtext/></mml:math><inline-graphic xlink:href="12859_2015_728_IEq7.gif"/></alternatives></inline-formula>
</td></tr><tr><td align="left">Possibility to change parameters</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">
<inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\checkmark $\end{document}</tex-math><mml:math id="M16"><mml:mtext/><mml:mi>&#x02713;</mml:mi><mml:mtext/></mml:math><inline-graphic xlink:href="12859_2015_728_IEq8.gif"/></alternatives></inline-formula>
</td></tr></tbody></table></table-wrap>
</p></sec><sec id="Sec2"><title>Materials and methods</title><sec id="Sec3"><title>Benchmarking process</title><p>In order to provide a sound and fair comparison of the different methods, the use of various simulators is essential. A large set of gene expressions generated by various simulators is collected in what we call &#x0201c;Datasource&#x0201d; (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>).
<fig id="Fig1"><label>Fig. 1</label><caption><p>Workflow of the network evaluation process</p></caption><graphic xlink:href="12859_2015_728_Fig1_HTML" id="MO1"/></fig>
</p><p>At this stage, the data generated by the simulators is free of noise. The noise will be added later so that it is possible to control its properties independently of the simulators and also to provide fully reproducible tests. This study involves data generated by three different GRN simulators:</p><p>
<bold>GNW</bold> The GNW simulator [<xref ref-type="bibr" rid="CR3">3</xref>] generates network structures by extracting parts of known real GRN structures capturing several of their important structural properties. To produce gene expression data, the simulator relies on a system of non-linear ordinary differential equations (ODEs).</p><p>
<bold>SynTReN</bold> The SynTReN simulator [<xref ref-type="bibr" rid="CR1">1</xref>] generates the underlying networks by selecting sub-networks from <italic>E. coli</italic> and <italic>Yeast</italic> organisms. Then the experiments are obtained by simulating equations based on Michaelis-Menten and Hill kinetics under different conditions.</p><p>
<bold>Rogers</bold> The data generator described in [<xref ref-type="bibr" rid="CR10">10</xref>] that will be referred as <italic>Rogers</italic> (as in [<xref ref-type="bibr" rid="CR11">11</xref>]) relies on a power-law distribution on the number of connections of the genes to generate the underlying network. The steady state of the system is obtained by integrating a system of differential equations simulating only knockout data.</p><p>
<bold>Data generation process</bold> Using these simulators, five large datasources involving many noise-free experiments have been generated.</p><p>The characteristics of these datasources are detailed in Table <xref rid="Tab2" ref-type="table">2</xref>. In order to generate these datasources we have simulated multifactorial data with SynTReN and GNW, which provides less information than than extensive knockout, knockdown or time series experiments [<xref ref-type="bibr" rid="CR12">12</xref>]. However, multifactorial data are the most common type of expression datasets because of experimental constraints.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Datasources used in this study and their characteristics</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Datasource</th><th align="left">Name</th><th align="left">Topology</th><th align="left">Experiments</th><th align="left">Genes</th><th align="left">Edges</th></tr></thead><tbody><tr><td align="left">
<italic>R</italic>
<italic>o</italic>
<italic>g</italic>
<italic>e</italic>
<italic>r</italic>
<italic>s</italic>
<sub>1000</sub>
</td><td align="left">R1</td><td align="left">Power-law</td><td align="left">1000</td><td align="left">1000</td><td align="left">1350</td></tr><tr><td align="left"/><td align="left"/><td align="left">tail topology</td><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">
<italic>S</italic>
<italic>y</italic>
<italic>n</italic>
<italic>T</italic>
<italic>R</italic>
<italic>e</italic>
<italic>N</italic>
<sub>300</sub>
</td><td align="left">S1</td><td align="left">E. coli</td><td align="left">800</td><td align="left">300</td><td align="left">468</td></tr><tr><td align="left">
<italic>S</italic>
<italic>y</italic>
<italic>n</italic>
<italic>T</italic>
<italic>R</italic>
<italic>e</italic>
<italic>N</italic>
<sub>1000</sub>
</td><td align="left">S2</td><td align="left">E. coli</td><td align="left">1000</td><td align="left">1000</td><td align="left">4695</td></tr><tr><td align="left">
<italic>G</italic>
<italic>N</italic>
<italic>W</italic>
<sub>1565</sub>
</td><td align="left">G1</td><td align="left">E. coli</td><td align="left">1565</td><td align="left">1565</td><td align="left">7264</td></tr><tr><td align="left">
<italic>G</italic>
<italic>N</italic>
<italic>W</italic>
<sub>2000</sub>
</td><td align="left">G2</td><td align="left">Yeast</td><td align="left">2000</td><td align="left">2000</td><td align="left">10392</td></tr></tbody></table></table-wrap>
</p><p>The next step of the benchmarking process is to randomly subsample those datasources in order to generate a large set of different but homogeneous datasets. Each dataset has a different number of experiments extracted from one of the five datasources. In the design we prevent the same experiment to be used several times in the same dataset, but it can appear in different datasets (it is worth noting that because of the high number of samples provided in the datasource, the probability of many identical samples in several datasets is very low in all our tested setups). Each dataset is then contaminated with noise with a slightly different signal-to-noise ratio; this aims to reproduce the variability in the real microarray generation process within the same laboratory or between different ones. In the present study, we have chosen to add a mixture of Gaussian noise and lognormal noise to resemble to characteristics of the experimental noise observed in microarrays [<xref ref-type="bibr" rid="CR13">13</xref>]. The first noise, called &#x0201c;local&#x0201d; noise is an additive Gaussian noise with zero mean and a standard deviation (<italic>&#x003c3;</italic>
<sub><italic>L</italic><italic>o</italic><italic>c</italic><italic>a</italic><italic>l</italic>(<italic>g</italic>)</sub>) that is around a percentage (<italic>&#x003ba;</italic>
<italic>%</italic>) of the gene standard deviation (<italic>&#x003c3;</italic>
<sub><italic>g</italic></sub>). Therefore, the Signal-to-Noise-Ratio (SNR) of each gene is similar. The local noise standard deviation can be formulated as follows:
<disp-formula id="Equ1"><label>(1)</label><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \sigma_{Local(g);\kappa\%}=\sigma_{g} \frac{ \mathcal{U}(0.8\kappa,1.2\kappa)}{100},  $$ \end{document}</tex-math><mml:math id="M18"><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">Local</mml:mtext><mml:mo>(</mml:mo><mml:mi>g</mml:mi><mml:mo>)</mml:mo><mml:mo>;</mml:mo><mml:mi>&#x003ba;%</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mi mathvariant="script">U</mml:mi><mml:mo>(</mml:mo><mml:mn>0.8</mml:mn><mml:mi>&#x003ba;</mml:mi><mml:mo>,</mml:mo><mml:mn>1.2</mml:mn><mml:mi>&#x003ba;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>100</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12859_2015_728_Equ1.gif" position="anchor"/></alternatives></disp-formula>
</p><p>where <inline-formula id="IEq9"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathcal {U}(a,b)$\end{document}</tex-math><mml:math id="M20"><mml:mi mathvariant="script">U</mml:mi><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:math><inline-graphic xlink:href="12859_2015_728_IEq9.gif"/></alternatives></inline-formula> denotes the uniform distribution between <italic>a</italic> and <italic>b</italic>. This kind of noise will be referred to as local noise.</p><p>Additionally, we add an independent lognormal noise called &#x0201c;global&#x0201d; noise in the sequel. The standard deviation of this noise (<italic>&#x003c3;</italic>
<sub><italic>Global</italic></sub>) is the same for the whole dataset and is a percentage (<italic>&#x003ba;</italic>
<sub><italic>g</italic></sub>
<italic>%</italic>) of the mean variance of all the genes in the dataset (<inline-formula id="IEq10"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\overline {\sigma _{g}}$\end{document}</tex-math><mml:math id="M22"><mml:mover accent="false"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">&#x000af;</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2015_728_IEq10.gif"/></alternatives></inline-formula>). It is defined as follows:
<disp-formula id="Equ2"><label>(2)</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \sigma_{Global;\kappa_{g}\%}=\overline{\sigma_{g}} \frac{ \mathcal{U}(0.8\kappa_{g},1.2\kappa_{g})}{100}.  $$ \end{document}</tex-math><mml:math id="M24"><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">Global</mml:mtext><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003ba;</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mi>%</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mover accent="false"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo accent="true">&#x000af;</mml:mo></mml:mover><mml:mfrac><mml:mrow><mml:mi mathvariant="script">U</mml:mi><mml:mo>(</mml:mo><mml:mn>0.8</mml:mn><mml:msub><mml:mrow><mml:mi>&#x003ba;</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mn>1.2</mml:mn><mml:msub><mml:mrow><mml:mi>&#x003ba;</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>100</mml:mn></mml:mrow></mml:mfrac><mml:mi>.</mml:mi></mml:math><graphic xlink:href="12859_2015_728_Equ2.gif" position="anchor"/></alternatives></disp-formula>
</p><p>We have chosen to add a range of 40 % around <italic>&#x003ba;</italic> and <italic>&#x003ba;</italic>
<sub><italic>g</italic></sub> in order to add some variability to the different generated datasets. This range allows the various datasets to have some heterogeneity in noise but ensures at the same time that they are not too different from the originally specified values <italic>&#x003ba;</italic> and <italic>&#x003ba;</italic>
<sub><italic>g</italic></sub>. We have chosen this value to reflect our experience with real data. Nevertheless, in addition to this range (40 %), we also tested bigger and smaller ranges (60 %, 20 % and 10 %) around <italic>&#x003ba;</italic> and <italic>&#x003ba;</italic>
<sub><italic>g</italic></sub>, and the conclusions reached by the benchmark are equivalent. In Fig. <xref rid="Fig1" ref-type="fig">1</xref>, a flowchart illustrates the process. In our implementation, the various datasources have previously been generated with the in silico simulators and stored. As a result, the process is fast as no ODEs have to be computed. Moreover, this makes the reproducibility of the tests much easier, as it is not necessary to interact and parametrize the various simulators (with some of them being quite complex). Although no artificial generator is really equivalent to real data, an in silico analysis gives reliable guidelines on algorithms&#x02019; performance in line with the results obtained on real data sets [<xref ref-type="bibr" rid="CR14">14</xref>]. Additionally, the use of several different datasources coming from different simulators renders the subsequent analysis of methods more credible before any use on real data.</p><p>
<bold>Implementation in NetBenchmark package</bold> The different datasets are automatically loaded with the package, and are listed in character vector named Availabledata, which contains the names of the datasources. For each of these, we provide the simulated data and the underlying network. The former is a data.frame containing a simulated microarray experiment, where each row contains an experiment and each column contains the gene expression. The true underlying network is in the form of an adjacency matrix.</p><p>The dataset generation process is implemented in the function datasource.subsample, that returns a list with datasets.num number of elements. Each element of the list contains a data.frame of the subsampled datasource with the same number of genes and different numbers of experiments. The user could also specify the number of experiments. Moreover, the amount of local noise and global noise are controlled by parameters local.noise and global.noise, respectively. The distribution of noise with the variable noiseType that can be (&#x0201c;normal&#x0201d; or &#x0201c;lognormal&#x0201d;).</p></sec><sec id="Sec4"><title>Evaluation protocol</title><p>A network reconstruction problem can be seen as a binary decision problem. After thresholding the edge list provided by the GRN algorithm, the final decision can be seen as a classification. For each possible pair of nodes, the algorithm either infers an edge or not. As a result, we get correct connections and misclassified connections. Therefore, the performance evaluation can be done with the usual metrics of machine learning like Receiver Operating Characteristic (ROC) and Precision and Recall (PR) curves. ROC curves display the relative frequencies of true positives to false negatives for every predicted link of the edge list. Whereas the PR curves shows the relative precision (the fraction of correct predictions) versus recall (also called sensitivity) that is equivalent to the true positive ratio. These relative frequencies are also computed for every link. For a discussion of the relation between PR and ROC curves, we refer the reader to [<xref ref-type="bibr" rid="CR15">15</xref>].</p><p>Note that since the provided expression datasets do not contain temporal information, predicting self-interactions is irrelevant. Moreover, most of the state-of-the-art methods do not attempt to recover this kind of relationships. So, we do not consider self-interactions to compute those evaluation metrics.</p><p>The DREAM5 challenge [<xref ref-type="bibr" rid="CR4">4</xref>] and its previous editions [<xref ref-type="bibr" rid="CR12">12</xref>] have established a de-facto protocol to evaluate an inferred network. The protocol consists in computing the PR or ROC curves, and in measuring the Area Under the Precision Recall curve (AUPR) or Area Under ROC curve (AUROC). This approach gives an estimation of the global behavior of the method. However, other papers have evaluated the inferred networks using only the most reliable inferred connections [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR16">16</xref>].</p><p>We have adopted the latter approach, evaluating the inferred networks using only the top best <italic>x</italic> % of the total number of possible connections (if the network has <italic>G</italic> genes, then the total number of possible connections is <italic>G</italic>
<sup>2</sup>&#x02212;<italic>G</italic>). This leads to a total of <italic>t</italic> evaluated connections that will be different for each datasource.</p><p>We use as performance measures the mean precision, the AUPR and the AUROC in the top best <italic>t</italic> inferred connections. These measures could be obtained from a directed or undirected evaluation. The former evaluates the existence of an edge and its direction while the latter only evaluates the existence of an edge.</p><p>
<bold>Implementation in NetBenchmark package</bold> The evaluation is performed by the function evaluate(inf.net,true.net,sym) which compares the inferred network (inf.net) with the true underlying network (true.net). It returns the resulting confusion matrices for each threshold value. This could be obtained from a directed or undirected evaluation (specified with the logical argument sym).</p><p>
<bold>GRN inference methods</bold> In this section, we provide a brief overview of the different GRN Inference approaches: algorithms based on co-expression, information-theoretic approaches, and feature selection approaches.</p><p>We use the following notation: <italic>X</italic>
<sub><italic>i</italic></sub> denotes the expression levels of the <italic>i</italic>th gene in every experiment. It is a vector with <italic>N</italic> observations corresponding to the various experiments. Finally, the particular gene expression level of the <italic>k</italic>th experiment of the <italic>i</italic>th gene is denoted by <italic>x</italic>
<sub><italic>ik</italic></sub>.</p><p>
<bold>1) Co-expression algorithms</bold> These methods assume that similar patterns in gene expression profiles under different conditions are evidence of relationships between genes. Since the coordinated co-expression of genes encodes interacting proteins, studying co-expression patterns can provide insight into the underlying cellular processes.</p><p>Co-expression algorithms reconstruct a network by computing a similarity score for each pair of genes. The most simple co-expression method uses the correlation between genes as similarity measure. If the correlation is greater than a threshold, then the genes are connected in the graph in an undirected way (because the correlation is symmetric).</p><p>But, in practice these methods are not used for transcriptional network reconstruction because they recover indirect regulatory relationships. For example, if gene <italic>A</italic> regulates gene <italic>B</italic> and this last one regulates gene <italic>C</italic>. Co-expression algorithms will find a relationship between gene <italic>A</italic> and gene <italic>C</italic> even though it is an indirect effect. To avoid the inclusion of these indirect effects in the recovered network, a post-processing step should be carried on.</p><p>
<bold>GeneNet</bold> In [<xref ref-type="bibr" rid="CR17">17</xref>], the authors propose a heuristic for statistically learning a causal network. It relies on the conversion of a network inferred through correlation into a partial correlation graph. Then, a partial ordering of the nodes is assigned by means of a multiple testing of the log-ratio of standardized partial variances. This allows identifying a directed acyclic causal network as a sub-graph of the partial correlation network.</p><p>
<bold>MutRank</bold> MutRank [<xref ref-type="bibr" rid="CR18">18</xref>] ranks the correlation between every pair of genes and this rank is taken as the score that describes the similarity between genes. For every gene <italic>i</italic>, the Pearson&#x02019;s correlation (corr) with all other genes <italic>l</italic> is computed and ranked:
<disp-formula id="Equ3"><label>(3)</label><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ r_{ij} = \operatorname*{\,rank}_{j} (\operatorname*{\,corr} (X_{i},X_{l}),\forall i \ne l).  $$ \end{document}</tex-math><mml:math id="M26"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>rank</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mo>corr</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mo>&#x02200;</mml:mo><mml:mi>i</mml:mi><mml:mo>&#x02260;</mml:mo><mml:mi>l</mml:mi><mml:mo>)</mml:mo><mml:mi>.</mml:mi></mml:math><graphic xlink:href="12859_2015_728_Equ3.gif" position="anchor"/></alternatives></disp-formula>
</p><p>As this expression is not symmetric, the final confidence score assigned between genes <italic>i</italic> and <italic>j</italic> is computed as the geometric mean of the scores obtained between gene <italic>i</italic> and <italic>j</italic> and vice versa:
<disp-formula id="Equ4"><label>(4)</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ s_{ij}=\frac{r_{ij}\cdot r_{ji}}{2}.  $$ \end{document}</tex-math><mml:math id="M28"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ji</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mi>.</mml:mi></mml:math><graphic xlink:href="12859_2015_728_Equ4.gif" position="anchor"/></alternatives></disp-formula>
</p><p>
<bold>Zscore</bold> Zscore [<xref ref-type="bibr" rid="CR19">19</xref>] is a method that assumes interventional data, more concretely knockout experiments that lead to a change in other genes. The assumption is that the knocked-out gene <italic>i</italic> in the experiment <italic>k</italic> affects more strongly the genes that it regulates than the others. The effect of the gene <italic>i</italic> over gene <italic>j</italic> is captured with the Zscore <italic>z</italic>
<sub><italic>ij</italic></sub>:
<disp-formula id="Equ5"><label>(5)</label><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$  z_{ij}=\left|\frac{x_{jk}-\mu_{X_{j}}}{\sigma_{X_{j}}}\right|,  $$ \end{document}</tex-math><mml:math id="M30"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="|" open="|" separators=""><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">jk</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12859_2015_728_Equ5.gif" position="anchor"/></alternatives></disp-formula>
</p><p>assuming that the <italic>k</italic>th experiment is a knockout of gene <italic>i</italic>, <inline-formula id="IEq11"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mu _{X_{j}}$\end{document}</tex-math><mml:math id="M32"><mml:msub><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2015_728_IEq11.gif"/></alternatives></inline-formula> and <inline-formula id="IEq12"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\sigma _{X_{j}}$\end{document}</tex-math><mml:math id="M34"><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2015_728_IEq12.gif"/></alternatives></inline-formula> are respectively the mean and standard deviation of the empirical distribution of the gene <italic>j</italic>. To apply the original method, one needs to know which knockouts are done in each experiment. However, in practice, one can assume that the knocked-out gene is the one corresponding to the minimum value in the experiment <italic>k</italic>: arg min<sub><italic>l</italic></sub>(<italic>x</italic>
<sub><italic>lk</italic></sub>)=<italic>i</italic>. With this generalization, the method can be applied to any type of data like multifactorial or knockdown data. If the same gene is detected to be knocked-out in various experiments, then the final Zscore is the mean of the individual Zscore values.</p><p>
<bold>2) Information-theoretic approaches</bold> These approaches use a generalization of the pairwise correlation coefficient that is called mutual information (<italic>M</italic>
<sub><italic>ij</italic></sub>) [<xref ref-type="bibr" rid="CR20">20</xref>]. It measures the degree of dependence between two genes <italic>X</italic>
<sub><italic>i</italic></sub> and <italic>X</italic>
<sub><italic>j</italic></sub>.
<disp-formula id="Equ6"><label>(6)</label><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ M_{ij}=\sum_{X_{i}}\sum_{X_{j}} p(X_{i},X_{j}) \log_{2} \frac{p(X_{i},X_{j})}{p(X_{i})p(X_{j})},  $$ \end{document}</tex-math><mml:math id="M36"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:munder><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:munder><mml:mrow><mml:mo>log</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12859_2015_728_Equ6.gif" position="anchor"/></alternatives></disp-formula>
</p><p>where <italic>p</italic>(<italic>X</italic>
<sub><italic>i</italic></sub>,<italic>X</italic>
<sub><italic>j</italic></sub>) is the joint probability distribution function of <italic>X</italic>
<sub><italic>i</italic></sub> and <italic>X</italic>
<sub><italic>j</italic></sub>, and <italic>p</italic>(<italic>X</italic>
<sub><italic>i</italic></sub>) and <italic>p</italic>(<italic>X</italic>
<sub><italic>j</italic></sub>) are the marginal probability distribution functions of <italic>X</italic>
<sub><italic>i</italic></sub> and <italic>X</italic>
<sub><italic>j</italic></sub> respectively [<xref ref-type="bibr" rid="CR20">20</xref>].</p><p>
<bold>Relevance network</bold> The RELNET [<xref ref-type="bibr" rid="CR21">21</xref>] is the simplest method based on mutual information. For each pair of genes, the mutual information <italic>M</italic>
<sub><italic>ij</italic></sub> is estimated and the edge between genes <italic>i</italic> and <italic>j</italic> is created if the mutual information is above a threshold. Despite that mutual information is more general than the Pearson correlation coefficient, in practice thresholding the <italic>M</italic>
<sub><italic>ij</italic></sub> or Pearson correlation produces similar results [<xref ref-type="bibr" rid="CR22">22</xref>].</p><p>
<bold>CLR</bold> The Context Likelihood or Relatedness network (CLR) method [<xref ref-type="bibr" rid="CR9">9</xref>] is an extension of the previous method. The method derives a score that is associated to the empirical distribution of the mutual information values. In practice, the score between gene <italic>i</italic> and gene <italic>j</italic> is defined as follows:
<disp-formula id="Equ7"><label>(7)</label><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \begin{aligned} c_{ij} &#x00026;=\sqrt{{c^{2}_{i}}+{c^{2}_{j}}}, \, \, \text{with} \, \, c_{i} =\max \left(0,\frac{M_{ij}-\mu_{M_{i}}}{\sigma_{M_{i}}} \right) \, \, \text{and} \, \,\\ c_{j} &#x00026;=\max \left(0,\frac{M_{ji}-\mu_{M_{j}}}{\sigma_{M_{j}}} \right). \end{aligned}  $$ \end{document}</tex-math><mml:math id="M38"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:msqrt><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mspace width="0.3em"/><mml:mtext>with</mml:mtext><mml:mspace width="0.3em"/><mml:mspace width="0.3em"/><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>max</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mspace width="0.3em"/><mml:mspace width="0.3em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.3em"/><mml:mspace width="0.3em"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mo>max</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ji</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mi>.</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2015_728_Equ7.gif" position="anchor"/></alternatives></disp-formula>
</p><p>The mean and standard deviation of the empirical distribution of the mutual information between both genes are denoted by <inline-formula id="IEq13"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mu _{M_{i}}$\end{document}</tex-math><mml:math id="M40"><mml:msub><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2015_728_IEq13.gif"/></alternatives></inline-formula> and <inline-formula id="IEq14"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\sigma _{M_{i}}$\end{document}</tex-math><mml:math id="M42"><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2015_728_IEq14.gif"/></alternatives></inline-formula>, which are defined as:
<disp-formula id="Equ8"><label>(8)</label><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$  \mu_{M_{i}} =\frac{1}{G} \sum_{l=1}^{G} M_{il},\quad \sigma_{M_{i}} =\sqrt{\frac{1}{G-1} \sum_{l=1}^{G} (M_{il}-\mu_{M_{i}})^{2}} \,\,.  $$ \end{document}</tex-math><mml:math id="M44"><mml:mspace width="-5.0pt"/><mml:msub><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">il</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">il</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msqrt><mml:mspace width="0.3em"/><mml:mspace width="0.3em"/><mml:mi>.</mml:mi></mml:math><graphic xlink:href="12859_2015_728_Equ8.gif" position="anchor"/></alternatives></disp-formula>
</p><p>This process can be seen as a normalization of the mutual information [<xref ref-type="bibr" rid="CR23">23</xref>].</p><p>
<bold>ARACNE</bold> The motivation of the Algorithm for the Reconstruction of Accurate Cellular NEtworks (ARACNE) [<xref ref-type="bibr" rid="CR24">24</xref>] is that many similar measures between variables may be the result of indirect effects. In order to avoid the indirect effect, the algorithm relies on the &#x0201c;Data Processing Inequality&#x0201d; (DPI) which removes the weakest edge, that is the one with the lowest mutual information, in every triplet of genes.</p><p>
<bold>PCIT</bold> The Partial Correlation coefficient with Information Theory (PCIT) [<xref ref-type="bibr" rid="CR25">25</xref>] algorithm combines the concept of partial correlation coefficient with information theory to identify significant gene-to-gene associations.</p><p>Similarly to ARACNE, PCIT extracts all possible interaction triangles and applies DPI to filter indirect connections, but instead of mutual information it uses first-order partial correlation as interaction weights. The partial correlation tries to eliminate the effect of a third gene <italic>l</italic> on the correlation of genes <italic>i</italic> and <italic>j</italic>.</p><p>
<bold>C3NET</bold> The Conservative Causal Core NETwork (C3NET) [<xref ref-type="bibr" rid="CR26">26</xref>] consists of two main steps. In the first step pairwise mutual information is computed. Then, non-significant connections are eliminated, according to a chosen significance level <italic>&#x003b1;</italic>, between gene pairs. But the main difference is the second step, where only the most significant edge for each gene is selected. This edge corresponds also to the highest mutual information value among the neighboring connections for each gene.</p><p>The consequence of the second step is that the highest possible number of connections that can be reconstructed by C3NET is equal to the number of genes under consideration. C3NET does not aim at reconstructing the entire network underlying gene regulation but mainly tries to recover the core structure.</p><p>
<bold>3) Feature selection approaches</bold> A GRN reconstruction problem can also be seen as a feature selection problem. For every gene, the goal is to discover its true regulators among all other genes or candidate regulators. This approach can integrate knowledge about genes that are not TFs and therefore reduce the search space.</p><p>Typically, this approach only focuses on designing a significance score <italic>s</italic>(<italic>i</italic>,<italic>j</italic>) that leads to a good ranking of the candidate regulations, such that true regulations tend to be at the top of the list since an edge is assigned between <italic>i</italic> and <italic>j</italic> if the evidence <italic>s</italic>(<italic>i</italic>,<italic>j</italic>) is larger than a threshold.</p><p>With the feature selection approach, the scores <italic>s</italic>(<italic>i</italic>,<italic>j</italic>) for all the genes are jointly estimated with a method that is able to capture the fact that a large score for a link (<italic>i</italic>,<italic>j</italic>) is not needed if the apparent relationship between <italic>i</italic> and <italic>j</italic> is already explained by another and more likely regulation.</p><p>
<bold>MRNET</bold> The Minimum Redundancy NETworks (MRNET) [<xref ref-type="bibr" rid="CR27">27</xref>] method reconstructs a network using the feature selection technique known as Minimum Redundancy Maximum Relevance (MRMR) [<xref ref-type="bibr" rid="CR28">28</xref>], which is based on a mutual information measure. In order to get a network, the algorithm performs a feature selection for each gene (<italic>i</italic>&#x02208; [1,<italic>G</italic>]) on the set of remaining genes (<italic>j</italic>&#x02208; [1,<italic>G</italic>]&#x02216;<italic>i</italic>).</p><p>The MRMR procedure returns a ranked list of features that maximize the mutual information with the target gene (maximum relevance) and, at the same time, such that the selected genes are mutually dissimilar (minimum redundancy). For every gene, the MRMR feature selection provides a score of potential connections where the higher scores should correspond to direct interactions. The indirect interactions should have a lower scores because they are redundant with the direct ones. Then, a threshold is computed as in the RELNET method.</p><p>The MRNET reconstructs a network using a forward selection strategy, which leads to subset selection that is strongly conditioned by the first selected variables. The Minimum Redundancy NETworks using Backward elimination (MRNETB), uses instead a backward selection strategy followed by a sequential replacement [<xref ref-type="bibr" rid="CR29">29</xref>].</p><p>
<bold>Genie3</bold> The GEne Network Inference with Ensemble of trees (Genie3) [<xref ref-type="bibr" rid="CR30">30</xref>] algorithm uses the random forests [<xref ref-type="bibr" rid="CR31">31</xref>] feature selection technique to solve a regression problem for each of the genes in the network. In each of the regression problems, the expression pattern of the target gene should be predicted from the expression patterns of all transcription factors.</p><p>The importance of each transcription factor in the prediction of the target gene is taken as an indication of an apparent regulatory edge. Then these candidate regulatory connections are aggregated over all genes to generate a ranking for the whole network.</p><p>
<bold>How to benchmark a method</bold> These previously presented methods are implemented or imported with the package. We have developed a wrapper with the with the parameters recommended in the original publications of each method. The only exception is the Genie3, for which we reduced the number of trees from 1000 to 500 in order to limit the computation time required for this method. Table <xref rid="Tab3" ref-type="table">3</xref> shows the computation time in seconds needed by the various methods for each datasource. The names of the wrappers of the GRN inference algorithms that are currently available are listed in Table <xref rid="Tab4" ref-type="table">4</xref>.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Evaluation of the computational complexity. Mean CPU time in seconds of each reconstruction method on the different datasources in a 2 x Intel Xeon E5 2670 8C (2.6 GHz)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Datasource</th><th align="left">ARACNE</th><th align="left">C3NET</th><th align="left">CLR</th><th align="left">GeneNet</th><th align="left">Genie3</th><th align="left">MRNET</th><th align="left">MutRank</th><th align="left">MRNETB</th><th align="left">PCIT</th><th align="left">Zscore</th></tr></thead><tbody><tr><td align="left">R1</td><td align="left">2.483</td><td align="left">2.367</td><td align="left">0.409</td><td align="left">9.377</td><td align="left">1310.486</td><td align="left">7.200</td><td align="left">0.638</td><td align="left">11.195</td><td align="left">11.352</td><td align="left">0.086</td></tr><tr><td align="left">S1</td><td align="left">0.106</td><td align="left">0.215</td><td align="left">0.059</td><td align="left">0.917</td><td align="left">183.266</td><td align="left">0.120</td><td align="left">0.056</td><td align="left">0.406</td><td align="left">0.333</td><td align="left">0.010</td></tr><tr><td align="left">S2</td><td align="left">1.775</td><td align="left">1.904</td><td align="left">0.349</td><td align="left">9.504</td><td align="left">950.648</td><td align="left">7.101</td><td align="left">0.585</td><td align="left">10.907</td><td align="left">10.898</td><td align="left">0.091</td></tr><tr><td align="left">G1</td><td align="left">10.442</td><td align="left">6.795</td><td align="left">1.079</td><td align="left">29.612</td><td align="left">2839.319</td><td align="left">31.385</td><td align="left">1.865</td><td align="left">46.255</td><td align="left">47.106</td><td align="left">0.260</td></tr><tr><td align="left">G2</td><td align="left">25.551</td><td align="left">12.189</td><td align="left">1.750</td><td align="left">53.792</td><td align="left">4115.408</td><td align="left">60.143</td><td align="left">3.431</td><td align="left">100.375</td><td align="left">103.085</td><td align="left">0.418</td></tr></tbody></table></table-wrap>
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Included GRN algorithms. GRN algorithms included in the current version (1.0) of the netbenchmark Bioconductor package</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">GRN Algorithms</th><th align="left">Wrapper function</th></tr></thead><tbody><tr><td align="left">ARACNE [<xref ref-type="bibr" rid="CR24">24</xref>]</td><td align="left">
aracne.wrap
</td></tr><tr><td align="left">C3NET [<xref ref-type="bibr" rid="CR26">26</xref>]</td><td align="left">
c3net.wrap
</td></tr><tr><td align="left">CLR [<xref ref-type="bibr" rid="CR9">9</xref>]</td><td align="left">
clr.wrap
</td></tr><tr><td align="left">GeneNet [<xref ref-type="bibr" rid="CR17">17</xref>]</td><td align="left">
genenet.wrap
</td></tr><tr><td align="left">Genie3 [<xref ref-type="bibr" rid="CR30">30</xref>]</td><td align="left">
genie3.wrap
</td></tr><tr><td align="left">MutRank [<xref ref-type="bibr" rid="CR18">18</xref>]</td><td align="left">
mutrank.wrap
</td></tr><tr><td align="left">MRNET/B [<xref ref-type="bibr" rid="CR27">27</xref>, <xref ref-type="bibr" rid="CR29">29</xref>]</td><td align="left">
mrnet.wrap &#x00026; mrnetb.wrap
</td></tr><tr><td align="left">PCIT [<xref ref-type="bibr" rid="CR25">25</xref>]</td><td align="left">
pcit.wrap
</td></tr><tr><td align="left">Zscore [<xref ref-type="bibr" rid="CR19">19</xref>]</td><td align="left">
zscore.wrap
</td></tr></tbody></table></table-wrap>
</p><p>The package allows the user to reproduce as well as to modify the experiments reported in this paper. However, an important additional functionality is that it also allows new methods to be evaluated. In the current version of the netbenchmark package (1.0), it is possible to evaluate new unsupervised network inference methods. The method should infer the network from steady-state expression data, and should be able to perform this task with a number of experiments much lower than the number of genes. The last requirement is that the provided method is and be able to infer networks with thousands of genes. In order to benchmark a new method, a new wrapper has to be defined: fun(data). This function receives a numeric data.frame with the gene expression data in the argument data where the columns contain the genes and the rows the experiments. The function should return a matrix which is the weighted adjacency matrix of the network inferred by the algorithm. In order to benchmark this method against all the other algorithms of the package the following procedure should be followed:</p><p>
<graphic xlink:href="12859_2015_728_Figa_HTML.gif" id="MO2"/>
</p><p>For more information on this topic, we refer the interested reader to the vignette of the package where an example is provided.</p></sec></sec><sec id="Sec5"><title>Implementation</title><p>NetBenchmark is a Bioconductor [<xref ref-type="bibr" rid="CR32">32</xref>] package. As a results, the code is written primarily in R [*]. However, time-critical functions are written in C++ for greater speed. The package imports several CRAN and Bioconductor packages. Most of those provide competitive network inference methods that are used in our benchmark. The pipeline starts with a set of noise-free datasources coming from different GRN simulators that have been pregenerated for this package. The datasources are stored in grndata package [**] and are loaded automatically as input. These datasources are subsampled and contaminated with noise in order to generate datasets with enough variability to provide an informative and thorough comparison of GRN inference methods. This benchmarking process is detailed throughout the subsequents sections of the paper. A helper vignette and a webpage (see &#x0201c; Availability and requirements &#x0201d;) are also provided in order to unlock the full set of functionalities of the package including the ability of adding new methods in the benchmark.</p><p>[*] R Core Team: R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria (2015). R Foundation for Statistical Computing. <ext-link ext-link-type="uri" xlink:href="https://www.R-project.org">https://www.R-project.org</ext-link>.</p><p>[**] Bellot, P., Olsen, C., Meyer, P.E.: grndata: Synthetic Expression Data for Gene Regulatory Network Inference. (2014). R package version 1.0.0.</p></sec><sec id="Sec6" sec-type="results"><title>Results</title><p>In this section, we present the results of the benchmark with the presented methodology and obtained with version 1.0 of the package (see &#x0201c; Availability and requirements &#x0201d;). For each datasource of Table <xref rid="Tab2" ref-type="table">2</xref>, we generate ten datasets with around 150 experiments. We aim to reproduce common real microarray datasets that are typically constituted of much less experiments than genes. As explained in section &#x0201c;<xref rid="Sec3" ref-type="sec">Benchmarking process</xref>&#x0201d;, we add two different types of noise: local and global. We perform a benchmark of the methods listed in Table <xref rid="Tab4" ref-type="table">4</xref> adding local Gaussian noise around 20 % of the standard deviation (<italic>&#x003c3;</italic>
<sub><italic>L</italic><italic>o</italic><italic>c</italic><italic>a</italic><italic>l</italic>(<italic>g</italic>);20 <italic>%</italic></sub>, see Eq. <xref rid="Equ1" ref-type="">1</xref>) and global lognormal noise around 10 % (<italic>&#x003c3;</italic>
<sub><italic>G</italic><italic>l</italic><italic>o</italic><italic>b</italic><italic>a</italic><italic>l</italic>;10 <italic>%</italic></sub>, see Eq <xref rid="Equ2" ref-type="">2</xref>). Additionally to this benchmark, we also analyze the different algorithms according to two different aspects: the impact of the noise and the influence of the number of experiments included in the datasets.</p><p>Table <xref rid="Tab5" ref-type="table">5</xref> presents the Area Under Precision Recall curve obtained in an undirected evaluation on the top 20 % (<italic>A</italic>
<italic>U</italic>
<italic>P</italic>
<italic>R</italic>
<sub>20 <italic>%</italic></sub>) of the total possible connections for each datasource. The table also gives the mean and variance across the 10 different datasets.
<table-wrap id="Tab5"><label>Table 5</label><caption><p>Performances of the various GRN inference methods on the datasources. AUPR in the top 20 % of the possible connections with a undirected evaluation for each GRN inference method on the different datasources of the benchmark with a 20 % local Gaussian noise and 10 % of global lognormal noise. The best statistically significant results tested with a Wilcoxon test are highlighted for each datasource. Results obtained with current version (1.0) of the package and are updated online</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="2">Datasource</th><th align="left">ARACNE</th><th align="left">C3NET</th><th align="left">CLR</th><th align="left">GeneNet</th><th align="left">Genie3</th><th align="left">MRNET</th><th align="left">MutRank</th><th align="left">MRNETB</th><th align="left">PCIT</th><th align="left">Zscore</th><th align="left">Random</th></tr></thead><tbody><tr><td align="left">R1</td><td align="left">mean</td><td align="left">0.004</td><td align="left">0.002</td><td align="left">0.005</td><td align="left">0.140</td><td align="left">0.024</td><td align="left">0.005</td><td align="left">0.042</td><td align="left">0.005</td><td align="left">
<bold>0.177</bold>
</td><td align="left">0.140</td><td align="left">&#x0003c;0.001</td></tr><tr><td align="left"/><td align="left">
<italic>&#x003c3;</italic>(&#x000d7;10<sup>&#x02212;3</sup>)</td><td align="left">1.1</td><td align="left">0.789</td><td align="left">1.22</td><td align="left">16</td><td align="left">2.97</td><td align="left">1.26</td><td align="left">7.27</td><td align="left">1.26</td><td align="left">16.1</td><td align="left">13.6</td><td align="left">0.0265</td></tr><tr><td align="left">S1</td><td align="left">mean</td><td align="left">0.039</td><td align="left">0.032</td><td align="left">0.139</td><td align="left">0.062</td><td align="left">0.134</td><td align="left">0.109</td><td align="left">0.063</td><td align="left">0.118</td><td align="left">0.060</td><td align="left">0.028</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">
<italic>&#x003c3;</italic>(&#x000d7;10<sup>&#x02212;3</sup>)</td><td align="left">8.02</td><td align="left">7.92</td><td align="left">1.98</td><td align="left">8.25</td><td align="left">3.51</td><td align="left">9.45</td><td align="left">2.25</td><td align="left">5.83</td><td align="left">1.44</td><td align="left">13.8</td><td align="left">0.211</td></tr><tr><td align="left">S2</td><td align="left">mean</td><td align="left">0.006</td><td align="left">0.006</td><td align="left">0.042</td><td align="left">0.013</td><td align="left">0.036</td><td align="left">0.021</td><td align="left">0.021</td><td align="left">0.021</td><td align="left">0.01</td><td align="left">0.003</td><td align="left">&#x0003c;0.001</td></tr><tr><td align="left"/><td align="left">
<italic>&#x003c3;</italic>(&#x000d7;10<sup>&#x02212;3</sup>)</td><td align="left">1.19</td><td align="left">1.63</td><td align="left">1.55</td><td align="left">1.56</td><td align="left">1</td><td align="left">2.76</td><td align="left">0.959</td><td align="left">2.01</td><td align="left">0.522</td><td align="left">1.46</td><td align="left">0.1</td></tr><tr><td align="left">G1</td><td align="left">mean</td><td align="left">0.106</td><td align="left">0.100</td><td align="left">
<bold>0.139</bold>
</td><td align="left">0.085</td><td align="left">0.108</td><td align="left">
<bold>0.134</bold>
</td><td align="left">0.034</td><td align="left">0.084</td><td align="left">0.063</td><td align="left">0.001</td><td align="left">&#x0003c;0.001</td></tr><tr><td align="left"/><td align="left">
<italic>&#x003c3;</italic>(&#x000d7;10<sup>&#x02212;3</sup>)</td><td align="left">7.46</td><td align="left">7.58</td><td align="left">7.83</td><td align="left">2.91</td><td align="left">6.66</td><td align="left">9.48</td><td align="left">2.26</td><td align="left">3.27</td><td align="left">2.69</td><td align="left">0.15</td><td align="left">0.0141</td></tr><tr><td align="left">G2</td><td align="left">mean</td><td align="left">0.101</td><td align="left">0.095</td><td align="left">0.106</td><td align="left">0.037</td><td align="left">0.069</td><td align="left">
<bold>0.126</bold>
</td><td align="left">0.025</td><td align="left">0.058</td><td align="left">0.044</td><td align="left">&#x0003c;0.001</td><td align="left">&#x0003c;0.001</td></tr><tr><td align="left"/><td align="left">
<italic>&#x003c3;</italic>(&#x000d7;10<sup>&#x02212;3</sup>)</td><td align="left">11.4</td><td align="left">9.95</td><td align="left">4.49</td><td align="left">1.62</td><td align="left">3.44</td><td align="left">9.49</td><td align="left">1.43</td><td align="left">2.23</td><td align="left">2.16</td><td align="left">0.0917</td><td align="left">0.0265</td></tr></tbody></table><table-wrap-foot><p>p &#x0003c; 0.05</p></table-wrap-foot></table-wrap>
</p><p>In order to assess the statistical significance of the results, we perform a Wilcoxon Rank sum test with Bonferroni correction [<xref ref-type="bibr" rid="CR33">33</xref>] on <italic>A</italic>
<italic>U</italic>
<italic>P</italic>
<italic>R</italic>
<sub>20 <italic>%</italic></sub> values for each datasource. Then, the best result is highlighted in bold if its metric is statistically different from the remaining values. Note that several results may be highlighted for the same datasource if they are not statistically different from each other.</p><p>In order to assess the overall behavior of each technique, we need to aggregate the different performances obtained on the different datasources. But as can be seen in Table <xref rid="Tab5" ref-type="table">5</xref>, the <italic>A</italic>
<italic>U</italic>
<italic>P</italic>
<italic>R</italic>
<sub>20 <italic>%</italic></sub> values have different ranges for each datasource. Therefore, instead of aggregating <italic>A</italic>
<italic>U</italic>
<italic>P</italic>
<italic>R</italic>
<sub>20 <italic>%</italic></sub> values, we aggregate the rank of each method, the smaller the rank the better the algorithm. Figure <xref rid="Fig2" ref-type="fig">2</xref> presents a boxplot of the rank of the different algorithms across all datasources. For more information on the boxplot, we refer the reader to [<xref ref-type="bibr" rid="CR34">34</xref>].
<fig id="Fig2"><label>Fig. 2</label><caption><p>Boxplots of performance. Each box represents the statistics of a method with the ranking performance across all datasources, the smaller the rank the better. The white dot represents the median of the distribution, the box goes form the first to third quartile, while whiskers are lines drawn from the ends of the box to the maximum and minimum of the data excluding outliers that are represented with a mark outside the whiskers</p></caption><graphic xlink:href="12859_2015_728_Fig2_HTML" id="MO3"/></fig>
</p><p>Additionally, Table <xref rid="Tab3" ref-type="table">3</xref> shows the time needed by the various methods for each datasource (in seconds). This information allows to estimate the scalability of each method.</p><p>
<bold>Implementation in NetBenchmark package</bold> In order to generate these results we use the main function netbenchmark. In listing ?? we present the different commands used in the netbenchmark function to generate the previously presented results, note that the random seed could be used to compare a new method on the same data than those used in the present study. Results are also available at online (see Project home page in section &#x0201c;Availability and requirements &#x0201d;) where the results of the benchmark will be updated (with most recent version of the package) with new methods or updates of the presented algorithms.</p><sec id="Sec7"><title>Noise sensitivity</title><p>Here we present a procedure in order to test the stability of the different algorithms in the presence of local Gaussian noise. To do so, we use all datasources in Table <xref rid="Tab2" ref-type="table">2</xref> increasing gradually the local noise intensity (increasing <italic>&#x003ba;</italic> value of <italic>&#x003c3;</italic>
<sub><italic>n</italic>;<italic>&#x003ba;</italic><italic>%</italic></sub>), therefore decreasing the SNR. In this study we also use subsampled datasources of 150 experiments in order to derive the effect of noise on the various GRN reconstruction methods and being able to compare them with the results obtained at the previous study. In Table <xref rid="Tab6" ref-type="table">6</xref> we present the mean values of the AUPR in an undirected evaluation on the top 20 % of the total possible connections at each dataset. For each <italic>&#x003c3;</italic>
<sub><italic>n</italic>;<italic>&#x003ba;</italic><italic>%</italic></sub> value, we perform ten different trials and the performance metrics (<italic>A</italic>
<italic>U</italic>
<italic>P</italic>
<italic>R</italic>
<sub>20 <italic>%</italic></sub>) are the average of the different trials. In Fig. <xref rid="Fig3" ref-type="fig">3</xref> the results of the datasources that have around 1000 genes are presented.
<fig id="Fig3"><label>Fig. 3</label><caption><p>Plots of performance with different noise intensities. Each line represents a method (color coded), the mean performance over the ten runs is presented</p></caption><graphic xlink:href="12859_2015_728_Fig3_HTML" id="MO4"/></fig>
<table-wrap id="Tab6"><label>Table 6</label><caption><p>Results of the study on noise sensitivity. Mean AUPR in the top 20 % of the possible connetions with a undirected evaluation with respect to intensity (<italic>&#x003ba;</italic>
<italic>%</italic>) of Gaussian local noise (<italic>&#x003c3;</italic>
<sub><italic>L</italic><italic>o</italic><italic>c</italic><italic>a</italic><italic>l</italic>(<italic>g</italic>);<italic>&#x003ba;</italic><italic>%</italic></sub>). The best results are highlighted. Results obtained with current version (1.0) of the package and are updated online</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Datasource</th><th align="left">
<italic>&#x003ba;</italic>
</th><th align="left">ARACNE</th><th align="left">C3NET</th><th align="left">CLR</th><th align="left">GeneNet</th><th align="left">Genie3</th><th align="left">MRNET</th><th align="left">MutRank</th><th align="left">MRNETB</th><th align="left">PCIT</th><th align="left">Zscore</th><th align="left">Random</th></tr></thead><tbody><tr><td align="left">R1</td><td align="left">0</td><td align="left">0.008</td><td align="left">0.004</td><td align="left">0.010</td><td align="left">0.140</td><td align="left">0.025</td><td align="left">0.010</td><td align="left">0.040</td><td align="left">0.010</td><td align="left">
<bold>0.174</bold>
</td><td align="left">0.133</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">25</td><td align="left">0.004</td><td align="left">0.002</td><td align="left">0.006</td><td align="left">0.134</td><td align="left">0.022</td><td align="left">0.006</td><td align="left">0.038</td><td align="left">0.005</td><td align="left">0.167</td><td align="left">0.132</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">50</td><td align="left">0.002</td><td align="left">0.001</td><td align="left">0.003</td><td align="left">0.121</td><td align="left">0.020</td><td align="left">0.003</td><td align="left">0.031</td><td align="left">0.003</td><td align="left">0.150</td><td align="left">0.130</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">75</td><td align="left">0.001</td><td align="left">0.001</td><td align="left">0.002</td><td align="left">0.086</td><td align="left">0.018</td><td align="left">0.002</td><td align="left">0.025</td><td align="left">0.002</td><td align="left">0.126</td><td align="left">
<bold>0.127</bold>
</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">100</td><td align="left">0.001</td><td align="left">0.001</td><td align="left">0.001</td><td align="left">0.006</td><td align="left">0.015</td><td align="left">0.001</td><td align="left">0.017</td><td align="left">0.001</td><td align="left">0.097</td><td align="left">
<bold>0.125</bold>
</td><td align="left">0.001</td></tr><tr><td align="left">S1</td><td align="left">0</td><td align="left">0.091</td><td align="left">0.140</td><td align="left">0.132</td><td align="left">0.114</td><td align="left">0.137</td><td align="left">0.199</td><td align="left">0.060</td><td align="left">0.120</td><td align="left">0.023</td><td align="left">0.072</td><td align="left">0.002</td></tr><tr><td align="left"/><td align="left">25</td><td align="left">0.040</td><td align="left">0.033</td><td align="left">
<bold>0.140</bold>
</td><td align="left">0.059</td><td align="left">0.133</td><td align="left">0.112</td><td align="left">0.062</td><td align="left">0.126</td><td align="left">0.059</td><td align="left">0.035</td><td align="left">0.002</td></tr><tr><td align="left"/><td align="left">50</td><td align="left">0.027</td><td align="left">0.021</td><td align="left">
<bold>0.139</bold>
</td><td align="left">0.031</td><td align="left">0.121</td><td align="left">0.097</td><td align="left">0.067</td><td align="left">0.121</td><td align="left">0.066</td><td align="left">0.022</td><td align="left">0.002</td></tr><tr><td align="left"/><td align="left">75</td><td align="left">0.021</td><td align="left">0.014</td><td align="left">
<bold>0.126</bold>
</td><td align="left">0.024</td><td align="left">0.104</td><td align="left">0.076</td><td align="left">0.066</td><td align="left">0.098</td><td align="left">0.063</td><td align="left">0.011</td><td align="left">0.003</td></tr><tr><td align="left"/><td align="left">100</td><td align="left">0.023</td><td align="left">0.017</td><td align="left">
<bold>0.119</bold>
</td><td align="left">0.013</td><td align="left">0.095</td><td align="left">0.072</td><td align="left">0.066</td><td align="left">0.089</td><td align="left">0.063</td><td align="left">0.010</td><td align="left">0.001</td></tr><tr><td align="left">S2</td><td align="left">0</td><td align="left">0.014</td><td align="left">0.039</td><td align="left">0.046</td><td align="left">0.025</td><td align="left">0.044</td><td align="left">0.060</td><td align="left">0.021</td><td align="left">0.039</td><td align="left">0.008</td><td align="left">0.001</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">25</td><td align="left">0.006</td><td align="left">0.006</td><td align="left">
<bold>0.044</bold>
</td><td align="left">0.020</td><td align="left">0.038</td><td align="left">0.022</td><td align="left">0.021</td><td align="left">0.028</td><td align="left">0.012</td><td align="left">0.005</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">50</td><td align="left">0.004</td><td align="left">0.003</td><td align="left">0.044</td><td align="left">0.016</td><td align="left">0.033</td><td align="left">0.016</td><td align="left">0.020</td><td align="left">0.026</td><td align="left">0.012</td><td align="left">0.002</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">75</td><td align="left">0.003</td><td align="left">0.002</td><td align="left">
<bold>0.040</bold>
</td><td align="left">0.012</td><td align="left">0.028</td><td align="left">0.013</td><td align="left">0.019</td><td align="left">0.021</td><td align="left">0.011</td><td align="left">0.002</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">100</td><td align="left">0.003</td><td align="left">0.002</td><td align="left">
<bold>0.034</bold>
</td><td align="left">0.008</td><td align="left">0.022</td><td align="left">0.011</td><td align="left">0.017</td><td align="left">0.015</td><td align="left">0.010</td><td align="left">0.001</td><td align="left">0.001</td></tr><tr><td align="left">G1</td><td align="left">0</td><td align="left">0.195</td><td align="left">0.145</td><td align="left">0.199</td><td align="left">0.084</td><td align="left">0.129</td><td align="left">0.218</td><td align="left">0.036</td><td align="left">0.111</td><td align="left">0.061</td><td align="left">0.001</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">25</td><td align="left">0.113</td><td align="left">0.107</td><td align="left">
<bold>0.144</bold>
</td><td align="left">0.082</td><td align="left">0.111</td><td align="left">0.142</td><td align="left">0.035</td><td align="left">0.086</td><td align="left">0.060</td><td align="left">&#x0003c;0.001</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">50</td><td align="left">0.069</td><td align="left">0.065</td><td align="left">
<bold>0.115</bold>
</td><td align="left">0.074</td><td align="left">0.091</td><td align="left">0.096</td><td align="left">0.031</td><td align="left">0.073</td><td align="left">0.057</td><td align="left">0.001</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">75</td><td align="left">0.041</td><td align="left">0.038</td><td align="left">
<bold>0.082</bold>
</td><td align="left">0.055</td><td align="left">0.068</td><td align="left">0.061</td><td align="left">0.024</td><td align="left">0.059</td><td align="left">0.049</td><td align="left">&#x0003c;0.001</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">100</td><td align="left">0.024</td><td align="left">0.020</td><td align="left">
<bold>0.048</bold>
</td><td align="left">0.031</td><td align="left">0.045</td><td align="left">0.034</td><td align="left">0.017</td><td align="left">0.042</td><td align="left">0.038</td><td align="left">0.001</td><td align="left">0.001</td></tr><tr><td align="left">G2</td><td align="left">0</td><td align="left">0.163</td><td align="left">0.147</td><td align="left">0.131</td><td align="left">0.038</td><td align="left">0.077</td><td align="left">0.177</td><td align="left">0.025</td><td align="left">0.062</td><td align="left">0.045</td><td align="left">0.002</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">25</td><td align="left">0.097</td><td align="left">0.092</td><td align="left">0.103</td><td align="left">0.036</td><td align="left">0.067</td><td align="left">
<bold>0.124</bold>
</td><td align="left">0.024</td><td align="left">0.059</td><td align="left">0.043</td><td align="left">&#x0003c;0.001</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">50</td><td align="left">0.042</td><td align="left">0.040</td><td align="left">
<bold>0.079</bold>
</td><td align="left">0.030</td><td align="left">0.052</td><td align="left">0.071</td><td align="left">0.021</td><td align="left">0.046</td><td align="left">0.041</td><td align="left">&#x0003c;0.001</td><td align="left">&#x0003c;0.001</td></tr><tr><td align="left"/><td align="left">75</td><td align="left">0.019</td><td align="left">0.018</td><td align="left">
<bold>0.054</bold>
</td><td align="left">0.019</td><td align="left">0.038</td><td align="left">0.038</td><td align="left">0.016</td><td align="left">0.034</td><td align="left">0.034</td><td align="left">&#x0003c;0.001</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">100</td><td align="left">0.011</td><td align="left">0.009</td><td align="left">
<bold>0.032</bold>
</td><td align="left">0.008</td><td align="left">0.025</td><td align="left">0.021</td><td align="left">0.011</td><td align="left">0.026</td><td align="left">0.025</td><td align="left">&#x0003c;0.001</td><td align="left">0.001</td></tr></tbody></table><table-wrap-foot><p>p &#x0003c; 0.05</p></table-wrap-foot></table-wrap>
</p></sec><sec id="Sec8"><title>Sensitivity to number of experiments</title><p>The aim of this procedure is to measure the robustness of the different reconstruction methods in terms of number of available experiments. In a real world scenario, one has budgetary limitations and therefore there is a restriction on the number of different experiments that can be done. Here, we want to address this issue by identifying the best methods in several scenarios with different number of experiments. To do so, we subsample the experiments of the datasources of Table <xref rid="Tab2" ref-type="table">2</xref> with different number of experiments and then add local noise of 20 % of intensity. As in the noise sensitivity study, this process is repeated ten times and the performance metrics (<italic>A</italic>
<italic>U</italic>
<italic>P</italic>
<italic>R</italic>
<sub>20 <italic>%</italic></sub>) are averaged over the different trials.</p><p>The results are presented in Table <xref rid="Tab7" ref-type="table">7</xref>. Figure <xref rid="Fig4" ref-type="fig">4</xref> presents the results for one datasource of each simulator; to have a realistic setting we have chosen datasources that have more than 800 genes and one datasource for each simulator.
<fig id="Fig4"><label>Fig. 4</label><caption><p>Plots of performance with different number of experiments. Each line represents a method (color coded), the mean performance over the ten runs is presented</p></caption><graphic xlink:href="12859_2015_728_Fig4_HTML" id="MO5"/></fig>
<table-wrap id="Tab7"><label>Table 7</label><caption><p>Results of the study on the sensitivity with respect to the number of experiments. Mean AUPR in the top 20 % of the possible connetions with a undirected evaluation with respect to number of experiments (# exp). The best results are highlighted. Results obtained with current version (1.0) of the package and are updated online</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Datasource</th><th align="left"># exp</th><th align="left">ARACNE</th><th align="left">C3NET</th><th align="left">CLR</th><th align="left">GeneNet</th><th align="left">Genie3</th><th align="left">MRNET</th><th align="left">MutRank</th><th align="left">MRNETB</th><th align="left">PCIT</th><th align="left">Zscore</th><th align="left">Random</th></tr></thead><tbody><tr><td align="left">R1</td><td align="left">20</td><td align="left">0.001</td><td align="left">0.001</td><td align="left">0.001</td><td align="left">0.001</td><td align="left">0.001</td><td align="left">0.001</td><td align="left">0.002</td><td align="left">0.001</td><td align="left">
<bold>0.018</bold>
</td><td align="left">
<bold>0.018</bold>
</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">50</td><td align="left">0.001</td><td align="left">0.001</td><td align="left">0.001</td><td align="left">0.001</td><td align="left">0.004</td><td align="left">0.001</td><td align="left">0.007</td><td align="left">0.001</td><td align="left">0.056</td><td align="left">0.046</td><td align="left">&#x0003c;0.001</td></tr><tr><td align="left"/><td align="left">200</td><td align="left">0.008</td><td align="left">0.004</td><td align="left">0.010</td><td align="left">0.181</td><td align="left">0.035</td><td align="left">0.010</td><td align="left">0.060</td><td align="left">0.010</td><td align="left">0.226</td><td align="left">0.179</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">800</td><td align="left">0.160</td><td align="left">0.114</td><td align="left">0.166</td><td align="left">0.723</td><td align="left">0.249</td><td align="left">0.166</td><td align="left">0.306</td><td align="left">0.167</td><td align="left">0.764</td><td align="left">0.726</td><td align="left">&#x0003c;0.001</td></tr><tr><td align="left">S1</td><td align="left">20</td><td align="left">0.021</td><td align="left">0.016</td><td align="left">
<bold>0.113</bold>
</td><td align="left">0.096</td><td align="left">0.097</td><td align="left">0.077</td><td align="left">0.058</td><td align="left">0.089</td><td align="left">0.055</td><td align="left">0.005</td><td align="left">0.002</td></tr><tr><td align="left"/><td align="left">50</td><td align="left">0.027</td><td align="left">0.020</td><td align="left">
<bold>0.129</bold>
</td><td align="left">0.099</td><td align="left">0.122</td><td align="left">0.091</td><td align="left">0.060</td><td align="left">0.110</td><td align="left">0.057</td><td align="left">0.017</td><td align="left">0.002</td></tr><tr><td align="left"/><td align="left">200</td><td align="left">0.036</td><td align="left">0.030</td><td align="left">
<bold>0.138</bold>
</td><td align="left">0.066</td><td align="left">0.135</td><td align="left">0.108</td><td align="left">0.064</td><td align="left">0.122</td><td align="left">0.059</td><td align="left">0.034</td><td align="left">0.002</td></tr><tr><td align="left"/><td align="left">800</td><td align="left">0.064</td><td align="left">0.054</td><td align="left">0.141</td><td align="left">0.053</td><td align="left">
<bold>0.144</bold>
</td><td align="left">0.139</td><td align="left">0.065</td><td align="left">0.130</td><td align="left">0.059</td><td align="left">0.058</td><td align="left">0.003</td></tr><tr><td align="left">S2</td><td align="left">20</td><td align="left">0.003</td><td align="left">0.003</td><td align="left">
<bold>0.033</bold>
</td><td align="left">0.025</td><td align="left">0.026</td><td align="left">0.014</td><td align="left">0.019</td><td align="left">0.019</td><td align="left">0.011</td><td align="left">0.003</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">50</td><td align="left">0.005</td><td align="left">0.004</td><td align="left">
<bold>0.040</bold>
</td><td align="left">0.025</td><td align="left">0.033</td><td align="left">0.018</td><td align="left">0.021</td><td align="left">0.025</td><td align="left">0.013</td><td align="left">0.002</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">200</td><td align="left">0.007</td><td align="left">0.006</td><td align="left">
<bold>0.044</bold>
</td><td align="left">0.018</td><td align="left">0.040</td><td align="left">0.024</td><td align="left">0.022</td><td align="left">0.028</td><td align="left">0.013</td><td align="left">0.004</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">800</td><td align="left">0.011</td><td align="left">0.010</td><td align="left">
<bold>0.045</bold>
</td><td align="left">0.010</td><td align="left">
<bold>0.044</bold>
</td><td align="left">0.028</td><td align="left">0.022</td><td align="left">0.027</td><td align="left">0.012</td><td align="left">0.013</td><td align="left">0.001</td></tr><tr><td align="left">G1</td><td align="left">20</td><td align="left">0.014</td><td align="left">0.012</td><td align="left">0.020</td><td align="left">0.001</td><td align="left">0.015</td><td align="left">0.017</td><td align="left">0.009</td><td align="left">0.024</td><td align="left">
<bold>0.029</bold>
</td><td align="left">0.001</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">50</td><td align="left">0.051</td><td align="left">0.047</td><td align="left">
<bold>0.078</bold>
</td><td align="left">0.056</td><td align="left">0.065</td><td align="left">0.064</td><td align="left">0.020</td><td align="left">0.063</td><td align="left">0.048</td><td align="left">&#x0003c;0.001</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">200</td><td align="left">0.136</td><td align="left">0.127</td><td align="left">
<bold>0.160</bold>
</td><td align="left">0.083</td><td align="left">0.122</td><td align="left">0.164</td><td align="left">0.038</td><td align="left">0.090</td><td align="left">0.061</td><td align="left">0.001</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">800</td><td align="left">
<bold>0.242</bold>
</td><td align="left">0.215</td><td align="left">0.222</td><td align="left">0.091</td><td align="left">0.156</td><td align="left">0.238</td><td align="left">0.049</td><td align="left">0.105</td><td align="left">0.071</td><td align="left">0.001</td><td align="left">0.001</td></tr><tr><td align="left">G2</td><td align="left">20</td><td align="left">0.012</td><td align="left">0.010</td><td align="left">0.022</td><td align="left">0.001</td><td align="left">0.012</td><td align="left">0.017</td><td align="left">0.007</td><td align="left">
<bold>0.025</bold>
</td><td align="left">
<bold>0.023</bold>
</td><td align="left">0.001</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">50</td><td align="left">0.040</td><td align="left">0.038</td><td align="left">
<bold>0.064</bold>
</td><td align="left">0.026</td><td align="left">0.042</td><td align="left">0.059</td><td align="left">0.015</td><td align="left">0.047</td><td align="left">0.034</td><td align="left">&#x0003c;0.001</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">200</td><td align="left">0.137</td><td align="left">0.127</td><td align="left">0.120</td><td align="left">0.037</td><td align="left">0.079</td><td align="left">
<bold>0.157</bold>
</td><td align="left">0.028</td><td align="left">0.063</td><td align="left">0.046</td><td align="left">&#x0003c;0.001</td><td align="left">0.001</td></tr><tr><td align="left"/><td align="left">800</td><td align="left">
<bold>0.246</bold>
</td><td align="left">0.214</td><td align="left">0.157</td><td align="left">0.036</td><td align="left">0.100</td><td align="left">0.218</td><td align="left">0.034</td><td align="left">0.070</td><td align="left">0.051</td><td align="left">&#x0003c;0.001</td><td align="left">0.001</td></tr></tbody></table><table-wrap-foot><p>p &#x0003c; 0.05</p></table-wrap-foot></table-wrap>
</p></sec></sec><sec id="Sec9" sec-type="discussion"><title>Discussion</title><p>The results reveal that the studied methods exhibit different behavior across different simulators (and datasources), and none of the methods is the best one for all datasources. We also find large variations in terms of <italic>A</italic>
<italic>U</italic>
<italic>P</italic>
<italic>R</italic>
<sub>20 <italic>%</italic></sub> across datasources: Better results can be expected for smaller networks and for simpler simulators such as Rogers. It is worth noting that PCIT and Zscore almost reach a 100 % precision over their most confident connections in the Rogers datasets (see average precision-recall curves in supplemental material from Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Figure S1, Additional file <xref rid="MOESM2" ref-type="media">2</xref>: Figure S2, Additional file <xref rid="MOESM3" ref-type="media">3</xref>: Figure S3, Additional file <xref rid="MOESM4" ref-type="media">4</xref>: Figure S4 and Additional file <xref rid="MOESM5" ref-type="media">5</xref>: Figure S5. This could be easily explained because both methods assume knockout experiments and normally distributed samples, in phase with how the data have been generated (by the Rogers simulator). As mentioned, none of the methods obtains the best results across the different datasources. But, as a general overview (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>), we can observe that CLR is the best on the majority of the datasets. It is also one of the fastest methods in terms of computation time (see Table <xref rid="Tab3" ref-type="table">3</xref>).</p><p>Differently from [<xref ref-type="bibr" rid="CR5">5</xref>], we do not find the Zscore method as the best-performing method. However, there are several aspects to take into account. Our analysis evaluates only the most confident connections returned by the different methods whereas the study reported in [<xref ref-type="bibr" rid="CR5">5</xref>] evaluates all the connections. The authors use the AUROC measure that could benefit the sparse recovered networks [<xref ref-type="bibr" rid="CR15">15</xref>], as is the case of Zscore method. Furthermore, the analysis of [<xref ref-type="bibr" rid="CR5">5</xref>] is based on simulation of the fully interventional data, knockouts and knockdowns, of the DREAM4 [<xref ref-type="bibr" rid="CR12">12</xref>], and only involves the GNW simulator. Nevertheless, we also have evaluated the different reconstruction methods with the same setup as in [<xref ref-type="bibr" rid="CR5">5</xref>] and also found that the Zscore is one of the best-performing methods when using knockout data.</p><sec id="Sec10"><title>Effect of noise</title><p>We have studied the effect of noise on the performance using an additive Gaussian noise with different noise intensities, and we have found that the majority of the methods are quite robust to the noise effects. Also, the improvement of the performance on the datasets without noise is almost negligible. Even in the absence of noise, the <italic>A</italic>
<italic>U</italic>
<italic>P</italic>
<italic>R</italic>
<sub>20 <italic>%</italic></sub> values remain low, which highlights the difficulty of the task at hand. Still, we observe a trend of decreasing performance when the noise increases. However, we can see how the performances of ARACNE, C3NET and GeneNet are the most affected by increasing noises. The other methods appear less sensible to the noise addition.</p></sec><sec id="Sec11"><title>Effect of number of experiments</title><p>We also have studied the effect of the number of experiments on the performances. On one extreme, we have included a setup involving more experiments than genes and, on the other extreme, a setup where the number of experiments is around 1 % of the number of genes. We found that increasing the number of samples seems beneficial in most of the methods; it is worth noting that on datasource R1 the performance is outstanding for the Zscore, PCIT and GeneNet methods. These results are coherent with a similar study presented at [<xref ref-type="bibr" rid="CR5">5</xref>]. Note that C3NET and ARACNE methods are the methods that suffer more the effects of a low number of experiments scenario. When few experiments are available the mutual information values between genes is more difficult to be estimated. The C3NET extracts the maximum value of MI per gene, while ARACNE eliminates the edge with minimum value of MI at every triangle.</p></sec></sec><sec id="Sec12"><title>Review reproducibility</title><p>As previously stated, the present review is fully reproducible, with one function call of the Bioconductor package NetBenchmark. With this package, the different datasources are automatically loaded and the presented methods are implemented or imported with the package.</p><p>R is a broadly used open source language and environment for statistical computing and graphics [<xref ref-type="bibr" rid="CR35">35</xref>]. Nowadays, it is a standard in statistical modeling, data analysis, bio-statistics and machine learning. There is a very active R community developing R packages implementing the latest advances in computational statistics. Moreover, platforms like Bioconductor host a huge amount of algorithms whose aim is the analysis and comprehension of genomic data mainly based on the R programming language [<xref ref-type="bibr" rid="CR32">32</xref>]. Therefore, many GRN methods are implemented in an R package. This is why we chose to develop an R package to perform the benchmarking process in a fast and easy way.</p><p>We have developed several wrappers with the default parameters for most methods. The names of the wrappers of the GRN reconstruction algorithms that are currently available in the package are listed in Table <xref rid="Tab4" ref-type="table">4</xref>. In order to reproduce the presented results, the user can run the commands provided in listing ?? after the download and installation of the package. Thanks to the seed of the random number generators of the different studies, the results are replicable.</p><p>
<graphic xlink:href="12859_2015_728_Figb_HTML.gif" id="MO6"/>
</p><p>In the present study we made a set of choices such as the evaluation measure or the number of datasets per datasource, but thanks to the Bioconductor package NetBenchmark, the user can make a different sets of choices, and the package can also be used for a deeper analysis of the methods. We refer the interested reader to the help files of the package for further information.</p><p>Additionally, the Bioconductor package NetBenchmark allows testing new methods with the benchmark in the same conditions that we presented in this review. The presented results are available online (<ext-link ext-link-type="uri" xlink:href="https://imatge.upc.edu/netbenchmark/">https://imatge.upc.edu/netbenchmark/</ext-link>) that allows following research and comparison of new methods within the same conditions.</p></sec><sec id="Sec13" sec-type="conclusion"><title>Conclusions</title><p>In this paper, we have presented a new benchmark process for network reconstruction algorithms that relies on several in silico generators and a subsampling strategy to generate an environment for evaluating the different methods, in a fast and robust way. This benchmark is focused on (but not limited to) a GRN reconstruction task and therefore we have taken into account the goals of the community such as the evaluation of the most confident connections. We have also developed a Bioconductor package and webpage to allow future research and comparison of new methods under the same conditions and to provide the possibility to change them. The present paper has assessed the different GRN methods in a high-heterogeneity data scenario and has highlighted the specialization of methods for the different network types and data.</p><p>As a general conclusion, we can observe that CLR is the best on the majority of the datasets, but it does not obtain the best results across all the different datasources and kinds of data. In the case of complete knockout data, the best-performing methods are the Zscore followed by PCIT and GeneNet. Let us note also that Genie3 and MRNET exhibit competitive performances, however, these methods are not as fast as CLR in terms of computation time.</p></sec></body><back><app-group><app id="App1"><sec id="Sec14"><title>Additional files</title><p>
<media position="anchor" xlink:href="12859_2015_728_MOESM1_ESM.eps" id="MOESM1"><label>Additional file 1</label><caption><p>
<bold>Figure S1.</bold> Mean Precision Recall curves for the different GNR reconstruction methods at datasource R1. Each line is the mean curve over ten datasets. (EPS 242 kb)</p></caption></media>
</p><p>
<media position="anchor" xlink:href="12859_2015_728_MOESM2_ESM.eps" id="MOESM2"><label>Additional file 2</label><caption><p>
<bold>Figure S2.</bold> Mean Precision Recall curves for the different GNR reconstruction methods at datasource S1. Each line is the mean curve over ten datasets. (EPS 260 kb)</p></caption></media>
</p><p>
<media position="anchor" xlink:href="12859_2015_728_MOESM3_ESM.eps" id="MOESM3"><label>Additional file 3</label><caption><p>
<bold>Figure S3.</bold> Mean Precision Recall curves for the different GNR reconstruction methods at datasource S2. Each line is the mean curve over ten datasets. (EPS 266 kb)</p></caption></media>
</p><p>
<media position="anchor" xlink:href="12859_2015_728_MOESM4_ESM.eps" id="MOESM4"><label>Additional file 4</label><caption><p>
<bold>Figure S4.</bold> Mean Precision Recall curves for the different GNR reconstruction methods at datasource G1. Each line is the mean curve over ten datasets. (EPS 268 kb)</p></caption></media>
</p><p>
<media position="anchor" xlink:href="12859_2015_728_MOESM5_ESM.eps" id="MOESM5"><label>Additional file 5</label><caption><p>
<bold>Figure S5.</bold> Mean Precision Recall curves for the different GNR reconstruction methods at datasource G2. Each line is the mean curve over ten datasets. (EPS 268 kb)</p></caption></media>
</p></sec></app></app-group><fn-group><fn><p><bold>Competing interests</bold></p><p>The authors declare that they have no competing interests.</p></fn><fn><p><bold>Authors&#x02019; contributions</bold></p><p>PEM proposed and supervised the setup of the study. All authors participated in the improvement of the design of the study and the experimental setup. The package and coding has been implemented by PB, CO and PEM. PB wrote the first draft of the manuscript. PS, AOV, CO and PEM have revised the manuscript critically for important intellectual content. All authors helped to improve the draft of the manuscript. All authors read and approved the final manuscript.</p></fn><fn><p><bold>Authors&#x02019; information</bold></p><p>Not applicable.</p></fn><fn><p><bold>Availability and requirements</bold></p><p>The R package is available for free from Bioconductor [<xref ref-type="bibr" rid="CR32">32</xref>]. It is most easily obtained by starting R and running source("
<ext-link ext-link-type="uri" xlink:href="http://bioconductor.org/biocLite.R">http://bioconductor.org/biocLite.R</ext-link>
");biocLite("netbenchmark") in the console window.</p><p>&#x02219;<bold>Project name:</bold> NetBenchmark</p><p>&#x02219;<bold>Project home page:</bold>
<ext-link ext-link-type="uri" xlink:href="https://imatge.upc.edu/netbenchmark/">https://imatge.upc.edu/netbenchmark/</ext-link>
</p><p>&#x02219;<bold>Version:</bold> 1.0.0</p><p>&#x02219;<bold>Operating systems:</bold> Platform independent</p><p>&#x02219;<bold>Programming language:</bold> R</p><p>&#x02219;<bold>Other requirements:</bold> R packages dependencies which are free and automatically downloaded</p><p>&#x02219;<bold>License:</bold> CC BY-NC-SA 4.0</p></fn></fn-group><ack><title>Acknowledgements</title><p>PB is supported by the Spanish &#x0201c;Ministerio de Educaci&#x000f3;n, Cultura y Deporte&#x0201d; FPU Research Fellowship, and the Cellex foundation. CO was supported by the Innoviris EHealth platform project BridgeIris and a ULB postdoctoral position. This work has been developed in the framework of the project BIGGRAPH-TEC2013-43935-R, funded by the Spanish Ministerio de Econom&#x000ed;a y Competitividad and the European Regional Development Fund (ERDF). The present research also benefited from the use of high performance computing resources (&#x0201c;durandal&#x0201d; grid computer) funded by three grants from the University of Li&#x000e8;ge: (SFRD-12/03, SFRD-12/04, C-14/73) as well as a Cr&#x000e9;dit de Recherche of the FNRS under award number nr 23678785.</p></ack><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van den Bulcke</surname><given-names>T</given-names></name><name><surname>Van Leemput</surname><given-names>K</given-names></name><name><surname>Naudts</surname><given-names>B</given-names></name><name><surname>van Remortel</surname><given-names>P</given-names></name><name><surname>Ma</surname><given-names>H</given-names></name><name><surname>Verschoren</surname><given-names>A</given-names></name><etal/></person-group><article-title>Syntren: a generator of synthetic gene expression data for design and analysis of structure learning algorithms</article-title><source>BMC Bioinformatics</source><year>2006</year><volume>7</volume><issue>1</issue><fpage>43</fpage><pub-id pub-id-type="doi">10.1186/1471-2105-7-43</pub-id><pub-id pub-id-type="pmid">16438721</pub-id></element-citation></ref><ref id="CR2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Altay</surname><given-names>G</given-names></name><name><surname>Emmert-Streib</surname><given-names>F</given-names></name></person-group><article-title>Revealing differences in gene network inference algorithms on the network level by ensemble methods</article-title><source>Bioinformatics</source><year>2010</year><volume>26</volume><issue>14</issue><fpage>1738</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btq259</pub-id><pub-id pub-id-type="pmid">20501553</pub-id></element-citation></ref><ref id="CR3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaffter</surname><given-names>T</given-names></name><name><surname>Marbach</surname><given-names>D</given-names></name><name><surname>Floreano</surname><given-names>D</given-names></name></person-group><article-title>Genenetweaver: in silico benchmark generation and performance profiling of network inference methods</article-title><source>Bioinformatics</source><year>2011</year><volume>27</volume><issue>16</issue><fpage>2263</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btr373</pub-id><pub-id pub-id-type="pmid">21697125</pub-id></element-citation></ref><ref id="CR4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marbach</surname><given-names>D</given-names></name><name><surname>Costello</surname><given-names>JC</given-names></name><name><surname>K&#x000fc;ffner</surname><given-names>R</given-names></name><name><surname>Vega</surname><given-names>NM</given-names></name><name><surname>Prill</surname><given-names>RJ</given-names></name><name><surname>Camacho</surname><given-names>DM</given-names></name><etal/></person-group><article-title>Wisdom of crowds for robust gene network inference</article-title><source>Nat Methods</source><year>2012</year><volume>9</volume><issue>8</issue><fpage>796</fpage><lpage>804</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2016</pub-id><pub-id pub-id-type="pmid">22796662</pub-id></element-citation></ref><ref id="CR5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maetschke</surname><given-names>SR</given-names></name><name><surname>Madhamshettiwar</surname><given-names>PB</given-names></name><name><surname>Davis</surname><given-names>MJ</given-names></name><name><surname>Ragan</surname><given-names>MA</given-names></name></person-group><article-title>Supervised, semi-supervised and unsupervised inference of gene regulatory networks</article-title><source>Briefings Bioinformatics</source><year>2014</year><volume>15</volume><issue>2</issue><fpage>195</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1093/bib/bbt034</pub-id></element-citation></ref><ref id="CR6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Smet</surname><given-names>R</given-names></name><name><surname>Marchal</surname><given-names>K</given-names></name></person-group><article-title>Advantages and limitations of current network inference methods</article-title><source>Nat Rev Microbiol</source><year>2010</year><volume>8</volume><issue>10</issue><fpage>717</fpage><lpage>29</lpage><pub-id pub-id-type="pmid">20805835</pub-id></element-citation></ref><ref id="CR7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Madhamshettiwar</surname><given-names>PB</given-names></name><name><surname>Maetschke</surname><given-names>SR</given-names></name><name><surname>Davis</surname><given-names>MJ</given-names></name><name><surname>Reverter</surname><given-names>A</given-names></name><name><surname>Ragan</surname><given-names>MA</given-names></name></person-group><article-title>Gene regulatory network inference: evaluation and application to ovarian cancer allows the prioritization of drug targets</article-title><source>Genome Med</source><year>2012</year><volume>4</volume><issue>5</issue><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1186/gm340</pub-id><pub-id pub-id-type="pmid">22257447</pub-id></element-citation></ref><ref id="CR8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roy</surname><given-names>S</given-names></name><name><surname>Ernst</surname><given-names>J</given-names></name><name><surname>Kharchenko</surname><given-names>PV</given-names></name><name><surname>Kheradpour</surname><given-names>P</given-names></name><name><surname>Negre</surname><given-names>N</given-names></name><name><surname>Eaton</surname><given-names>ML</given-names></name><etal/></person-group><article-title>Identification of functional elements and regulatory circuits by drosophila modencode</article-title><source>Science</source><year>2010</year><volume>330</volume><issue>6012</issue><fpage>1787</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1126/science.1198374</pub-id><pub-id pub-id-type="pmid">21177974</pub-id></element-citation></ref><ref id="CR9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faith</surname><given-names>JJ</given-names></name><name><surname>Hayete</surname><given-names>B</given-names></name><name><surname>Thaden</surname><given-names>JT</given-names></name><name><surname>Mogno</surname><given-names>I</given-names></name><name><surname>Wierzbowski</surname><given-names>J</given-names></name><name><surname>Cottarel</surname><given-names>G</given-names></name><etal/></person-group><article-title>Large-scale mapping and validation of escherichia coli transcriptional regulation from a compendium of expression profiles</article-title><source>PLoS Biol</source><year>2007</year><volume>5</volume><issue>1</issue><fpage>8</fpage><pub-id pub-id-type="doi">10.1371/journal.pbio.0050008</pub-id></element-citation></ref><ref id="CR10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rogers</surname><given-names>S</given-names></name><name><surname>Girolami</surname><given-names>M</given-names></name></person-group><article-title>A bayesian regression approach to the inference of regulatory networks from gene expression data</article-title><source>Bioinformatics</source><year>2005</year><volume>21</volume><issue>14</issue><fpage>3131</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/bti487</pub-id><pub-id pub-id-type="pmid">15879452</pub-id></element-citation></ref><ref id="CR11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olsen</surname><given-names>C</given-names></name><name><surname>Meyer</surname><given-names>PE</given-names></name><name><surname>Bontempi</surname><given-names>G</given-names></name></person-group><article-title>On the impact of entropy estimation on transcriptional regulatory network inference based on mutual information</article-title><source>EURASIP J Bioinform Syst Biol</source><year>2009</year><volume>2009</volume><issue>1</issue><fpage>308959</fpage><pub-id pub-id-type="pmid">19148299</pub-id></element-citation></ref><ref id="CR12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marbach</surname><given-names>D</given-names></name><name><surname>Prill</surname><given-names>RJ</given-names></name><name><surname>Schaffter</surname><given-names>T</given-names></name><name><surname>Mattiussi</surname><given-names>C</given-names></name><name><surname>Floreano</surname><given-names>D</given-names></name><name><surname>Stolovitzky</surname><given-names>G</given-names></name></person-group><article-title>Revealing strengths and weaknesses of methods for gene network inference</article-title><source>Proc Natl Acad Sci</source><year>2010</year><volume>107</volume><issue>14</issue><fpage>6286</fpage><lpage>91</lpage><pub-id pub-id-type="doi">10.1073/pnas.0913357107</pub-id><pub-id pub-id-type="pmid">20308593</pub-id></element-citation></ref><ref id="CR13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stolovitzky</surname><given-names>G</given-names></name><name><surname>Kundaje</surname><given-names>A</given-names></name><name><surname>Held</surname><given-names>G</given-names></name><name><surname>Duggar</surname><given-names>K</given-names></name><name><surname>Haudenschild</surname><given-names>C</given-names></name><etal/></person-group><article-title>Statistical analysis of mpss measurements: application to the study of lps-activated macrophage gene expression</article-title><source>Proc Natl Acad Sci U S A</source><year>2005</year><volume>102</volume><issue>5</issue><fpage>1402</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1073/pnas.0406555102</pub-id><pub-id pub-id-type="pmid">15668391</pub-id></element-citation></ref><ref id="CR14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bansal</surname><given-names>M</given-names></name><name><surname>Belcastro</surname><given-names>V</given-names></name><name><surname>Ambesi-Impiombato</surname><given-names>A</given-names></name><name><surname>di Bernardo</surname><given-names>D</given-names></name></person-group><article-title>How to infer gene networks from expression profiles</article-title><source>Mol Syst Biol</source><year>2007</year><volume>3</volume><issue>1</issue><fpage>1</fpage><lpage>10</lpage></element-citation></ref><ref id="CR15"><label>15</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>J</given-names></name><name><surname>Goadrich</surname><given-names>M</given-names></name></person-group><article-title>The relationship between precision-recall and roc curves</article-title><source>Proceedings of the 23rd International Conference on Machine Learning. ICML &#x02019;06</source><year>2006</year><publisher-loc>New York, NY, USA</publisher-loc><publisher-name>ACM</publisher-name></element-citation></ref><ref id="CR16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marbach</surname><given-names>D</given-names></name><name><surname>Roy</surname><given-names>S</given-names></name><name><surname>Ay</surname><given-names>F</given-names></name><name><surname>Meyer</surname><given-names>PE</given-names></name><name><surname>Candeias</surname><given-names>R</given-names></name><name><surname>Kahveci</surname><given-names>T</given-names></name><etal/></person-group><article-title>Predictive regulatory models in drosophila melanogaster by integrative inference of transcriptional networks</article-title><source>Genome Res</source><year>2012</year><volume>22</volume><issue>7</issue><fpage>1334</fpage><lpage>49</lpage><pub-id pub-id-type="doi">10.1101/gr.127191.111</pub-id><pub-id pub-id-type="pmid">22456606</pub-id></element-citation></ref><ref id="CR17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Opgen-Rhein</surname><given-names>R</given-names></name><name><surname>Strimmer</surname><given-names>K</given-names></name></person-group><article-title>From correlation to causation networks: a simple approximate learning algorithm and its application to high-dimensional plant gene expression data</article-title><source>BMC Syst Biol</source><year>2007</year><volume>1</volume><issue>1</issue><fpage>37</fpage><pub-id pub-id-type="doi">10.1186/1752-0509-1-37</pub-id><pub-id pub-id-type="pmid">17683609</pub-id></element-citation></ref><ref id="CR18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Obayashi</surname><given-names>T</given-names></name><name><surname>Kinoshita</surname><given-names>K</given-names></name></person-group><article-title>Rank of correlation coefficient as a comparable measure for biological significance of gene coexpression</article-title><source>DNA Res</source><year>2009</year><volume>16</volume><issue>5</issue><fpage>249</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1093/dnares/dsp016</pub-id><pub-id pub-id-type="pmid">19767600</pub-id></element-citation></ref><ref id="CR19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prill</surname><given-names>RJ</given-names></name><name><surname>Marbach</surname><given-names>D</given-names></name><name><surname>Saez-Rodriguez</surname><given-names>J</given-names></name><name><surname>Sorger</surname><given-names>PK</given-names></name><name><surname>Alexopoulos</surname><given-names>LG</given-names></name><name><surname>Xue</surname><given-names>X</given-names></name><etal/></person-group><article-title>Towards a rigorous assessment of systems biology models: the dream3 challenges</article-title><source>PloS ONE</source><year>2010</year><volume>5</volume><issue>2</issue><fpage>9202</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0009202</pub-id></element-citation></ref><ref id="CR20"><label>20</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cover</surname><given-names>TM</given-names></name><name><surname>Thomas</surname><given-names>JA</given-names></name></person-group><source>Elements of Information Theory</source><year>2006</year><publisher-loc>Hoboken, New Jersey</publisher-loc><publisher-name>John Wiley &#x00026; Sons</publisher-name></element-citation></ref><ref id="CR21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butte</surname><given-names>AJ</given-names></name><name><surname>Kohane</surname><given-names>IS</given-names></name></person-group><article-title>Mutual information relevance networks: functional genomic clustering using pairwise entropy measurements</article-title><source>Pac Symp Biocomput</source><year>2000</year><volume>5</volume><fpage>418</fpage><lpage>29</lpage><pub-id pub-id-type="pmid">10902190</pub-id></element-citation></ref><ref id="CR22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steuer</surname><given-names>R</given-names></name><name><surname>Kurths</surname><given-names>J</given-names></name><name><surname>Daub</surname><given-names>CO</given-names></name><name><surname>Weise</surname><given-names>J</given-names></name><name><surname>Selbig</surname><given-names>J</given-names></name></person-group><article-title>The mutual information: detecting and evaluating dependencies between variables</article-title><source>Bioinformatics</source><year>2002</year><volume>18</volume><issue>suppl 2</issue><fpage>231</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/18.suppl_2.S231</pub-id></element-citation></ref><ref id="CR23"><label>23</label><mixed-citation publication-type="other">Bellot P, Meyer PE. Efficient combination of pairwise feature networks. In: JMLR: Workshop and Conference Proceedings, Connectomics (ECML 2014). vol. 11, pp. 93&#x02013;100 (2014).</mixed-citation></ref><ref id="CR24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Margolin</surname><given-names>AA</given-names></name><name><surname>Nemenman</surname><given-names>I</given-names></name><name><surname>Basso</surname><given-names>K</given-names></name><name><surname>Wiggins</surname><given-names>C</given-names></name><name><surname>Stolovitzky</surname><given-names>G</given-names></name><name><surname>Favera</surname><given-names>RD</given-names></name><etal/></person-group><article-title>Aracne: an algorithm for the reconstruction of gene regulatory networks in a mammalian cellular context</article-title><source>BMC Bioinformatics</source><year>2006</year><volume>7</volume><issue>Suppl 1</issue><fpage>7</fpage><pub-id pub-id-type="doi">10.1186/1471-2105-7-S1-S7</pub-id><pub-id pub-id-type="pmid">16401345</pub-id></element-citation></ref><ref id="CR25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reverter</surname><given-names>A</given-names></name><name><surname>Chan</surname><given-names>EK</given-names></name></person-group><article-title>Combining partial correlation and an information theory approach to the reversed engineering of gene co-expression networks</article-title><source>Bioinformatics</source><year>2008</year><volume>24</volume><issue>21</issue><fpage>2491</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btn482</pub-id><pub-id pub-id-type="pmid">18784117</pub-id></element-citation></ref><ref id="CR26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Altay</surname><given-names>G</given-names></name><name><surname>Emmert-Streib</surname><given-names>F</given-names></name></person-group><article-title>Inferring the conservative causal core of gene regulatory networks</article-title><source>BMC Syst Biol</source><year>2010</year><volume>4</volume><issue>1</issue><fpage>132</fpage><pub-id pub-id-type="doi">10.1186/1752-0509-4-132</pub-id><pub-id pub-id-type="pmid">20920161</pub-id></element-citation></ref><ref id="CR27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>PE</given-names></name><name><surname>Kontos</surname><given-names>K</given-names></name><name><surname>Lafitte</surname><given-names>F</given-names></name><name><surname>Bontempi</surname><given-names>G</given-names></name></person-group><article-title>Information-theoretic inference of large transcriptional regulatory networks</article-title><source>EURASIP J Bioinform Syst Biol</source><year>2007</year><volume>2007</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1155/2007/79879</pub-id></element-citation></ref><ref id="CR28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>C</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name></person-group><article-title>Minimum redundancy feature selection from microarray gene expression data</article-title><source>J Bioinformatics Comput Biol</source><year>2005</year><volume>3</volume><issue>02</issue><fpage>185</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1142/S0219720005001004</pub-id></element-citation></ref><ref id="CR29"><label>29</label><mixed-citation publication-type="other">Meyer PE, Marbach D, Roy S, Kellis M. Information-theoretic inference of gene networks using backward elimination. In: BIOCOMP, International Conference on Bioinformatics and Computational Biology: 2010. p. 700&#x02013;5.</mixed-citation></ref><ref id="CR30"><label>30</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huynh-Thu</surname><given-names>VA</given-names></name><name><surname>Irrthum</surname><given-names>A</given-names></name><name><surname>Wehenkel</surname><given-names>L</given-names></name><name><surname>Geurts</surname><given-names>P</given-names></name></person-group><article-title>Inferring regulatory networks from expression data using tree-based methods</article-title><source>PloS ONE</source><year>2010</year><volume>5</volume><issue>9</issue><fpage>12776</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0012776</pub-id></element-citation></ref><ref id="CR31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breiman</surname><given-names>L</given-names></name></person-group><article-title>Random forests</article-title><source>Mach Learn</source><year>2001</year><volume>45</volume><issue>1</issue><fpage>5</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id></element-citation></ref><ref id="CR32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gentleman</surname><given-names>RC</given-names></name><name><surname>Carey</surname><given-names>VJ</given-names></name><name><surname>Bates</surname><given-names>DM</given-names></name><name><surname>Bolstad</surname><given-names>B</given-names></name><name><surname>Dettling</surname><given-names>M</given-names></name><name><surname>Dudoit</surname><given-names>S</given-names></name><etal/></person-group><article-title>Bioconductor: open software development for computational biology and bioinformatics</article-title><source>Genome Biol</source><year>2004</year><volume>5</volume><issue>10</issue><fpage>80</fpage><pub-id pub-id-type="doi">10.1186/gb-2004-5-10-r80</pub-id></element-citation></ref><ref id="CR33"><label>33</label><mixed-citation publication-type="other">Conover WJ, Conover W. Practical nonparametric statistics. 1980.</mixed-citation></ref><ref id="CR34"><label>34</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chambers</surname><given-names>JM</given-names></name></person-group><source>Graphical Methods for Data Analysis</source><year>1983</year><publisher-loc>California, USA</publisher-loc><publisher-name>Wadsworth International Group</publisher-name></element-citation></ref><ref id="CR35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ihaka</surname><given-names>R</given-names></name><name><surname>Gentleman</surname><given-names>R</given-names></name></person-group><article-title>R: a language for data analysis and graphics</article-title><source>J Computat Graph Stat</source><year>1996</year><volume>5</volume><issue>3</issue><fpage>299</fpage><lpage>314</lpage></element-citation></ref></ref-list></back></article>