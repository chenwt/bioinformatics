<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="en"><?DTDIdentifier.IdentifierValue article.dtd?><?DTDIdentifier.IdentifierType system?><?SourceDTD.DTDName article.dtd?><?SourceDTD.Version 1.0?><?ConverterInfo.XSLTName bmc2nlmx2.xsl?><?ConverterInfo.Version 2?><front><journal-meta><journal-id journal-id-type="nlm-ta">Biol Direct</journal-id><journal-id journal-id-type="iso-abbrev">Biol. Direct</journal-id><journal-title-group><journal-title>Biology Direct</journal-title></journal-title-group><issn pub-type="epub">1745-6150</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">3599581</article-id><article-id pub-id-type="publisher-id">1745-6150-7-33</article-id><article-id pub-id-type="pmid">23031190</article-id><article-id pub-id-type="doi">10.1186/1745-6150-7-33</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>Stable feature selection and classification algorithms for multiclass microarray data</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="A1"><name><surname>Student</surname><given-names>Sebastian</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>sebastian.student@polsl.pl</email></contrib><contrib contrib-type="author" id="A2"><name><surname>Fujarewicz</surname><given-names>Krzysztof</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>krzysztof.fujarewicz@polsl.pl</email></contrib></contrib-group><aff id="I1"><label>1</label>Institute of Automatic Control, Silesian University of Technology, Akademicka 16, 44-100 Gliwice, Poland</aff><pub-date pub-type="collection"><year>2012</year></pub-date><pub-date pub-type="epub"><day>2</day><month>10</month><year>2012</year></pub-date><volume>7</volume><fpage>33</fpage><lpage>33</lpage><history><date date-type="received"><day>16</day><month>4</month><year>2012</year></date><date date-type="accepted"><day>7</day><month>9</month><year>2012</year></date></history><permissions><copyright-statement>Copyright &#x000a9;2012 Student and Fujarewicz; licensee BioMed Central Ltd.</copyright-statement><copyright-year>2012</copyright-year><copyright-holder>Student and Fujarewicz; licensee BioMed Central Ltd.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0"><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0">http://creativecommons.org/licenses/by/2.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xlink:href="http://www.biology-direct.com/content/7/33"/><abstract><sec><title>Background</title><p>Recent studies suggest that gene expression profiles are a promising alternative for clinical cancer classification. One major problem in applying DNA microarrays for classification is the dimension of obtained data sets. In this paper we propose a multiclass gene selection method based on Partial Least Squares (PLS) for selecting genes for classification. The new idea is to solve multiclass selection problem with the PLS method and decomposition to a set of two-class sub-problems: one versus rest (OvR) and one versus one (OvO). We use OvR and OvO two-class decomposition for other recently published gene selection method. Ranked gene lists are highly unstable in the sense that a small change of the data set often leads to big changes in the obtained ordered lists. In this paper, we take a look at the assessment of stability of the proposed methods. We use the linear support vector machines (SVM) technique in different variants: one versus one, one versus rest, multiclass SVM (MSVM) and the linear discriminant analysis (LDA) as a classifier. We use balanced bootstrap to estimate the prediction error and to test the variability of the obtained ordered lists.</p></sec><sec><title>Results</title><p>This paper focuses on effective identification of informative genes. As a result, a new strategy to find a small subset of significant genes is designed. Our results on real multiclass cancer data show that our method has a very high accuracy rate for different combinations of classification methods, giving concurrently very stable feature rankings.</p></sec><sec><title>Conclusions</title><p>This paper shows that the proposed strategies can improve the performance of selected gene sets substantially. OvR and OvO techniques applied to existing gene selection methods improve results as well. The presented method allows to obtain a more reliable classifier with less classifier error. In the same time the method generates more stable ordered feature lists in comparison with existing methods.</p></sec><sec><title>Reviewers</title><p>This article was reviewed by Prof Marek Kimmel, Dr Hans Binder (nominated by Dr Tomasz Lipniacki) and Dr Yuriy Gusev</p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>Recent studies suggest that gene expression profiles may represent a promising alternative for clinical cancer classification. Molecular-based approaches have opened the possibility of investigating the activity of thousands of genes simultaneously and can be used to find genes involved in neoplasia. A well known problem in applying microarrays in classification problem is dimension of obtained datasets. In work [<xref ref-type="bibr" rid="B1">1</xref>] authors listed three main sources of the instability of feature selection in biomarker discovery: choosing selection algorithms without considering stability, the existence of multiple sets of true markers and small number of samples. They suggested that the problem of small number of samples in high dimensional feature space is the most difficult one in biomarker discovery. Other authors indicate a technical problems, like post-hybridization washing [<xref ref-type="bibr" rid="B2">2</xref>], or chip-specific systematic variations on the raw intensity level [<xref ref-type="bibr" rid="B3">3</xref>], which can cause errors in computed expression levels and may have a big influence on the instability of feature selection. In [<xref ref-type="bibr" rid="B4">4</xref>] authors denoted the same problems not only for microarray data, but also for proteomic mass spectometry data. Traditional statistical methodology for classification does not work well when there are more variables than samples. Thus, methods able to cope with the high dimensionality of the data are needed. In this paper we focus on multiclass feature selection and classification problem, which are intrinsically more difficult than their binary counterparts [<xref ref-type="bibr" rid="B5">5</xref>]. Gene selection for a classifier is a very important problem. Over the past few years many algorithms were proposed to solve this problem. However, most of the studies are designed for dimension reduction in two-class problems and only a few of them involve multiclass cases. In [<xref ref-type="bibr" rid="B6">6</xref>,<xref ref-type="bibr" rid="B7">7</xref>] authors underline, that selection of informative features for a classifier is a crucial and delicate task. The optimal selection of informative genes for multiclass analysis is still an open problem. We propose a gene selection method based on Partial Least Squares (PLS) [<xref ref-type="bibr" rid="B8">8</xref>,<xref ref-type="bibr" rid="B9">9</xref>]. Then we compare the results with the multiclass gene selection method proposed in [<xref ref-type="bibr" rid="B10">10</xref>], Recursive Feature Elimination (RFE) method [<xref ref-type="bibr" rid="B7">7</xref>] and the classical t-statistics.</p><p>The standard way to use the PLS algorithm is for feature extraction only and not for selecting significant features. Here, we use this method for gene ranking. In [<xref ref-type="bibr" rid="B8">8</xref>] it has been shown how to use the PLS method for multiclass feature extraction. Also in [<xref ref-type="bibr" rid="B11">11</xref>] the author considers a PLS-based method to gene selection, but for 2-class data only. The new idea is to use the PLS for multiclass feature selection. A well known method of solving the multiclass feature selection problem is to take into consideration &#x02018;all classes at once&#x02019;.</p><p>We propose a new method based on decomposition of a multiclass feature selection problem into a set of two-class problems that are used in one versus rest (OvR) and one versus one (OvO) techniques.</p><p>An important aspect of feature selection methods is the stability of obtained ordered lists [<xref ref-type="bibr" rid="B1">1</xref>,<xref ref-type="bibr" rid="B12">12</xref>]. In [<xref ref-type="bibr" rid="B1">1</xref>] we can find a review that summarizes some stable feature selection methods and a big range of stability measures. Authors have noted that stable feature selection is a very important problem, and they have suggested to pay more attention on it.</p><p>In literature [<xref ref-type="bibr" rid="B13">13</xref>] most of the feature selection and classification methods are compared based on the accuracy rate only. In general we can define the accuracy rate, as the percentage of correctly classified probes among all probes (in most cases in the validation set). It is very difficult to evaluate the methods only by the small differences in accuracy rate. In this paper we use the stability criterion and accuracy rate to clearly compare different gene ranking methods. By better stability, we mean less variability of the ranked lists obtained with the same method, but with slightly modified datasets. The stability problem of gene lists is very important for their validation by biological methods and for the clinical applicability of molecular markers. For example, for long gene lists, experimentalists will test only the most important genes, in this case the top-ranked genes.</p></sec><sec sec-type="methods"><title>Methods</title></sec><sec><title>Symbols and abbreviations</title><p><italic>l</italic> &#x02014; number of samples; <italic>m</italic> &#x02014; number of genes; <italic>g</italic> &#x02014; number of selected genes; <italic>L</italic> &#x02014; list of selected genes; <italic>K</italic> &#x02014; number of classes; <italic>B</italic> &#x02014; number of bootstrap samples; PLS &#x02014; Partial least squares regression method; <italic>s</italic> &#x02014; number of PLS components; <italic>w</italic> &#x02014; PLS weight vector; SIMPLS, NIPALS &#x02014; names of two used PLS algorithms; PLS+MCLASS &#x02014; PLS based multiclass gene selection method with &#x02018;all classes at once&#x02019; approach; PLS+OvO &#x02014; PLS based multiclass gene selection method with &#x02018;one versus one&#x02019; decomposition; PLS+OvR &#x02014; PLS based multiclass gene selection method with &#x02018;one versus rest&#x02019; decomposition; GS &#x02014; gene selection method proposed in [<xref ref-type="bibr" rid="B10">10</xref>]; RFE &#x02014; Recursive Feature Elimination gene selection method; <italic>s</italic><sub>1</sub>, <italic>s</italic><sub>2</sub> &#x02014; stability score indicators; SVM OvO, SVM OvR, MSVM &#x02014; support vector machines based classification methods; LDA &#x02014; linear discriminant analysis classification method;</p></sec><sec><title>Bootstrap resampling</title><p>We use bootstrap technique [<xref ref-type="bibr" rid="B14">14</xref>] which has good performance for relatively small sample classification problems [<xref ref-type="bibr" rid="B15">15</xref>]. In literature we can find many publication using bootstrap resampling for genomic data [<xref ref-type="bibr" rid="B16">16</xref>-<xref ref-type="bibr" rid="B21">21</xref>]. Of course, the best way to test classification and gene selection methods is to use an independent dataset. However, without such a dataset, the resampling approach is one of the best choice. For example in [<xref ref-type="bibr" rid="B16">16</xref>] we can see that resampling technique is useful for microarray data analysis, and the results can be validated by qPCR analysis with an extra and independent set of samples not used in the main analysis. In our opinion the main problem in case of microarray results validation is to find proper gene selection method for analyzed data.</p><p>Let us consider a dataset of size <italic>l</italic>, where <bold><italic>X</italic></bold>=(<italic>x</italic><sub>1</sub><italic>x</italic><sub>2</sub>,&#x02026;,<italic>x</italic><sub><italic>l</italic></sub>) is the input matrix and <bold><italic>Y</italic></bold>=(<italic>y</italic><sub>1</sub><italic>y</italic><sub>2</sub>,&#x02026;,<italic>y</italic><sub><italic>l</italic></sub>) is the response (class labels). For multiclass problem <italic>y</italic><sub><italic>i</italic></sub>&#x02208;{1,2,&#x02026;,<italic>K</italic>}, where <italic>K</italic> is the number of classes. The bootstrap sample is a random sample with replacement of the observations and has the same size as our original dataset. The probes that appear in a bootstrap sample constitute a training dataset. The rest of observations is used as a test dataset. This is done <italic>B</italic> times to produce <italic>B</italic> bootstrap samples. To divide our samples into training and test datasets we use the balanced bootstrap method [<xref ref-type="bibr" rid="B22">22</xref>,<xref ref-type="bibr" rid="B23">23</xref>]. The balanced bootstrap is a modified version of the bootstrap method that can reduce error variance and bias over the standard bootstrap method. This method forces each observation to occur in total <italic>B</italic> times in the collection of <italic>B</italic> bootstrap samples. This does not mean that all samples should occur in every bootstrap sample, because the first observation can occur for example twice in the first bootstrap sample and not at all in the second. We can do this by constructing a set with <italic>B</italic> copies of all <italic>l</italic> observations and then permuting the obtained set. Every <italic>l</italic>-element successive subset is one bootstrap sample.</p><p>The bootstrap resampling is computationally costly. We implemented it on a computer cluster using the MatlabMPI toolbox for parallel computation. The most important parameter for the bootstrap resampling technique is the number of resampling iterations <italic>B</italic>. We must find the compromise between analysis time and accuracy of predicted parameters. In our cases we use 500 resampling iterations of all stages of the classifier construction (i.e. gene preselection, gene selection and classifier learning). We did not observed significant changes in the results for all used datasets, after increasing the number of iterations. Of course, the necessary iterations number can change after changing the dataset and depends especially on the number of probes. We generated 500 bootstrap samples only once to reduce the variability of results for all tested methods. The distribution of the misclassification rate obtained during all bootstrap runs was used to estimate the 95% confidence interval. The accuracy of the classifier and the confidence interval were calculated for subsets of first genes on the lists up to 30 genes.</p><sec><title>Prediction error estimation</title><p>To estimate the prediction error (accuracy) we used the.632+ estimator [<xref ref-type="bibr" rid="B24">24</xref>]. The.632+ estimator described by Efron provides protection of overfitting, especially important for methods like SVM, where the resubstitution error is very small. In extreme case, when the resubstitution error is very small, and much smaller than the test error, the.632 [<xref ref-type="bibr" rid="B25">25</xref>] estimator provides too optimistic estimates for the true error. In this situation the.632+ estimator takes more weight to the test error part, than the.632 estimator. The detailed description for the.632+ estimator is given in the Appendix.</p></sec></sec><sec><title>PLS-based feature selection method</title><p>In this section we propose a new method for selecting the most significant genes. It is based on partial least squares regression (PLSR) [<xref ref-type="bibr" rid="B26">26</xref>]. There are some other regression methods like Lasso method [<xref ref-type="bibr" rid="B27">27</xref>] or ridge regression [<xref ref-type="bibr" rid="B28">28</xref>]. It was shown that PLS method outperforms Lasso method in terms of identifying relevant predictors [<xref ref-type="bibr" rid="B29">29</xref>]. We also do not use the ridge regression, where it is a problem with estimation the ridge parameter. PLSR method is well known as a method for feature extraction [<xref ref-type="bibr" rid="B8">8</xref>,<xref ref-type="bibr" rid="B30">30</xref>,<xref ref-type="bibr" rid="B31">31</xref>], but its application for selecting significant genes is less evident. PLS feature extraction method can be used for significance analysis of gene expression data [<xref ref-type="bibr" rid="B32">32</xref>,<xref ref-type="bibr" rid="B33">33</xref>]. The authors of [<xref ref-type="bibr" rid="B34">34</xref>] used jackknife of PLS components to interpret the importance of the variables (genes) for the PLS model. When we use the feature extraction techniques like those based on projection (e.g. principal component analysis) or compression (e.g. based on information theory), we use all genes in our model (with different weights), and the accuracy of the classifier is estimated for all of the genes. In contrast to feature extraction, feature selection techniques do not alter the original representation of the variables, but only select their subset. Feature selection is very important for biomarker discovery, specifically for RT-PCR experiment and leads to new knowledge about the biology of the disease. In that case, the genes selected are more important than the classifier used. In Boulesteix [<xref ref-type="bibr" rid="B31">31</xref>,<xref ref-type="bibr" rid="B35">35</xref>], the PLS connection to other statistical methods is described. Boulesteix proved that in case of the data matrix scaled to unit variance and two-class classification the lists of genes obtained with ordered squared weight vector <bold><italic>w</italic></bold><sup>2</sup> from the first PLS component is of the same order as from F-statistics. It is equivalent to the t-test with equal variance and also with the BSS/WSS-statistics, where BSS denotes the between-group sum of squares and WSS the within-group sum of squares. In our comparison we did not scale the data to unit variance, but only centered the data. Boulesteix and Strimmer [<xref ref-type="bibr" rid="B35">35</xref>] describe and refer the connection of PLS to gene selection based on &#x0201c;variable importance in projection&#x0201d; (VIP) indicator proposed by Musumarra et al. [<xref ref-type="bibr" rid="B36">36</xref>], which indicates the importance of genes in the used PLS latent components. Musumarra et al. described the PLS method as dimension reduction method and used the weight vectors to order genes in term of their relevance for classification problem. The main difference between our approach and VIP indicator is that in VIP method the latent components for classifier and the weight vector are used only for measure of the importance of each gene in PLS model.</p><p>In this paper we use the weight vector obtained from the PLS method to select the most important genes.</p><p>PLS aims at finding uncorrelated linear transformations of the original input features which have high covariance with the response features. Based on these latent components, PLS predicts response features (the task of regression) and reconstructs an original dataset matrix (the task of data modeling) at the same time. For dataset matrix <bold><italic>X</italic></bold> of size <italic>l</italic>&#x000d7;<italic>m</italic> with <italic>l</italic> probes and <italic>m</italic> genes we denote the <italic>l</italic>&#x000d7;1 vector of response value <bold><italic>y</italic></bold>. The PLS components <bold><italic>t</italic></bold><sub><italic>i</italic></sub><italic>i</italic>=1,&#x02026;,<italic>s</italic>are constructed to maximize the objective criterion based on the sample covariance between <bold><italic>y</italic></bold> and linear combination of genes (PLS components) <bold><italic>t</italic></bold>=<bold><italic>Xw</italic></bold>. We search the weight vector <bold><italic>w</italic></bold>sequentially, to satisfy the following criterion </p><p><disp-formula id="bmcM1"><label>(1)</label><mml:math id="M1" name="1745-6150-7-33-i1" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi>argmax</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder><mml:mspace width="2.77695pt"/><mml:msup><mml:mrow><mml:mtext>cov</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>subject to the orthogonality constraint </p><p><disp-formula id="bmcM2"><label>(2)</label><mml:math id="M2" name="1745-6150-7-33-i2" overflow="scroll"><mml:mtable class="align" columnalign="right left"><mml:mtr><mml:mtd class="align-1"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="2em"/><mml:mn>1</mml:mn><mml:mo>&#x02264;</mml:mo><mml:mi>i</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mi>j</mml:mi><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mspace width="2em"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd class="align-1"><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mtd><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02032;</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mi>.</mml:mi><mml:mspace width="2em"/></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>This criterion is the mostly used in literature as general description for PLS method. In case of multiclass categorical data this criterion can be simplified as mentioned in [<xref ref-type="bibr" rid="B37">37</xref>] and maximize var(<bold><italic>X</italic></bold><bold><italic>w</italic></bold>) Cor<sup>2</sup>(<bold><italic>X</italic></bold><bold><italic>w</italic></bold><bold><italic>Y</italic></bold>). To derive components (named &#x0201c;latent variables&#x0201d; or scores), <bold><italic>t</italic></bold><sub><italic>i</italic></sub>(<italic>i</italic>=1,&#x02026;,<italic>s</italic>), the PLS decomposes <bold><italic>X</italic></bold>and <bold><italic>y</italic></bold> to produce a bilinear representation of the data [<xref ref-type="bibr" rid="B38">38</xref>]</p><p><disp-formula id="bmcM3"><label>(3)</label><mml:math id="M3" name="1745-6150-7-33-i3" overflow="scroll"><mml:mtable class="align" columnalign="left"><mml:mtr><mml:mtd class="align-1"><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mtd><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">E</mml:mi><mml:mspace width="2em"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd class="align-1"><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mtd><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>,</mml:mo><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mspace width="2em"/></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>where <bold><italic>p</italic></bold><sub><bold><italic>i</italic></bold></sub> are loadings, <italic>q</italic><sub><italic>i</italic></sub> are scalars and <bold><italic>E</italic></bold><bold><italic>f</italic></bold> are residuals. The idea of PLS is to estimate loadings and scores by a regression. The PLS fits a sequence of bilinear models by least squares. At every step <italic>i</italic>(<italic>i</italic>=1,&#x02026;,<italic>s</italic>) vector <bold><italic>w</italic></bold><sub><italic>i</italic></sub> is estimated to obtain the PLS component that has maximal sample covariance with the response variable <bold><italic>y</italic></bold>. Each component <bold><italic>t</italic></bold><sub><italic>i</italic></sub>is uncorrelated with all previously constructed components. There are two main PLS algorithms described in literature: NIPALS algorithm [<xref ref-type="bibr" rid="B39">39</xref>] and SIMPLS algorithm [<xref ref-type="bibr" rid="B40">40</xref>]. The SIMPLS algorithm, is different from NIPALS in two important ways: first, successive <italic>t</italic><sub><italic>i</italic></sub>components are calculated explicitly as linear combinations of X and second, X is not deflated in each iteration. The SIMPLS algorithm will be assessed in accordance with the criteria eq. (1). In NIPALS the first PLS component <bold><italic>t</italic></bold><sub>1</sub> is obtained on the basis of the covariance between <bold><italic>X</italic></bold>and <bold><italic>y</italic></bold>, and is qual to the first component of SIMPLS algorithm. Component <bold><italic>t</italic></bold><sub><italic>i</italic></sub>(<italic>i</italic>=2,&#x02026;,<italic>s</italic>), is computed using the residuals of <bold><italic>X</italic></bold>and <bold><italic>y</italic></bold> from the previous step, which account for the variations left by the previous components. Maximal number of components <italic>s</italic> is equal to the rank of <bold><italic>X</italic></bold>.</p><p>As we say before the weight vector from SIMPLS algorithm sometimes referred to <bold><italic>r</italic></bold> is applied to the original <bold><italic>X</italic></bold> matrix and De Jong [<xref ref-type="bibr" rid="B40">40</xref>] showed that we can calculate the weights <bold><italic>r</italic></bold>directly from the NIPALS algorithm </p><p><disp-formula id="bmcM4"><label>(4)</label><mml:math id="M4" name="1745-6150-7-33-i4" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02032;</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>where <bold><italic>p</italic></bold><sub><italic>i</italic></sub> are the loading and <bold><italic>w</italic></bold><sub><italic>i</italic></sub>are the weight vector for i-th component of NIPALS algorithm.</p><p>De Jong proved in [<xref ref-type="bibr" rid="B40">40</xref>] that for univariate response the score vectors <bold><italic>t</italic></bold><sub><bold><italic>i</italic></bold></sub>(<italic>i</italic>=<italic>i</italic>,&#x02026;,<italic>s</italic>) for NIPALS and SIMPLS algorithms are the same. In contrast to score vectors, the weight vectors <bold><italic>w</italic></bold><sub><bold><italic>i</italic></bold></sub> and <bold><italic>r</italic></bold><sub><bold><italic>i</italic></bold></sub> for NIPALS and SIMPLS respectively are different for <italic>i</italic>&#x0003e;1. This phenomenon is a consequence of different method to compute the weights vectors. The <bold><italic>w</italic></bold><sub><bold><italic>i</italic></bold></sub>vectors in NIPALS procedure are calculated with deflated data matrices <bold><italic>X</italic></bold><sub><bold><italic>i</italic></bold></sub> and <bold><italic>Y</italic></bold><sub><bold><italic>i</italic></bold></sub> in each iteration, and the weights <bold><italic>r</italic></bold><sub><bold><italic>i</italic></bold></sub>are obtained without the deflation step in SIMPLS algorithm. For this reason in this paper, we use the weight vectors <bold><italic>w</italic></bold> and <bold><italic>r</italic></bold>from both algorithms to determine the ranked list. In our method the sum of the <inline-formula><mml:math id="M5" name="1745-6150-7-33-i5" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math></inline-formula> over the <italic>s</italic> PLS components presents the gene importance vector and the &#x0201c;best genes&#x0201d; have the highest values in this vector. First <italic>g</italic> genes with the highest value in the gene importance vector are selected for the classifier. To test the optimal number of components we use the first squared weight vector and the sum of squared weight vectors from first 5 and 10 components. The standard way to use PLS for a multiclass data, is to search for the best direction for maximization of the covariance between responses with all classes and linear combination of genes. As we mentioned before, we compare our method based on decomposition of a multi-class feature selection problem into a set of two-class problems with a well known &#x02018;all classes at once&#x02019; technique. For each two-class selections &#x0201c;best genes&#x0201d; are selected and one ranked gene list is constructed as follows: genes with the highest weight in all two-class selections are located at the top of the list, then genes with the second highest weights, and so on. We must underline, that <bold><italic>y</italic></bold>for two-class selections is coded as a vector with value 1 for the first class and &#x02212;1 for the second class. For the &#x02018;all classes at once&#x02019; technique <bold><italic>y</italic></bold>is a matrix with <italic>N</italic> rows and the number of columns is equal to the number of classes. In each row a class label has a value of 1 and &#x02212;1. For our needs we introduce the notation PLS+MCLASS for &#x02018;all classes at once&#x02019; technique and similarly PLS+OvO, PLS+OvR for two-class decomposition of the multiclass feature selection problem. On the Figure <xref ref-type="fig" rid="F1">1</xref> we show the principals and essentials of the introduced method.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p>PLS based gene selection method with two-class decomposition technique.</p></caption><graphic xlink:href="1745-6150-7-33-1"/></fig></sec><sec><title>Stability analysis for ordered gene lists</title><p>In [<xref ref-type="bibr" rid="B6">6</xref>,<xref ref-type="bibr" rid="B41">41</xref>] authors have used resampling technique for testing the significance of the obtained results of microarray analysis. They have examined the influence of sample class label permutations and selection of exact number of randomly selected features on the classification accuracy. We can find in literature various applications of bootstrap technique for example to assess the stability of the cell lines cluster dendrogram in unsupervised microarray analysis [<xref ref-type="bibr" rid="B42">42</xref>]. In our article we use bootstrap resampling to examine the stability of obtained gene lists. By stability of an obtained gene list we understand similarity between lists from the same experiment, but with a slightly changed data set. To show the distance between different gene selection methods we use a method based on bootstrap resampling. This approach is based on the comparison of sets consisting of a fixed number of the top <italic>g</italic> genes. In this framework we consider the list <bold><italic>L</italic></bold> with first <italic>g</italic> top-genes obtained from the entire dataset and lists <bold><italic>L</italic></bold><sub><italic>b</italic></sub>;<italic>b</italic>=1,2,&#x02026;,<italic>B</italic>obtained from every <italic>b</italic> of <italic>B</italic> bootstrap iterations.</p><p>In this paper we assess stability in two ways. The first one is to calculate stability indices. In this case we have used Percentage of Overlapping Genes (POG) criterion [<xref ref-type="bibr" rid="B43">43</xref>] and modified POG indicator. The POG criterion takes into account only the content of gene lists, and ignores the gene order. The modified POG indicator does not ignore the gene order on compared lists. Both indicators are detailed described in the Appendix.</p><p>The second one is to visualize how obtained gene lists are stable by looking at descriptive plots. In the next section we introduce the detailed description of the stability plots used in this article.</p><sec><title>Stability plots</title><p>To visualize the stability of the ordered gene lists we plot the boxplots of rank for each gene in the list <bold><italic>L</italic></bold> against ranks in all <italic>b</italic> bootstrap iteration lists <bold><italic>L</italic></bold><sub><italic>b</italic></sub>;<italic>b</italic>=1,2,&#x02026;,<italic>B</italic>. We set the limit to determine which points are extreme to the rank out of the <italic>g</italic> gene list. Another way to visualize gene lists stability is to plot a so-called Bootstrap Based Feature Ranking (BBFR) plot [<xref ref-type="bibr" rid="B44">44</xref>]. The BBFR score, in opposite to indices <italic>s</italic><sub>1</sub>and <italic>s</italic><sub>2</sub>, is calculated separately for each gene. The BBFR score for the gene number <italic>j</italic> is defined as </p><p><disp-formula id="bmcM5"><label>(5)</label><mml:math id="M6" name="1745-6150-7-33-i6" overflow="scroll"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">bj</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="italic">Bg</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>where <italic>r</italic><sub><italic>bj</italic></sub> is the <italic>rank</italic> of the <italic>j</italic>-th gene in <italic>b</italic>-th bootstrap iteration </p><p><disp-formula id="bmcM6"><label>(6)</label><mml:math id="M7" name="1745-6150-7-33-i7" overflow="scroll"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">bj</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">bj</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:math></disp-formula></p><p>for the top-scored gene <italic>r</italic><sub><italic>bj</italic></sub>=<italic>g</italic>.</p><p>The maximum possible value of the <italic>Q</italic><sub><italic>j</italic></sub>score is 1. It means that one gene was top-ranked in all <italic>B</italic> bootstrap iterations. The score <italic>Q</italic><sub><italic>j</italic></sub> takes into account the rank <italic>r</italic><sub><italic>bj</italic></sub>of <italic>j</italic>-th gene in all <italic>B</italic> bootstrap iterations.</p><p>The modified BBFR score <inline-formula><mml:math id="M8" name="1745-6150-7-33-i8" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02032;</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> takes into account only the presence of the gene <italic>j</italic> in the lists <italic>L</italic><sub><italic>b</italic></sub>;<italic>b</italic>=1,2,&#x02026;,<italic>B</italic></p><p><disp-formula id="bmcM7"><label>(7)</label><mml:math id="M9" name="1745-6150-7-33-i9" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02032;</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:munderover><mml:mi>I</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">bj</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02264;</mml:mo><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:mfrac><mml:mi>.</mml:mi></mml:math></disp-formula></p><p>The maximum possible value of the <inline-formula><mml:math id="M10" name="1745-6150-7-33-i10" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02032;</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> score is 1. The 0 value indicates genes not included on the gene lists in all bootstrap iterations.</p><p>Both <italic>Q</italic><sub><italic>j</italic></sub>and <inline-formula><mml:math id="M11" name="1745-6150-7-33-i11" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02032;</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> indices are sorted and plotted in descending order. In this paper we use only the second ranking plot <inline-formula><mml:math id="M12" name="1745-6150-7-33-i12" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02032;</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula>. In the ideal case (when gene lists are perfectly reproducible) the <inline-formula><mml:math id="M13" name="1745-6150-7-33-i13" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>&#x02032;</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> plot reaches a value of 1 for the first <italic>g</italic> genes and 0 for the rest.</p></sec></sec><sec><title>Datasets</title><p>In our study we chose three publicly available multiclass microarray datasets. The first is the LUNG dataset published by [<xref ref-type="bibr" rid="B45">45</xref>]. It consists of 254 samples of 4 subtypes of lung carcinomas and normal samples. Samples were normalized by RMA and GA annotation [<xref ref-type="bibr" rid="B46">46</xref>]. Each sample has 8359 gene expression levels after re-annotation. The data is available at <ext-link ext-link-type="uri" xlink:href="http://www.broadinstitute.org/mpr/lung/">http://www.broadinstitute.org/mpr/lung/</ext-link>. The second is the MLL dataset published by [<xref ref-type="bibr" rid="B47">47</xref>]. It consists of 72 samples of 3 subtypes of leukemia cancer classes. Samples was normalized by RMA and GA annotation [<xref ref-type="bibr" rid="B46">46</xref>]. Each sample has 8359 gene expression levels after re-annotation. The data is available at <ext-link ext-link-type="uri" xlink:href="http://www.broadinstitute.org/cgi-bin/cancer/publications/pub_paper.cgi?mode=view&#x00026;paper_id=63">http://www.broadinstitute.org/cgi-bin/cancer/publications/pub_paper.cgi?mode=view&#x00026;paper_id=63</ext-link>. The third is the SRBCT dataset published by [<xref ref-type="bibr" rid="B48">48</xref>]. It consists of 83 samples of 4 subtypes of small, round blue cell tumors. Each sample has 2308 gene expression levels. The data is available at <ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/content/supplementary/1471-2105-7-228-s4.tgz">http://www.biomedcentral.com/content/supplementary/1471-2105-7-228-s4.tgz</ext-link>[<xref ref-type="bibr" rid="B10">10</xref>]. The results for the LUNG dataset are presented in the main body of this paper, and the results for MLL and SRCT datasets are presented in the Appendix section.</p></sec><sec><title>Results and Discussion</title><p>We chose three multiclass microarray datasets (detailed described in the Datasets section) for our experiments.</p><p>For the numerical experiment we use SVM method classification method in three variants OvO, OvR, MSVM and LDA method. These methods are common used in microarray classification problems [<xref ref-type="bibr" rid="B49">49</xref>-<xref ref-type="bibr" rid="B51">51</xref>]. We demonstrate the usefulness of the proposed methodology to select significant genes with decomposition technique and the PLS method. All methods: PLS+OvO, PLS+OvR and PLS+MCLASS were tested and compared with other methods. As it has been mentioned before, we executed 500 bootstrap iterations for each method. Because the most important task is to find a small number of informative genes, we classify this data in every bootstrap iteration for diverse number of best genes up to 30 genes. In Tables 1, 2 and 3 (Tables are available in the Appendix) we collect all results for all tested methods. For all plots we use the classifier with the best classification rate chosen separately for all tested method. The PLS algorithm and the number of PLS components were chosen with respect to the best accuracy rate criterion. In most cases the <bold><italic>r</italic></bold> vector calculated from SIMPLS method was better than the vector <bold><italic>w</italic></bold>calculated from NIPALS algorithm for more than one component. Only for PLS+MCLASS method the accuracy rate is higher when we use more than 1 PLS component. In our study we also applied a method searching for the optimal number of components based on leave one out classification error on training samples and the SVM classifier (results not showed here). In general the results for classification accuracy rate were not significantly better and in some cases even worse. In all tables we bolded the best accuracy rate for tested classification methods and variants of PLS method (algorithm and number of PLS components). In the last columns we show the standard deviations values for the best classifier. The comparison of accuracy rate and stability index <italic>s</italic><sub>2</sub>for all tested datasets proves the advantage of the PLS method (Figure <xref ref-type="fig" rid="F2">2</xref>). In all cases stability index <italic>s</italic><sub>2</sub> for the PLS method with decomposition technique is higher than the score for the PLS+MCLASS method. Only for the LUNG dataset the stability index for decomposition version of the GS method is lower than with the GS+MCLASS method (Figure <xref ref-type="fig" rid="F2">2</xref>). However, in this case, the accuracy rate for the GS+MCLASS was about 3% lower than for the GS+OvO method. Consequently, looking at all the classification accuracies and the 95% confidence interval as shown in Tables 1, 2 and 3, one general conclusion is that there are no significant differences between best gene selection methods. Typically, our methods outperform the other methods when we compare the stability index. Another conclusion is that more components spoil the stability of obtained genes lists and the classification error is not significantly smaller.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Stability index</bold><bold><italic>s</italic></bold><sub><bold><italic>2</italic></bold></sub><bold>(bar chart) and accuracy of classification (dot chart) with the 95% confidence interval of the best classifier on the tested feature selection methods for LUNG data.</bold></p></caption><graphic xlink:href="1745-6150-7-33-2"/></fig><p>On Figure <xref ref-type="fig" rid="F3">3</xref> we can see how many genes we need to obtain good prediction. For the arbitrary changed number of features selected we built the model and estimate the accuracy rate. We do not use the accuracy rate to estimate the number of selected genes as in backward elimination features selection. When we compare the results for different datasets (for example Figure <xref ref-type="fig" rid="F3">3</xref>, and Figure 8, Figure 9 from Appendix), we can see, that in all cases the two class decomposition based gene selection methods are better for different number of selected genes, when we consider the accuracy rate into account. However, we can see that there are big differences between used methods, especially, when we use a very small number of genes. We also observe, slight different accuracy results for the different data sets and selected gene number, especially in the dynamics of accuracy rate for increased number of genes. This means, that the number of selected genes depends on dataset used and is important for distinguish the best gene selection method (for example comparison of Accuracy rate results for LUNG data on Figure <xref ref-type="fig" rid="F3">3</xref> and for MLL data set Figure 8 from Appendix).</p><fig id="F3" position="float"><label>Figure 3</label><caption><p>Accuracy of classification obtained by successive gene set reduction selected with all feature selection methods of the best classifier for LUNG data.</p></caption><graphic xlink:href="1745-6150-7-33-3"/></fig><p>In all tested datasets the 30 genes were sufficient enough to obtain a high accuracy rate. In all datasets the decomposition variants of the GS method outperform the GS+MCLASS method. The PLS+OvO and PLS+OvR methods perform at least comparably well and for the MLL dataset the accuracy rate was higher for different number of selected genes.</p><p>The bootstrap-based feature ranking (BBFR) is computed for a list of 30 genes. The BBFR ranking (Figure <xref ref-type="fig" rid="F4">4</xref>) and the boxplots of rank for each gene in the bootstrap lists versus the whole dataset gene list (Figure <xref ref-type="fig" rid="F5">5</xref>) confirm the advantage of the proposed gene selection method. For all datasets only the BBFR curves for PLS+OvO and PLS+OVR are very close to ideal curve. This means that the same genes are reselected frequently in most bootstrap iterations. In Tables 1, 2 and 3 we can see, that for the PLS method we observe the smallest number of all genes selected in all bootstrap iteration 30-genes lists (reselected genes column). That means, that the reproducibility of the PLS method is very high in contrast to other methods, where we observe more than one hundred genes more. Our conclusion for different number of selected genes is confirmed by the boxplots in Figure <xref ref-type="fig" rid="F5">5</xref> for tested methods. The figures illustrate how close the bootstrap based feature ranking is to the ranking obtained from the whole datasets for the first 30 genes. The red line indicate the ideal case. The best reproducibility is found with the PLS method. The worst reproducibility is found for the classical T-TEST and RFE method.</p><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Results of bootstrap-based feature ranking (BBFR) for the first 50 genes for LUNG data.</bold> In the ideal case (when gene lists are perfectly reproducible) the BBFR score reaches a value of 1 for the first selected genes and 0 for the rest (black curve).</p></caption><graphic xlink:href="1745-6150-7-33-4"/></fig><fig id="F5" position="float"><label>Figure 5</label><caption><p>Comparison of rank boxplots in the bootstrap samples against rank in the original data set on all tested methods for LUNG data.</p></caption><graphic xlink:href="1745-6150-7-33-5"/></fig></sec><sec sec-type="conclusions"><title>Conclusions</title><p>In this paper we proposed a new PLS-based method to select significant genes. Our results have shown that this gene selection method gives very good accuracy rate and stability of obtained gene lists. The principal of PLS is based on the maximization of the covariance criterion, which can lead to good generalization ability and stability. In our opinion this is a reason of the good results obtained with PLS method. Another important result is the fact that it is more effective to solve a multiclass feature selection by splitting it into a set of two-class problems and merging the results in one gene list. The explanation for these result can be the difference between used methods: the idea of MCLASS approach is to look for genes able to distinguish between all classes simultaneously. Such genes are more difficult to find, and they can have smaller discriminatory power. This problem do not exist in the decomposed multiclass problem for OvO and OvR approaches. From the methodological side we suppose, that the MCLASS multiclass feature selection methods are not so good developed, as the 2-class methods, and this fact can be the explanation for our results. The comparison to other feature selection methods shows that the gene lists stability index is the highest for PLS with OvR and OvO techniques. In two cases the stability index is slightly better for PLS+MCLASS method with one PLS component, but the accuracy rate for this method is significantly worse. All other methods indicated much worse stability of obtained gene lists. We can observe that using the GS method with 2-class decomposition technique improves the accuracy rate and with two of the datasets gene list stability increased as well. Another advantage of the 2-class decomposition technique for gene selection methods is easy interpretation of the results by biologists. In all cases the &#x02018;all classes at once&#x02019; technique of PLS and GS methods achieves worse classification accuracy than their 2-class versions. The presented method makes it possible to obtain more stable gene selection lists and a more reliable classifier with less classifier error. We show that accuracy rate assessing accompanied with the gene stability analysis gives more reliable evaluation of various gene selection methods. Of course our methods can be applicable also to other high dimensional data where we consider classification problems such as protein microarrays, DNA copy number variation, exome profiling and RNAseq. In all cases, where the dataset has much more features than observations it is recommended to take into consideration the accuracy rate, but also the stability score.</p></sec><sec><title>Appendix</title><sec><title>Stability indices</title><p>In general there are two different approaches to measure the stability of gene lists. The first approach takes into account only the content of gene lists, and ignores the gene order. The second one does not ignore the gene order on compared lists.</p><p>One of the most frequently used criteria is the Percentage of Overlapping Genes (POG) [<xref ref-type="bibr" rid="B43">43</xref>], belonging to first class of stability measures. In the simplest case it measures the similarity between two lists <italic>L</italic><sub>1</sub> and <italic>L</italic><sub>2</sub> of the size <italic>g</italic>. Let <italic>k</italic> be the size of the intersection of <italic>L</italic><sub>1</sub>and <italic>L</italic><sub>2</sub>. Then POG is defined as <italic>s</italic><sub>1</sub>=<italic>k</italic>/<italic>g</italic>.</p><p>POG criterion may be extended in such a way that it measures the similarity between the list <bold><italic>L</italic></bold> and lists <bold><italic>L</italic></bold><sub><italic>b</italic></sub>;<italic>b</italic>=1,2,&#x02026;,<italic>B</italic>. Let <italic>u</italic><sub><italic>j</italic></sub> be the placement of the <italic>j</italic>-th gene in the list <bold><italic>L</italic></bold>. For the top-scored gene <italic>u</italic><sub><italic>j</italic></sub>=1. Similarly, <italic>u</italic><sub><italic>bj</italic></sub> is the placement of the <italic>j</italic>-th gene in the list <bold><italic>L</italic></bold><sub><italic>b</italic></sub>. The POG is calculated as </p><p><disp-formula id="bmcM8"><label>(8)</label><mml:math id="M14" name="1745-6150-7-33-i14" overflow="scroll"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:munderover><mml:mi>I</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02264;</mml:mo><mml:mi>g</mml:mi><mml:mo>&#x02227;</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">bj</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02264;</mml:mo><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="italic">Bg</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>where <italic>I</italic> denotes the indicator function </p><p><disp-formula id="bmcM9"><label>(9)</label><mml:math id="M15" name="1745-6150-7-33-i15" overflow="scroll"><mml:mi>I</mml:mi><mml:mo>(</mml:mo><mml:mi>A</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn><mml:mspace width="0.3em"/><mml:mspace width="0.3em"/><mml:mtext>if</mml:mtext><mml:mspace width="0.3em"/><mml:mspace width="0.3em"/><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="italic">true</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn><mml:mspace width="0.3em"/><mml:mspace width="0.3em"/><mml:mtext>if</mml:mtext><mml:mspace width="0.3em"/><mml:mspace width="0.3em"/><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="italic">false</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math></disp-formula></p><p>We introduce the modified relative <italic>s</italic><sub>2</sub>score to estimate the similarity between all lists </p><p><disp-formula id="bmcM10"><label>(10)</label><mml:math id="M16" name="1745-6150-7-33-i16" overflow="scroll"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:munderover><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">bj</mml:mtext></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="italic">Bg</mml:mi><mml:mo>(</mml:mo><mml:mi>g</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mi>.</mml:mi></mml:math></disp-formula></p><p>In opposite to previous indicator <italic>s</italic><sub>1</sub>, it does not ignore the rank of the selected genes within the considered subset, hence it belongs to the second mentioned class of stability measures. The value for the gene that is out of <bold><italic>L</italic></bold><sub><italic>b</italic></sub> is set to <italic>g</italic> + 1. The value of functions <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub> is scaled to the interval &#x02329;0,1&#x0232a; and the higher value indicates better stability of the obtained gene list.</p><p>Another indicator used to estimate the stability of an obtained gene list is given by the number of genes that were selected at least one time in all bootstrap samples. The best value is <italic>g</italic> and the worst is <italic>Max</italic>(<italic>G</italic>,<italic>Bg</italic>) where <italic>G</italic> is the number of all genes. This approach is equal to the number of genes with a non-zero score in the Bootstrap Based Feature Ranking (BBFR) (described in the next section).</p></sec></sec><sec><title>Prediction error estimation</title><p>To estimate the prediction error we use the.632+ estimator [<xref ref-type="bibr" rid="B24">24</xref>]. First we must define the prediction model as <inline-formula><mml:math id="M17" name="1745-6150-7-33-i17" overflow="scroll"><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> which can be estimated from a training sample. The loss function for measuring errors between <bold><italic>Y</italic></bold> and <inline-formula><mml:math id="M18" name="1745-6150-7-33-i18" overflow="scroll"><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> we can describe as <inline-formula><mml:math id="M19" name="1745-6150-7-33-i19" overflow="scroll"><mml:mi>L</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:math></inline-formula>. This function returns 0 if response <bold><italic>Y</italic></bold>equals predicted value <inline-formula><mml:math id="M20" name="1745-6150-7-33-i20" overflow="scroll"><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> and 1 otherwise. Now we can define the resubstitution error </p><p><disp-formula id="bmcM11"><label>(11)</label><mml:math id="M21" name="1745-6150-7-33-i21" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="italic">Err</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">resub</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:mfrac><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munderover><mml:mi>L</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="M22" name="1745-6150-7-33-i22" overflow="scroll"><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> is the predicted value at <italic>x</italic><sub><italic>i</italic></sub>of the whole dataset. This predictor can make overfitted predictions and the estimated error rate will be downward biased. It demonstrates why we obtain error estimator for test data sets in the form </p><p><disp-formula id="bmcM12"><label>(12)</label><mml:math id="M23" name="1745-6150-7-33-i23" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="italic">Err</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">test</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:mfrac><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:munder><mml:mi>L</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>&#x02217;</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mfenced><mml:mi>.</mml:mi></mml:math></disp-formula></p><p>The model trained on a training set will be tested on other samples and not used to fit the model. This provides protection against overfitting. As we have mentioned before, we compute the error rate for <italic>B</italic> sets <italic>C</italic><sub><italic>b</italic></sub> containing samples that do not appear in <italic>b</italic>-th bootstrap sample and |<italic>C</italic><sub><italic>b</italic></sub>| is a number of such samples. This estimator will overestimate the true prediction error, and when the test set is small it can have high variance [<xref ref-type="bibr" rid="B15">15</xref>]. To resolve this problem we use the.632+ estimator. This is a modified version of the.632 estimator to avoid downward bias in overfitting case of our classifier. Define <italic>&#x003b3;</italic>to be the error rate of our prediction rule if the inputs and class labels are independent. Let <inline-formula><mml:math id="M24" name="1745-6150-7-33-i24" overflow="scroll"><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> be the observed proportion of responses <italic>y</italic><sub><italic>i</italic></sub>equal <italic>k</italic> and let <inline-formula><mml:math id="M25" name="1745-6150-7-33-i25" overflow="scroll"><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> be the proportion of predictions <inline-formula><mml:math id="M26" name="1745-6150-7-33-i26" overflow="scroll"><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> equal <italic>k</italic>, where <italic>k</italic> is the class label of <italic>K</italic> class. Then </p><p><disp-formula id="bmcM13"><label>(13)</label><mml:math id="M27" name="1745-6150-7-33-i27" overflow="scroll"><mml:mover accent="true"><mml:mrow><mml:mi>&#x003b3;</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mfenced open="(" close=")"><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mi>.</mml:mi></mml:math></disp-formula></p><p>The relative overfitting rate is </p><p><disp-formula id="bmcM14"><label>(14)</label><mml:math id="M28" name="1745-6150-7-33-i28" overflow="scroll"><mml:mover accent="true"><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="italic">Err</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">test</mml:mtext></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="italic">Err</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">resub</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003b3;</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="italic">Err</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">resub</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>.</mml:mi></mml:math></disp-formula></p><p>Now we can define the.632+ estimator by </p><p><disp-formula id="bmcM15"><label>(15)</label><mml:math id="M29" name="1745-6150-7-33-i29" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="italic">Err</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>.</mml:mi><mml:mn>632</mml:mn><mml:mo>+</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x00175;</mml:mi><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="italic">Err</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">resub</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x00175;</mml:mi><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="italic">Err</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">test</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math></disp-formula></p><p><disp-formula id="bmcM16"><label>(16)</label><mml:math id="M30" name="1745-6150-7-33-i30" overflow="scroll"><mml:mi>&#x00175;</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>0</mml:mn><mml:mi>.</mml:mi><mml:mn>632</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mn>0</mml:mn><mml:mi>.</mml:mi><mml:mn>368</mml:mn><mml:mover accent="true"><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mi>.</mml:mi></mml:math></disp-formula></p><p>When there is no overfitting problem the.632+ estimator is equal to the.632 estimator </p><p><disp-formula id="bmcM17"><label>(17)</label><mml:math id="M31" name="1745-6150-7-33-i31" overflow="scroll"><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="italic">Err</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>.</mml:mi><mml:mn>632</mml:mn><mml:mo>+</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mi>.</mml:mi><mml:mn>368</mml:mn><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="italic">Err</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">resub</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>0</mml:mn><mml:mi>.</mml:mi><mml:mn>632</mml:mn><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="italic">Err</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">test</mml:mtext></mml:mrow></mml:msub><mml:mi>.</mml:mi></mml:math></disp-formula></p><sec><title>Tables</title><p>Table <xref ref-type="table" rid="T1">1</xref> The bootstrap based classification accuracies, stability index and number of reselected genes in all bootstrap samples of the SVM-classifier and the LDA-classifier based on all tested gene selection methods, on the LUNG dataset.</p><table-wrap position="float" id="T1"><label>Table 1</label><caption><p>The bootstrap based classification accuracies, stability index and number of reselected genes in all bootstrap samples of the SVM-classifier and the LDA-classifier based on all tested gene selection methods, on the LUNG dataset</p></caption><table frame="hsides" rules="groups" border="1"><colgroup><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/></colgroup><thead valign="top"><tr><th colspan="3" align="center" valign="bottom"><bold>method</bold><hr/></th><th colspan="2" align="center" valign="bottom"><bold>stability index</bold><hr/></th><th align="center" valign="bottom"><bold>Reselected genes</bold><hr/></th><th colspan="4" align="center" valign="bottom"><bold>Classification method</bold><hr/></th><th colspan="3" align="center" valign="bottom"><bold>Best result</bold><hr/></th></tr><tr><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="center" valign="bottom"><bold>SVM OvO</bold><hr/></th><th align="center" valign="bottom"><bold>SVM OvR</bold><hr/></th><th align="center" valign="bottom"><bold>MSVM</bold><hr/></th><th align="center" valign="bottom"><bold>LDA</bold><hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th></tr><tr><th align="left">&#x000a0;</th><th align="left">&#x000a0;</th><th align="left">&#x000a0;</th><th align="center"><bold><italic>s</italic></bold><sub><bold>1</bold></sub></th><th align="center"><bold><italic>s</italic></bold><sub><bold>2</bold></sub></th><th align="left">&#x000a0;</th><th align="center"><bold>acc</bold></th><th align="center"><bold>acc</bold></th><th align="center"><bold>acc</bold></th><th align="center"><bold>acc</bold></th><th align="center"><bold>acc</bold></th><th align="center"><bold>accL</bold></th><th align="center"><bold>accH</bold></th></tr></thead><tbody valign="top"><tr><td align="left" valign="bottom">SIMPLS<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.86<hr/></td><td align="center" valign="bottom">0.69<hr/></td><td align="center" valign="bottom">84<hr/></td><td align="center" valign="bottom">0.954<hr/></td><td align="center" valign="bottom">0.946<hr/></td><td align="center" valign="bottom">0.951<hr/></td><td align="center" valign="bottom"><bold>0.956</bold><hr/></td><td align="center" valign="bottom">0.956<hr/></td><td align="center" valign="bottom">0.930<hr/></td><td align="center" valign="bottom">0.978<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.86<hr/></td><td align="center" valign="bottom">0.74<hr/></td><td align="center" valign="bottom">78<hr/></td><td align="center" valign="bottom">0.950<hr/></td><td align="center" valign="bottom">0.945<hr/></td><td align="center" valign="bottom">0.947<hr/></td><td align="center" valign="bottom"><bold>0.965</bold><hr/></td><td align="center" valign="bottom">0.965<hr/></td><td align="center" valign="bottom">0.937<hr/></td><td align="center" valign="bottom">0.985<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.88<hr/></td><td align="center" valign="bottom">0.79<hr/></td><td align="center" valign="bottom">70<hr/></td><td align="center" valign="bottom">0.917<hr/></td><td align="center" valign="bottom">0.882<hr/></td><td align="center" valign="bottom">0.892<hr/></td><td align="center" valign="bottom">0.895<hr/></td><td align="center" valign="bottom">0.917<hr/></td><td align="center" valign="bottom">0.868<hr/></td><td align="center" valign="bottom">0.956<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.60<hr/></td><td align="center" valign="bottom">0.51<hr/></td><td align="center" valign="bottom">186<hr/></td><td align="center" valign="bottom">0.950<hr/></td><td align="center" valign="bottom">0.928<hr/></td><td align="center" valign="bottom">0.944<hr/></td><td align="center" valign="bottom">0.966<hr/></td><td align="center" valign="bottom">0.966<hr/></td><td align="center" valign="bottom">0.933<hr/></td><td align="center" valign="bottom">0.986<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.71<hr/></td><td align="center" valign="bottom">0.61<hr/></td><td align="center" valign="bottom">170<hr/></td><td align="center" valign="bottom">0.958<hr/></td><td align="center" valign="bottom">0.946<hr/></td><td align="center" valign="bottom">0.953<hr/></td><td align="center" valign="bottom">0.963<hr/></td><td align="center" valign="bottom">0.963<hr/></td><td align="center" valign="bottom">0.940<hr/></td><td align="center" valign="bottom">0.986<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.75<hr/></td><td align="center" valign="bottom">0.58<hr/></td><td align="center" valign="bottom">103<hr/></td><td align="center" valign="bottom">0.953<hr/></td><td align="center" valign="bottom">0.945<hr/></td><td align="center" valign="bottom">0.949<hr/></td><td align="center" valign="bottom">0.917<hr/></td><td align="center" valign="bottom">0.953<hr/></td><td align="center" valign="bottom">0.920<hr/></td><td align="center" valign="bottom">0.979<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.58<hr/></td><td align="center" valign="bottom">0.44<hr/></td><td align="center" valign="bottom">214<hr/></td><td align="center" valign="bottom">0.949<hr/></td><td align="center" valign="bottom">0.928<hr/></td><td align="center" valign="bottom">0.941<hr/></td><td align="center" valign="bottom">0.946<hr/></td><td align="center" valign="bottom">0.949<hr/></td><td align="center" valign="bottom">0.913<hr/></td><td align="center" valign="bottom">0.979<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.63<hr/></td><td align="center" valign="bottom">0.49<hr/></td><td align="center" valign="bottom">228<hr/></td><td align="center" valign="bottom">0.955<hr/></td><td align="center" valign="bottom">0.944<hr/></td><td align="center" valign="bottom">0.950<hr/></td><td align="center" valign="bottom">0.961<hr/></td><td align="center" valign="bottom">0.961<hr/></td><td align="center" valign="bottom">0.931<hr/></td><td align="center" valign="bottom">0.983<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.72<hr/></td><td align="center" valign="bottom">0.48<hr/></td><td align="center" valign="bottom">128<hr/></td><td align="center" valign="bottom"><bold>0.955</bold><hr/></td><td align="center" valign="bottom">0.949<hr/></td><td align="center" valign="bottom">0.950<hr/></td><td align="center" valign="bottom">0.943<hr/></td><td align="center" valign="bottom">0.955<hr/></td><td align="center" valign="bottom">0.919<hr/></td><td align="center" valign="bottom">0.985<hr/></td></tr><tr><td align="left" valign="bottom">NIPALS<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.86<hr/></td><td align="center" valign="bottom">0.69<hr/></td><td align="center" valign="bottom">84<hr/></td><td align="center" valign="bottom">0.954<hr/></td><td align="center" valign="bottom">0.946<hr/></td><td align="center" valign="bottom">0.951<hr/></td><td align="center" valign="bottom">0.956<hr/></td><td align="center" valign="bottom">0.956<hr/></td><td align="center" valign="bottom">0.930<hr/></td><td align="center" valign="bottom">0.978<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.86<hr/></td><td align="center" valign="bottom">0.74<hr/></td><td align="center" valign="bottom">78<hr/></td><td align="center" valign="bottom">0.950<hr/></td><td align="center" valign="bottom">0.945<hr/></td><td align="center" valign="bottom">0.947<hr/></td><td align="center" valign="bottom">0.965<hr/></td><td align="center" valign="bottom">0.965<hr/></td><td align="center" valign="bottom">0.937<hr/></td><td align="center" valign="bottom">0.985<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.88<hr/></td><td align="center" valign="bottom">0.79<hr/></td><td align="center" valign="bottom">70<hr/></td><td align="center" valign="bottom">0.917<hr/></td><td align="center" valign="bottom">0.882<hr/></td><td align="center" valign="bottom">0.892<hr/></td><td align="center" valign="bottom">0.895<hr/></td><td align="center" valign="bottom">0.917<hr/></td><td align="center" valign="bottom">0.868<hr/></td><td align="center" valign="bottom">0.956<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.68<hr/></td><td align="center" valign="bottom">0.60<hr/></td><td align="center" valign="bottom">151<hr/></td><td align="center" valign="bottom">0.949<hr/></td><td align="center" valign="bottom">0.932<hr/></td><td align="center" valign="bottom">0.943<hr/></td><td align="center" valign="bottom">0.956<hr/></td><td align="center" valign="bottom">0.956<hr/></td><td align="center" valign="bottom">0.924<hr/></td><td align="center" valign="bottom">0.980<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.76<hr/></td><td align="center" valign="bottom">0.62<hr/></td><td align="center" valign="bottom">126<hr/></td><td align="center" valign="bottom">0.954<hr/></td><td align="center" valign="bottom">0.946<hr/></td><td align="center" valign="bottom">0.949<hr/></td><td align="center" valign="bottom">0.954<hr/></td><td align="center" valign="bottom">0.954<hr/></td><td align="center" valign="bottom">0.923<hr/></td><td align="center" valign="bottom">0.980<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.74<hr/></td><td align="center" valign="bottom">0.62<hr/></td><td align="center" valign="bottom">111<hr/></td><td align="center" valign="bottom">0.949<hr/></td><td align="center" valign="bottom">0.940<hr/></td><td align="center" valign="bottom">0.944<hr/></td><td align="center" valign="bottom">0.930<hr/></td><td align="center" valign="bottom">0.949<hr/></td><td align="center" valign="bottom">0.907<hr/></td><td align="center" valign="bottom">0.979<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.66<hr/></td><td align="center" valign="bottom">0.46<hr/></td><td align="center" valign="bottom">143<hr/></td><td align="center" valign="bottom">0.946<hr/></td><td align="center" valign="bottom">0.920<hr/></td><td align="center" valign="bottom">0.936<hr/></td><td align="center" valign="bottom">0.927<hr/></td><td align="center" valign="bottom">0.946<hr/></td><td align="center" valign="bottom">0.907<hr/></td><td align="center" valign="bottom">0.978<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.71<hr/></td><td align="center" valign="bottom">0.51<hr/></td><td align="center" valign="bottom">134<hr/></td><td align="center" valign="bottom">0.950<hr/></td><td align="center" valign="bottom">0.938<hr/></td><td align="center" valign="bottom">0.944<hr/></td><td align="center" valign="bottom">0.936<hr/></td><td align="center" valign="bottom">0.950<hr/></td><td align="center" valign="bottom">0.910<hr/></td><td align="center" valign="bottom">0.979<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.73<hr/></td><td align="center" valign="bottom">0.55<hr/></td><td align="center" valign="bottom">121<hr/></td><td align="center" valign="bottom">0.951<hr/></td><td align="center" valign="bottom">0.944<hr/></td><td align="center" valign="bottom">0.947<hr/></td><td align="center" valign="bottom">0.911<hr/></td><td align="center" valign="bottom">0.951<hr/></td><td align="center" valign="bottom">0.912<hr/></td><td align="center" valign="bottom">0.979<hr/></td></tr><tr><td align="left" valign="bottom">RFE<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.44<hr/></td><td align="center" valign="bottom">0.35<hr/></td><td align="center" valign="bottom">487<hr/></td><td align="center" valign="bottom">0.962<hr/></td><td align="center" valign="bottom">0.953<hr/></td><td align="center" valign="bottom">0.961<hr/></td><td align="center" valign="bottom"><bold>0.977</bold><hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.947<hr/></td><td align="center" valign="bottom">0.999<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.30<hr/></td><td align="center" valign="bottom">0.20<hr/></td><td align="center" valign="bottom">808<hr/></td><td align="center" valign="bottom">0.965<hr/></td><td align="center" valign="bottom">0.961<hr/></td><td align="center" valign="bottom">0.964<hr/></td><td align="center" valign="bottom"><bold>0.968</bold><hr/></td><td align="center" valign="bottom">0.968<hr/></td><td align="center" valign="bottom">0.938<hr/></td><td align="center" valign="bottom">0.992<hr/></td></tr><tr><td align="left" valign="bottom">T-TEST<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.09<hr/></td><td align="center" valign="bottom">0.07<hr/></td><td align="center" valign="bottom">333<hr/></td><td align="center" valign="bottom"><bold>0.956</bold><hr/></td><td align="center" valign="bottom">0.939<hr/></td><td align="center" valign="bottom">0.951<hr/></td><td align="center" valign="bottom">0.951<hr/></td><td align="center" valign="bottom">0.956<hr/></td><td align="center" valign="bottom">0.923<hr/></td><td align="center" valign="bottom">0.985<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.47<hr/></td><td align="center" valign="bottom">0.40<hr/></td><td align="center" valign="bottom">624<hr/></td><td align="center" valign="bottom"><bold>0.939</bold><hr/></td><td align="center" valign="bottom">0.925<hr/></td><td align="center" valign="bottom">0.934<hr/></td><td align="center" valign="bottom">0.850<hr/></td><td align="center" valign="bottom">0.939<hr/></td><td align="center" valign="bottom">0.896<hr/></td><td align="center" valign="bottom">0.977<hr/></td></tr><tr><td align="left" valign="bottom">GS<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.52<hr/></td><td align="center" valign="bottom">0.42<hr/></td><td align="center" valign="bottom">453<hr/></td><td align="center" valign="bottom">0.962<hr/></td><td align="center" valign="bottom">0.944<hr/></td><td align="center" valign="bottom">0.957<hr/></td><td align="center" valign="bottom"><bold>0.973</bold><hr/></td><td align="center" valign="bottom">0.973<hr/></td><td align="center" valign="bottom">0.946<hr/></td><td align="center" valign="bottom">0.994<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.62<hr/></td><td align="center" valign="bottom">0.49<hr/></td><td align="center" valign="bottom">305<hr/></td><td align="center" valign="bottom">0.964<hr/></td><td align="center" valign="bottom">0.953<hr/></td><td align="center" valign="bottom">0.961<hr/></td><td align="center" valign="bottom"><bold>0.971</bold><hr/></td><td align="center" valign="bottom">0.971<hr/></td><td align="center" valign="bottom">0.943<hr/></td><td align="center" valign="bottom">0.994<hr/></td></tr><tr><td align="left">&#x000a0;</td><td align="center">MCLASS</td><td align="center">&#x000a0;</td><td align="center">0.65</td><td align="center">0.53</td><td align="center">243</td><td align="center">0.935</td><td align="center">0.900</td><td align="center">0.921</td><td align="center"><bold>0.943</bold></td><td align="center">0.943</td><td align="center">0.883</td><td align="center">0.974</td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>The number of selected genes is set to 30 In last 3 columns is the best accuracy rate together with their bootstrap based standard deviations (accL,accH). The number of reselected genes is the sum of non zero bootstrap-based feature ranked genes (BBFR).</p></table-wrap-foot></table-wrap><p>Table <xref ref-type="table" rid="T2">2</xref> The bootstrap based classification accuracies, stability index and number of reselected genes in all bootstrap samples of the SVM-classifier and the LDA-classifier based on all tested gene selection methods, on the MLL dataset.</p><table-wrap position="float" id="T2"><label>Table 2</label><caption><p>The bootstrap based classification accuracies, stability index and number of reselected genes in all bootstrap samples of the SVM-classifier and the LDA-classifier based on all tested gene selection methods, on the MLL dataset</p></caption><table frame="hsides" rules="groups" border="1"><colgroup><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/></colgroup><thead valign="top"><tr><th colspan="3" align="left" valign="bottom"><bold>Selection method</bold><hr/></th><th colspan="2" align="center" valign="bottom"><bold>stability index</bold><hr/></th><th align="center" valign="bottom"><bold>Reselected genes</bold><hr/></th><th colspan="4" align="center" valign="bottom"><bold>Classification method</bold><hr/></th><th colspan="3" align="center" valign="bottom"><bold>Best result</bold><hr/></th></tr><tr><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="center" valign="bottom"><bold>SVM OvO</bold><hr/></th><th align="center" valign="bottom"><bold>SVM OvR</bold><hr/></th><th align="center" valign="bottom"><bold>MSVM</bold><hr/></th><th align="center" valign="bottom"><bold>LDA</bold><hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th></tr><tr><th align="left">&#x000a0;</th><th align="left">&#x000a0;</th><th align="left">&#x000a0;</th><th align="center"><bold><italic>s</italic></bold><sub><bold>1</bold></sub></th><th align="center"><bold><italic>s</italic></bold><sub><bold>2</bold></sub></th><th align="left">&#x000a0;</th><th align="center"><bold>acc</bold></th><th align="center"><bold>acc</bold></th><th align="center"><bold>acc</bold></th><th align="center"><bold>acc</bold></th><th align="center"><bold>acc</bold></th><th align="center"><bold>accL</bold></th><th align="center"><bold>accH</bold></th></tr></thead><tbody valign="top"><tr><td align="left" valign="bottom">SIMPLS<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.77<hr/></td><td align="center" valign="bottom">0.70<hr/></td><td align="center" valign="bottom">116<hr/></td><td align="center" valign="bottom">0.971<hr/></td><td align="center" valign="bottom">0.973<hr/></td><td align="center" valign="bottom">0.972<hr/></td><td align="center" valign="bottom"><bold>0.995</bold><hr/></td><td align="center" valign="bottom">0.995<hr/></td><td align="center" valign="bottom">0.971<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.77<hr/></td><td align="center" valign="bottom">0.71<hr/></td><td align="center" valign="bottom">114<hr/></td><td align="center" valign="bottom">0.973<hr/></td><td align="center" valign="bottom">0.974<hr/></td><td align="center" valign="bottom">0.972<hr/></td><td align="center" valign="bottom"><bold>0.993</bold><hr/></td><td align="center" valign="bottom">0.993<hr/></td><td align="center" valign="bottom">0.969<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.81<hr/></td><td align="center" valign="bottom">0.73<hr/></td><td align="center" valign="bottom">84<hr/></td><td align="center" valign="bottom">0.962<hr/></td><td align="center" valign="bottom">0.970<hr/></td><td align="center" valign="bottom">0.967<hr/></td><td align="center" valign="bottom">0.965<hr/></td><td align="center" valign="bottom">0.970<hr/></td><td align="center" valign="bottom">0.915<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.64<hr/></td><td align="center" valign="bottom">0.50<hr/></td><td align="center" valign="bottom">245<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.978<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.978<hr/></td><td align="center" valign="bottom">0.978<hr/></td><td align="center" valign="bottom">0.936<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.63<hr/></td><td align="center" valign="bottom">0.52<hr/></td><td align="center" valign="bottom">224<hr/></td><td align="center" valign="bottom">0.976<hr/></td><td align="center" valign="bottom">0.978<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.981<hr/></td><td align="center" valign="bottom">0.981<hr/></td><td align="center" valign="bottom">0.943<hr/></td><td align="center" valign="bottom">0.995<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.66<hr/></td><td align="center" valign="bottom">0.59<hr/></td><td align="center" valign="bottom">201<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.976<hr/></td><td align="center" valign="bottom"><bold>0.982</bold><hr/></td><td align="center" valign="bottom">0.982<hr/></td><td align="center" valign="bottom">0.943<hr/></td><td align="center" valign="bottom">0.995<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.52<hr/></td><td align="center" valign="bottom">0.40<hr/></td><td align="center" valign="bottom">281<hr/></td><td align="center" valign="bottom">0.974<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.973<hr/></td><td align="center" valign="bottom">0.971<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.936<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.58<hr/></td><td align="center" valign="bottom">0.47<hr/></td><td align="center" valign="bottom">236<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.976<hr/></td><td align="center" valign="bottom">0.974<hr/></td><td align="center" valign="bottom">0.972<hr/></td><td align="center" valign="bottom">0.976<hr/></td><td align="center" valign="bottom">0.936<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">NIPALS<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.77<hr/></td><td align="center" valign="bottom">0.70<hr/></td><td align="center" valign="bottom">116<hr/></td><td align="center" valign="bottom">0.971<hr/></td><td align="center" valign="bottom">0.973<hr/></td><td align="center" valign="bottom">0.972<hr/></td><td align="center" valign="bottom">0.995<hr/></td><td align="center" valign="bottom">0.995<hr/></td><td align="center" valign="bottom">0.971<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.77<hr/></td><td align="center" valign="bottom">0.71<hr/></td><td align="center" valign="bottom">114<hr/></td><td align="center" valign="bottom">0.973<hr/></td><td align="center" valign="bottom">0.974<hr/></td><td align="center" valign="bottom">0.972<hr/></td><td align="center" valign="bottom">0.993<hr/></td><td align="center" valign="bottom">0.993<hr/></td><td align="center" valign="bottom">0.969<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.81<hr/></td><td align="center" valign="bottom">0.73<hr/></td><td align="center" valign="bottom">84<hr/></td><td align="center" valign="bottom">0.962<hr/></td><td align="center" valign="bottom">0.970<hr/></td><td align="center" valign="bottom">0.967<hr/></td><td align="center" valign="bottom">0.965<hr/></td><td align="center" valign="bottom">0.970<hr/></td><td align="center" valign="bottom">0.915<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.62<hr/></td><td align="center" valign="bottom">0.50<hr/></td><td align="center" valign="bottom">221<hr/></td><td align="center" valign="bottom">0.974<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.974<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.924<hr/></td><td align="center" valign="bottom">0.995<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.62<hr/></td><td align="center" valign="bottom">0.53<hr/></td><td align="center" valign="bottom">198<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.976<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.938<hr/></td><td align="center" valign="bottom">0.995<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.67<hr/></td><td align="center" valign="bottom">0.53<hr/></td><td align="center" valign="bottom">188<hr/></td><td align="center" valign="bottom">0.974<hr/></td><td align="center" valign="bottom">0.976<hr/></td><td align="center" valign="bottom">0.974<hr/></td><td align="center" valign="bottom">0.979<hr/></td><td align="center" valign="bottom">0.979<hr/></td><td align="center" valign="bottom">0.943<hr/></td><td align="center" valign="bottom">0.995<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.62<hr/></td><td align="center" valign="bottom">0.46<hr/></td><td align="center" valign="bottom">211<hr/></td><td align="center" valign="bottom">0.973<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.974<hr/></td><td align="center" valign="bottom">0.963<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.928<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.61<hr/></td><td align="center" valign="bottom">0.47<hr/></td><td align="center" valign="bottom">196<hr/></td><td align="center" valign="bottom">0.970<hr/></td><td align="center" valign="bottom">0.971<hr/></td><td align="center" valign="bottom">0.970<hr/></td><td align="center" valign="bottom">0.960<hr/></td><td align="center" valign="bottom">0.971<hr/></td><td align="center" valign="bottom">0.971<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.63<hr/></td><td align="center" valign="bottom">0.51<hr/></td><td align="center" valign="bottom">204<hr/></td><td align="center" valign="bottom">0.971<hr/></td><td align="center" valign="bottom">0.973<hr/></td><td align="center" valign="bottom">0.971<hr/></td><td align="center" valign="bottom">0.957<hr/></td><td align="center" valign="bottom">0.973<hr/></td><td align="center" valign="bottom">0.973<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">RFE<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.58<hr/></td><td align="center" valign="bottom">0.48<hr/></td><td align="center" valign="bottom">318<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.974<hr/></td><td align="center" valign="bottom"><bold>0.982</bold><hr/></td><td align="center" valign="bottom">0.982<hr/></td><td align="center" valign="bottom">0.940<hr/></td><td align="center" valign="bottom">0.995<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.47<hr/></td><td align="center" valign="bottom">0.36<hr/></td><td align="center" valign="bottom">401<hr/></td><td align="center" valign="bottom">0.976<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom"><bold>0.988</bold><hr/></td><td align="center" valign="bottom">0.988<hr/></td><td align="center" valign="bottom">0.947<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">T-TEST<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.55<hr/></td><td align="center" valign="bottom">0.42<hr/></td><td align="center" valign="bottom">448<hr/></td><td align="center" valign="bottom">0.972<hr/></td><td align="center" valign="bottom">0.978<hr/></td><td align="center" valign="bottom">0.976<hr/></td><td align="center" valign="bottom"><bold>0.987</bold><hr/></td><td align="center" valign="bottom">0.987<hr/></td><td align="center" valign="bottom">0.945<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.59<hr/></td><td align="center" valign="bottom">0.49<hr/></td><td align="center" valign="bottom">534<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.978<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom"><bold>0.981</bold><hr/></td><td align="center" valign="bottom">0.981<hr/></td><td align="center" valign="bottom">0.935<hr/></td><td align="center" valign="bottom">0.995<hr/></td></tr><tr><td align="left" valign="bottom">GS<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.62<hr/></td><td align="center" valign="bottom">0.54<hr/></td><td align="center" valign="bottom">489<hr/></td><td align="center" valign="bottom">0.971<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom"><bold>0.982</bold><hr/></td><td align="center" valign="bottom">0.982<hr/></td><td align="center" valign="bottom">0.943<hr/></td><td align="center" valign="bottom">0.995<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.64<hr/></td><td align="center" valign="bottom">0.50<hr/></td><td align="center" valign="bottom">490<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.976<hr/></td><td align="center" valign="bottom"><bold>0.986</bold><hr/></td><td align="center" valign="bottom">0.986<hr/></td><td align="center" valign="bottom">0.947<hr/></td><td align="center" valign="bottom">0.995<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.59<hr/></td><td align="center" valign="bottom">0.43<hr/></td><td align="center" valign="bottom">526<hr/></td><td align="center" valign="bottom">0.963<hr/></td><td align="center" valign="bottom">0.967<hr/></td><td align="center" valign="bottom">0.965<hr/></td><td align="center" valign="bottom"><bold>0.970</bold><hr/></td><td align="center" valign="bottom">0.970<hr/></td><td align="center" valign="bottom">0.915<hr/></td><td align="center" valign="bottom">0.995<hr/></td></tr><tr><td align="left">&#x000a0;</td><td align="center">OvO</td><td align="center">10 comp.</td><td align="center">0.56</td><td align="center">0.33</td><td align="center">268</td><td align="center">0.969</td><td align="center">0.972</td><td align="center">0.971</td><td align="center">0.960</td><td align="center">0.972</td><td align="center">0.919</td><td align="center">1.000</td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>The number of selected genes is set to 30. In last 3 columns is the best accuracy rate together with their bootstrap based standard deviations (accL,accH). The number of reselected genes is the sum of non zero bootstrap-based feature ranked genes (BBFR).</p></table-wrap-foot></table-wrap><p>Table <xref ref-type="table" rid="T3">3</xref> The bootstrap based classification accuracies, stability index and number of reselected genes in all bootstrap samples of the SVM-classifier and the LDA-classifier based on all tested gene selection methods, on the SRBCT dataset</p><table-wrap position="float" id="T3"><label>Table 3</label><caption><p>The bootstrap based classification accuracies, stability index and number of reselected genes in all bootstrap samples of the SVM-classifier and the LDA-classifier based on all tested gene selection methods, on the SRBCT dataset</p></caption><table frame="hsides" rules="groups" border="1"><colgroup><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/></colgroup><thead valign="top"><tr><th colspan="3" align="center" valign="bottom"><bold>Selection method</bold><hr/></th><th colspan="2" align="center" valign="bottom"><bold>stability index</bold><hr/></th><th align="center" valign="bottom"><bold>Reselected genes</bold><hr/></th><th colspan="4" align="center" valign="bottom"><bold>Classification method</bold><hr/></th><th colspan="3" align="center" valign="bottom"><bold>Best result</bold><hr/></th></tr><tr><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="center" valign="bottom"><bold>SVM OvO</bold><hr/></th><th align="center" valign="bottom"><bold>SVM OvR</bold><hr/></th><th align="center" valign="bottom"><bold>MSVM</bold><hr/></th><th align="center" valign="bottom"><bold>LDA</bold><hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th><th align="left" valign="bottom">&#x000a0;<hr/></th></tr><tr><th align="left">&#x000a0;</th><th align="left">&#x000a0;</th><th align="left">&#x000a0;</th><th align="center"><bold><italic>s</italic></bold><sub><bold>1</bold></sub></th><th align="center"><bold><italic>s</italic></bold><sub><bold>2</bold></sub></th><th align="left">&#x000a0;</th><th align="center"><bold>acc</bold></th><th align="center"><bold>acc</bold></th><th align="center"><bold>acc</bold></th><th align="center"><bold>acc</bold></th><th align="center"><bold>acc</bold></th><th align="center"><bold>accL</bold></th><th align="center"><bold>accH</bold></th></tr></thead><tbody valign="top"><tr><td align="left" valign="bottom">SIMPLS<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.71<hr/></td><td align="center" valign="bottom">0.60<hr/></td><td align="center" valign="bottom">127<hr/></td><td align="center" valign="bottom">0.867<hr/></td><td align="center" valign="bottom"><bold>0.977</bold><hr/></td><td align="center" valign="bottom">0.976<hr/></td><td align="center" valign="bottom">0.941<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.913<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.74<hr/></td><td align="center" valign="bottom">0.59<hr/></td><td align="center" valign="bottom">137<hr/></td><td align="center" valign="bottom">0.882<hr/></td><td align="center" valign="bottom"><bold>0.980</bold><hr/></td><td align="center" valign="bottom">0.980<hr/></td><td align="center" valign="bottom">0.952<hr/></td><td align="center" valign="bottom">0.980<hr/></td><td align="center" valign="bottom">0.912<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.58<hr/></td><td align="center" valign="bottom">0.39<hr/></td><td align="center" valign="bottom">240<hr/></td><td align="center" valign="bottom">0.807<hr/></td><td align="center" valign="bottom">0.930<hr/></td><td align="center" valign="bottom">0.932<hr/></td><td align="center" valign="bottom">0.829<hr/></td><td align="center" valign="bottom">0.932<hr/></td><td align="center" valign="bottom">0.797<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.52<hr/></td><td align="center" valign="bottom">0.36<hr/></td><td align="center" valign="bottom">204<hr/></td><td align="center" valign="bottom">0.831<hr/></td><td align="center" valign="bottom">0.970<hr/></td><td align="center" valign="bottom">0.968<hr/></td><td align="center" valign="bottom">0.929<hr/></td><td align="center" valign="bottom">0.970<hr/></td><td align="center" valign="bottom">0.896<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.63<hr/></td><td align="center" valign="bottom">0.43<hr/></td><td align="center" valign="bottom">173<hr/></td><td align="center" valign="bottom">0.867<hr/></td><td align="center" valign="bottom">0.981<hr/></td><td align="center" valign="bottom">0.979<hr/></td><td align="center" valign="bottom">0.964<hr/></td><td align="center" valign="bottom">0.981<hr/></td><td align="center" valign="bottom">0.926<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.72<hr/></td><td align="center" valign="bottom">0.58<hr/></td><td align="center" valign="bottom">133<hr/></td><td align="center" valign="bottom">0.856<hr/></td><td align="center" valign="bottom"><bold>0.979</bold><hr/></td><td align="center" valign="bottom">0.978<hr/></td><td align="center" valign="bottom">0.945<hr/></td><td align="center" valign="bottom">0.979<hr/></td><td align="center" valign="bottom">0.903<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.40<hr/></td><td align="center" valign="bottom">0.25<hr/></td><td align="center" valign="bottom">239<hr/></td><td align="center" valign="bottom">0.817<hr/></td><td align="center" valign="bottom">0.961<hr/></td><td align="center" valign="bottom">0.958<hr/></td><td align="center" valign="bottom">0.910<hr/></td><td align="center" valign="bottom">0.961<hr/></td><td align="center" valign="bottom">0.873<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.45<hr/></td><td align="center" valign="bottom">0.23<hr/></td><td align="center" valign="bottom">237<hr/></td><td align="center" valign="bottom">0.839<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.974<hr/></td><td align="center" valign="bottom">0.942<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.912<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.63<hr/></td><td align="center" valign="bottom">0.41<hr/></td><td align="center" valign="bottom">133<hr/></td><td align="center" valign="bottom">0.832<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.973<hr/></td><td align="center" valign="bottom">0.931<hr/></td><td align="center" valign="bottom">0.975<hr/></td><td align="center" valign="bottom">0.912<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">NIPALS<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.71<hr/></td><td align="center" valign="bottom">0.60<hr/></td><td align="center" valign="bottom">127<hr/></td><td align="center" valign="bottom">0.867<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.976<hr/></td><td align="center" valign="bottom">0.941<hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.913<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.74<hr/></td><td align="center" valign="bottom">0.59<hr/></td><td align="center" valign="bottom">137<hr/></td><td align="center" valign="bottom">0.882<hr/></td><td align="center" valign="bottom">0.980<hr/></td><td align="center" valign="bottom">0.980<hr/></td><td align="center" valign="bottom">0.952<hr/></td><td align="center" valign="bottom">0.980<hr/></td><td align="center" valign="bottom">0.912<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">1 comp.<hr/></td><td align="center" valign="bottom">0.58<hr/></td><td align="center" valign="bottom">0.39<hr/></td><td align="center" valign="bottom">240<hr/></td><td align="center" valign="bottom">0.807<hr/></td><td align="center" valign="bottom">0.930<hr/></td><td align="center" valign="bottom">0.932<hr/></td><td align="center" valign="bottom">0.829<hr/></td><td align="center" valign="bottom">0.932<hr/></td><td align="center" valign="bottom">0.797<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.65<hr/></td><td align="center" valign="bottom">0.45<hr/></td><td align="center" valign="bottom">152<hr/></td><td align="center" valign="bottom">0.726<hr/></td><td align="center" valign="bottom">0.920<hr/></td><td align="center" valign="bottom">0.914<hr/></td><td align="center" valign="bottom">0.775<hr/></td><td align="center" valign="bottom">0.920<hr/></td><td align="center" valign="bottom">0.785<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.68<hr/></td><td align="center" valign="bottom">0.47<hr/></td><td align="center" valign="bottom">129<hr/></td><td align="center" valign="bottom">0.748<hr/></td><td align="center" valign="bottom">0.935<hr/></td><td align="center" valign="bottom">0.932<hr/></td><td align="center" valign="bottom">0.787<hr/></td><td align="center" valign="bottom">0.935<hr/></td><td align="center" valign="bottom">0.819<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">5 comp.<hr/></td><td align="center" valign="bottom">0.69<hr/></td><td align="center" valign="bottom">0.48<hr/></td><td align="center" valign="bottom">133<hr/></td><td align="center" valign="bottom">0.805<hr/></td><td align="center" valign="bottom">0.965<hr/></td><td align="center" valign="bottom">0.962<hr/></td><td align="center" valign="bottom">0.861<hr/></td><td align="center" valign="bottom">0.965<hr/></td><td align="center" valign="bottom">0.873<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.66<hr/></td><td align="center" valign="bottom">0.43<hr/></td><td align="center" valign="bottom">137<hr/></td><td align="center" valign="bottom">0.711<hr/></td><td align="center" valign="bottom">0.910<hr/></td><td align="center" valign="bottom">0.905<hr/></td><td align="center" valign="bottom">0.745<hr/></td><td align="center" valign="bottom">0.910<hr/></td><td align="center" valign="bottom">0.756<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.65<hr/></td><td align="center" valign="bottom">0.48<hr/></td><td align="center" valign="bottom">119<hr/></td><td align="center" valign="bottom">0.687<hr/></td><td align="center" valign="bottom">0.886<hr/></td><td align="center" valign="bottom">0.885<hr/></td><td align="center" valign="bottom">0.687<hr/></td><td align="center" valign="bottom">0.886<hr/></td><td align="center" valign="bottom">0.726<hr/></td><td align="center" valign="bottom">0.980<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">MCLASS<hr/></td><td align="center" valign="bottom">10 comp.<hr/></td><td align="center" valign="bottom">0.67<hr/></td><td align="center" valign="bottom">0.46<hr/></td><td align="center" valign="bottom">117<hr/></td><td align="center" valign="bottom">0.723<hr/></td><td align="center" valign="bottom">0.912<hr/></td><td align="center" valign="bottom">0.909<hr/></td><td align="center" valign="bottom">0.746<hr/></td><td align="center" valign="bottom">0.912<hr/></td><td align="center" valign="bottom">0.776<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">RFE<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.57<hr/></td><td align="center" valign="bottom">0.36<hr/></td><td align="center" valign="bottom">262<hr/></td><td align="center" valign="bottom">0.925<hr/></td><td align="center" valign="bottom"><bold>0.983</bold><hr/></td><td align="center" valign="bottom">0.982<hr/></td><td align="center" valign="bottom">0.972<hr/></td><td align="center" valign="bottom">0.983<hr/></td><td align="center" valign="bottom">0.919<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.40<hr/></td><td align="center" valign="bottom">0.32<hr/></td><td align="center" valign="bottom">338<hr/></td><td align="center" valign="bottom">0.923<hr/></td><td align="center" valign="bottom"><bold>0.982</bold><hr/></td><td align="center" valign="bottom">0.981<hr/></td><td align="center" valign="bottom">0.963<hr/></td><td align="center" valign="bottom">0.982<hr/></td><td align="center" valign="bottom">0.926<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">T-TEST<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.29<hr/></td><td align="center" valign="bottom">0.22<hr/></td><td align="center" valign="bottom">438<hr/></td><td align="center" valign="bottom">0.925<hr/></td><td align="center" valign="bottom"><bold>0.971</bold><hr/></td><td align="center" valign="bottom">0.969<hr/></td><td align="center" valign="bottom">0.964<hr/></td><td align="center" valign="bottom">0.971<hr/></td><td align="center" valign="bottom">0.899<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.47<hr/></td><td align="center" valign="bottom">0.37<hr/></td><td align="center" valign="bottom">498<hr/></td><td align="center" valign="bottom">0.929<hr/></td><td align="center" valign="bottom">0.972<hr/></td><td align="center" valign="bottom">0.971<hr/></td><td align="center" valign="bottom"><bold>0.973</bold><hr/></td><td align="center" valign="bottom">0.973<hr/></td><td align="center" valign="bottom">0.899<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">GS<hr/></td><td align="center" valign="bottom">OvO<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.51<hr/></td><td align="center" valign="bottom">0.39<hr/></td><td align="center" valign="bottom">533<hr/></td><td align="center" valign="bottom">0.921<hr/></td><td align="center" valign="bottom"><bold>0.969</bold><hr/></td><td align="center" valign="bottom">0.968<hr/></td><td align="center" valign="bottom">0.964<hr/></td><td align="center" valign="bottom">0.969<hr/></td><td align="center" valign="bottom">0.889<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">OvR<hr/></td><td align="center" valign="bottom">&#x000a0;<hr/></td><td align="center" valign="bottom">0.64<hr/></td><td align="center" valign="bottom">0.54<hr/></td><td align="center" valign="bottom">367<hr/></td><td align="center" valign="bottom">0.927<hr/></td><td align="center" valign="bottom"><bold>0.980</bold><hr/></td><td align="center" valign="bottom">0.977<hr/></td><td align="center" valign="bottom">0.979<hr/></td><td align="center" valign="bottom">0.980<hr/></td><td align="center" valign="bottom">0.923<hr/></td><td align="center" valign="bottom">1.000<hr/></td></tr><tr><td align="left">&#x000a0;</td><td align="center">MCLASS</td><td align="center">&#x000a0;</td><td align="center">0.57</td><td align="center">0.48</td><td align="center">407</td><td align="center">0.921</td><td align="center"><bold>0.959</bold></td><td align="center">0.957</td><td align="center">0.959</td><td align="center">0.959</td><td align="center">0.873</td><td align="center">1.000</td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>The number of selected genes is set to 30. In last 3 columns is the best accuracy rate together with their bootstrap based standard deviations (accL,accH). The number of reselected genes is the sum of non zero bootstrap-based feature ranked genes (BBFR)</p></table-wrap-foot></table-wrap></sec><sec><title>Figures for MLL and SEBCT data</title><p>Figure <xref ref-type="fig" rid="F6">6</xref> Stability index <bold><italic>s</italic></bold><sub><bold><italic>2</italic></bold></sub>(bar chart) and accuracy of classification (dot chart) with the 95% confidence interval of the best classifier on the tested feature selection methods for MLL data.</p><fig id="F6" position="float"><label>Figure 6</label><caption><p><bold>Stability index </bold><bold><italic>s</italic></bold><sub><bold><italic>2</italic></bold></sub><bold> (bar chart) and accuracy of classification (dot chart) with the 95% confidence interval of the best classifier on the tested feature selection methods for MLL data.</bold></p></caption><graphic xlink:href="1745-6150-7-33-6"/></fig><p>Figure <xref ref-type="fig" rid="F7">7</xref> Stability index <italic>s</italic><sub>2</sub>(bar chart) and accuracy of classification (dot chart) with the 95% confidence interval of the best classifier on the tested feature selection methods for SRBCT data.</p><fig id="F7" position="float"><label>Figure 7</label><caption><p><bold>Stability index </bold><bold><italic>s</italic></bold><sub><bold><italic>2</italic></bold></sub><bold> (bar chart) and accuracy of classification (dot chart) with the 95% confidence interval of the best classifier on the tested feature selection methods for SRBCT data.</bold></p></caption><graphic xlink:href="1745-6150-7-33-7"/></fig><p>Figure <xref ref-type="fig" rid="F8">8</xref> Accuracy of classification obtained by successive gene set reduction selected with all feature selection methods of the best classifier for MLL data.</p><fig id="F8" position="float"><label>Figure 8</label><caption><p>Accuracy of classification obtained by successive gene set reduction selected with all feature selection methods of the best classifier for MLL data.</p></caption><graphic xlink:href="1745-6150-7-33-8"/></fig><p>Figure <xref ref-type="fig" rid="F9">9</xref> Accuracy of classification obtained by successive gene set reduction selected with all feature selection methods of the best classifier for SRBCT data.</p><fig id="F9" position="float"><label>Figure 9</label><caption><p>Accuracy of classification obtained by successive gene set reduction selected with all feature selection methods of the best classifier for SRBCT data.</p></caption><graphic xlink:href="1745-6150-7-33-9"/></fig><p>Figure <xref ref-type="fig" rid="F10">10</xref> Results of bootstrap-based feature ranking (BBFR) for the first 50 genes for MLL data. In the ideal case (when gene lists are perfectly reproducible) the BBFR score reaches a value of 1 for the first selected genes and 0 for the rest (black curve).</p><fig id="F10" position="float"><label>Figure 10</label><caption><p><bold>Results of bootstrap-based feature ranking (BBFR) for the first 50 genes for MLL data.</bold> In the ideal case (when gene lists are perfectly reproducible) the BBFR score reaches a value of 1 for the first selected genes and 0 for the rest (black curve).</p></caption><graphic xlink:href="1745-6150-7-33-10"/></fig><p>Figure <xref ref-type="fig" rid="F11">11</xref> Results of bootstrap-based feature ranking (BBFR) for the first 50 genes for SRBCT data. In the ideal case (when gene lists are perfectly reproducible) the BBFR score reaches a value of 1 for the first selected genes and 0 for the rest (black curve).</p><fig id="F11" position="float"><label>Figure 11</label><caption><p><bold>Results of bootstrap-based feature ranking (BBFR) for the first 50 genes for SRBCT data.</bold> In the ideal case (when gene lists are perfectly reproducible) the BBFR score reaches a value of 1 for the first selected genes and 0 for the rest (black curve).</p></caption><graphic xlink:href="1745-6150-7-33-11"/></fig><p>Figure <xref ref-type="fig" rid="F12">12</xref> Comparison of rank boxplots in the bootstrap samples against rank in the original data set on all tested methods for MLL data.</p><fig id="F12" position="float"><label>Figure 12</label><caption><p>Comparison of rank boxplots in the bootstrap samples against rank in the original data set on all tested methods for MLL data.</p></caption><graphic xlink:href="1745-6150-7-33-12"/></fig><p>Figure <xref ref-type="fig" rid="F13">13</xref> Comparison of rank boxplots in the bootstrap samples against rank in the original data set on all tested methods for SRBCT data.</p><fig id="F13" position="float"><label>Figure 13</label><caption><p>Comparison of rank boxplots in the bootstrap samples against rank in the original data set on all tested methods for SRBCT data.</p></caption><graphic xlink:href="1745-6150-7-33-13"/></fig></sec></sec><sec><title>Reviewer&#x02019;s report 1</title><sec><title>Prof Marek Kimmel</title></sec><sec><title>Report form</title><p>As the authors state, &#x0201c;gene expression profiles are a promising alternative for clinical cancer classification&#x0201d;. The well-known difficulty is the large dimension of the vector of data, compared to the usually modest number of independent data replicates. The authors propose a new, arguably better combination of known methods to face the classification problem. This is important; however, the most interesting problem tackled in the paper in a novel way is that of stability. Ranked gene lists can be unstable in the sense that a small change of the data set leads to serious changes in the resulting ordered lists. The authors address this issue by comparing how different methods yield different stability of results. Eventually, they find a new strategy to find a small subset of significant genes giving very stable feature rankings compared to currently employed methods. The paper seems interesting and suitable for Biology Direct. On the editorial side, some language usages are uncommon and therefore not clearly understandable, such as for example &#x0201c;invariability&#x0201d; which might mean &#x0201c;invariance&#x0201d; or &#x0201c;absence of variability&#x0201d;. I suggest using Oxford English Dictionary Online or a similar source to rectify these ambiguities (or employing a human text editor fluent in scientific English).</p></sec><sec><title>Quality of written English</title><p>Needs some language corrections before being published</p><p><bold><italic>Author&#x02019;s response</italic></bold><italic>We have edited the text and corrected the paper&#x02019;s language mistakes.</italic></p></sec><sec><title>Dr Hans Binder</title></sec><sec><title>Report form</title><p>The manuscript Stable feature selection and classification algorithms for multiclass microarray data by Sebastian Student and Krzysztof Fujarewicz presents a new feature selection and multi-classification algorithm based on Partial Least Squares and decomposition into separate two-class problems. The authors clearly show that their method outperforms a series of state-of-the-art methods using appropriate benchmarks. The issue addressed is very important for the analysis of high-dimensional data and interesting for a broader readership as addressed by BD. Referencing and relation to state-of-the art is given appropriately. The method presented is novel, original and sound and obviously improves available solutions. Presentation, however, in general is suboptimal and requires revision. Particularly, I suggest the following points: 1. A large number of abbreviations are used and the reader gets completely lost in this jungle. I suggest to add a glossary which decodes and partly explains all abbreviations used, especially the different variants of methods used.</p><p><bold><italic>Author&#x02019;s response</italic></bold><italic>We have added short subsection in the</italic><italic>Methods</italic><italic>Methods section named: Symbols and abbreviations.</italic></p><p>2. The methodical part mixes basal points (e.g. how works PLS) with more peripheral ones (e.g. different benchmarking criteria such as stability plots etc.). The reader is overloaded with algorithmic details and formulae. The latter points are of course also important but many things become clear always on an intuitive level. I suggest to remove all non-essential details (e.g. all or, at least, part of the benchmark criteria) from the methodical part and to shift them into an appendix or supplementary text. The basal idea for benchmarks can be given in the methodical part very shortly in prosaic form (i.e. without formulae and algorithmic details).</p><p><bold><italic>Author&#x02019;s response</italic></bold><italic>According to the suggestion we shift the part of the benchmark criteria into the</italic><italic>Appendix</italic><italic>section.</italic></p><p>3. In my opinion, the methodical part should focus on the kernel of the new method, i.e. PLS and the decomposition into two-class comparisons and comparison with state of the art. Partly this information is given but mostly hidden in a heap of other things (see point 2.). A schematic figure that explains the essentials and novel aspects of the method and also visualizes the workflow might be very helpful. Possibly this scheme might visualize also differences with respect to other approaches. This point represents a real challenge but possibly the authors can solve it.</p><p><bold><italic>Author&#x02019;s response</italic></bold><italic>We have added a new figure with a scheme that explains the gene selection method based on PLS.</italic></p><p>4. The authors used 3 data sets for verification and 4 types of presentation which provides 3x4=12 figures at the end. This broad data basis allows proper verification of the methods. However, the results of benchmarking of the three different data sets are mostly similar if not identical with respect to the benchmark criteria applied. Here the reader is overloaded with very similar figures with mostly redundant information content. I suggest removing 2/3 of the figures into a supplementary file and to show only one of each type in the main paper.</p><p><bold><italic>Author&#x02019;s response</italic></bold><italic>We have moved figures for MLL and SRBCT datasets into a</italic><italic>Appendix</italic><italic>section.</italic></p><p>5. In exceptional cases the results for the different data sets slightly differ (e.g. Figure <xref ref-type="fig" rid="F5">5</xref> versus Figure 6). These details should be discussed.</p><p><bold><italic>Author&#x02019;s response</italic></bold><italic>We have added short discussion about these results in the</italic><italic>Results and Discussion</italic><italic>section</italic></p><p>6. The data sets are described in the Results-section, which dilutes the information content of the paper. I suggest moving this information into a &#x02018;Data&#x02019;-subsection in the Methods-chapter (incl. links and preprocessing).</p><p><bold><italic>Author&#x02019;s response</italic></bold><italic>We have moved these data sets description into the</italic><italic>Datasets</italic><italic>section.</italic></p><p>7. Main point: The benchmarking demonstrates that the PLS-variants used outperform the other methods. It would be desirable to understand the underlying principal reason for this difference and to generalize this finding. In the Conclusions section this question is shortly addressed. However, this issue, in my opinion, requires much more attention beyond all the benchmarking details. Obviously the decomposition of the multiclass problem into a series of two-class problems is more favorable than to solve the multiclass-problem at once. What is the deeper reason that causes this benefit. On the other hand: why, for example, simple t-testing performs worst. I strongly encourage the authors to extend the paper in this respect.</p><p><bold><italic>Author&#x02019;s response</italic></bold><italic>We have extended the</italic><italic>Conclusions</italic><italic>section and have discussed these questions, but we must agree, that it is hard to find the real explanation for our findings, especially, because multiclass problems are more complicated, than the two class problems.</italic></p><p>8. The authors should provide a computer program of their approach along with the paper that might be used by others.</p><p><bold><italic>Author&#x02019;s response</italic></bold><italic>Because bootstrap technique is computationally expensive, we apply our software on the computer cluster, which make it very difficult to publish. The main problem is that our software is not dedicated for personal computers, and for that reason we decided not to publish this code.</italic></p><p>Further minor points: 9. Both axes in all figures must be assigned. I.e. the y-axes must be labeled in Figures <xref ref-type="fig" rid="F5">5</xref>, 6 and 7 with &#x02018;accuracy&#x02019; and in Figures 8, 9 and 10 with something else (BBFR-score which defines simply the mean degree of agreement of gene ranking after bootstrap).10. The step-function in Figures 8, 9 and 10 must be shortly explained in the legend and in the text (might I overlooked details). The ideal curve is far different from the real ones. The authors should discuss why a list-length of 30 was assumed. This choice seems rather arbitrary.11. Legend of Figures 8, 9 and 10: It is claimed that &#x02018;every dot represents one gene&#x02019;. I miss the dots.12. Please indicate that the Tables are provided in the supplement and not in the main text.13. Define accuracy on p. 3.14. Define BSS/WSS on p. 6 (sum of squares&#x02026;???)!15. &#x02018;Scalars&#x02019; should be presumably substituted by &#x02018;scores&#x02019; on p. 7, line below Eq. (10)?</p><p><bold><italic>Author&#x02019;s response</italic></bold><italic>We have edited the manuscript and corrected these mistakes.</italic></p></sec><sec><title>Quality of written English</title><p>Acceptable</p></sec><sec><title>Dr Yuriy Gusev</title></sec><sec><title>Report form</title><p>General comments: The manuscript addresses one of the important problems in gene expression analysis i.e. feature selection for multiclass classicization of microarray data in cancer. While this problem has been investigated by many over past 10 years or so, the importance of utilization of gene expression data for classification of cancer samples remains high. This is mainly because of several potentially important practical applications in cancer diagnostics and prediction of drug response. Also &#x02013; practical utilization of gene expression signatures has been questioned by many due to the known problems of reproducibility and validation. This paper addresses some of these issues by detailed analysis of stability of existing most popular classification algorithms as well as new method proposed by the authors. This study might have other important implications as it could be applicable to other types of global molecular profiling that are becoming more popular in recent years such as DNA copy number variation, exome profiling and RNAseq. The paper could benefit from additional discussion of this issue of applicability of the proposed methods for other types of omics data such as RNAseq and CNV.</p><p><bold><italic>Author&#x02019;s response</italic></bold><italic>We have added in the</italic><italic>Conclusions</italic><italic>section the information about other possible applications of the presented feature selection methods.</italic></p><p>Strengths and weaknesses: This study has several strengths: a comparison of performance of many existing classification methods both in term of accuracy and stability of feature selection for the multiclass analysis. Also &#x02013; this work is focused on developing of new methodology of effective identification of the most informative genes with main goal of finding a small subset of most accurate features. The authors for the first time have demonstrated effectiveness of decomposition of mutli-class classification problem into series of sub-problem of two-class selection. The important part of this work was applying these methods for analysis of 3 independent data set for 3 types of cancer. Weaknesses of this study include: throughout the study the authors rely on bootstrap resampling for all estimations of accuracy and stability which is quite common technique. However the validity of such approach for testing of gene expression classifiers has been questioned in the literature. It has been reported that permutation based estimates could be a poor substitute for testing a classier on an independent set of real gene expression data. It would be interesting to see how well the proposed methods perform when tested on such independent gene expression datasets. It would be good to see additional discussion of this issue in the paper.</p><p><bold><italic>Author&#x02019;s response</italic></bold><italic>We have added additional discussion of the mentioned issue in the Bootstrap resampling section.</italic></p><p>Also &#x02013; this study is using 500 resampling iterations for all steps of classifier construction however it is not clear if this is sufficient to ensure stability of the results, it would be useful if author could include additional comments on the reason for using 500 interactions.</p><p><bold><italic>Author&#x02019;s response</italic></bold><italic>We have added additional explanation in the Bootstrap resampling section.</italic></p><p>Overall, this is detailed study of the important issues related to classification of cancer samples based on global gene expression profiling. It is addresses several technical issues of accuracy and stability of classification results. Reviewer recommends considering publishing this paper in more specialized journal which could provide a better targeted readership in the bioinformatics community.</p><p><bold><italic>Author&#x02019;s response</italic></bold><italic>Because of applicability of the proposed methods for other high dimension biological data, this problem is important not only for readership in the bioinformatics. In our opinion the problems of reproducibility and stability of obtained features is especially important for biologists, people who work with biological data.</italic></p></sec><sec><title>Quality of written English</title><p>Acceptable</p></sec></sec><sec><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec><title>Authors&#x02019; contributions</title><p>SS and KF contributed equally to this work. Both authors read and approved the final manuscript.</p></sec></body><back><sec><title>Acknowledgements</title><p>This work was supported by the Polish National Science Center under grants: N N519 647840 (S.S.) and 2012/04/A/ST7/00353 (K.F.).</p></sec><ref-list><ref id="B1"><mixed-citation publication-type="journal"><name><surname>He</surname><given-names>Z</given-names></name><name><surname>Yu</surname><given-names>W</given-names></name><article-title>Stable feature selection for biomarker discovery</article-title><source>Comput Biol and Chem</source><year>2010</year><volume>34</volume><issue>4</issue><fpage>215</fpage><lpage>225</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1001.0887">http://arxiv.org/abs/1001.0887</ext-link>]</comment><pub-id pub-id-type="doi">10.1016/j.compbiolchem.2010.07.002</pub-id><pub-id pub-id-type="pmid">20702140</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><name><surname>Binder</surname><given-names>H</given-names></name><name><surname>Krohn</surname><given-names>K</given-names></name><name><surname>Burden</surname><given-names>CJ</given-names></name><article-title>Washing scaling of GeneChip microarray expression</article-title><source>BMC Bioinf</source><year>2010</year><volume>11</volume><fpage>291</fpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2901370&#x00026;tool=pmcentrez&#x00026;rendertype=abstract">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2901370&#x00026;tool=pmcentrez&#x00026;rendertype=abstract</ext-link>]</comment><pub-id pub-id-type="doi">10.1186/1471-2105-11-291</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><name><surname>Binder</surname><given-names>H</given-names></name><name><surname>Preibisch</surname><given-names>S</given-names></name><name><surname>Berger</surname><given-names>H</given-names></name><article-title>Calibration of microarray gene-expression data</article-title><source>Methods In Mol Biol Clifton Nj</source><year>2010</year><volume>576</volume><issue>16</issue><fpage>375</fpage><lpage>407</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/19882273">http://www.ncbi.nlm.nih.gov/pubmed/19882273</ext-link>]</comment></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><name><surname>Dutkowski</surname><given-names>J</given-names></name><name><surname>Gambin</surname><given-names>A</given-names></name><article-title>On consensus biomarker selection</article-title><source>BMC Bioinf</source><year>2007</year><volume>8</volume><issue>Suppl 5</issue><fpage>S5</fpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/17570864">http://www.ncbi.nlm.nih.gov/pubmed/17570864</ext-link>]</comment><pub-id pub-id-type="doi">10.1186/1471-2105-8-S5-S5</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>T</given-names></name><name><surname>Li</surname><given-names>C</given-names></name><name><surname>Ogihara</surname><given-names>M</given-names></name><article-title>A comparative study of feature selection and multiclass classification methods for tissue classification based on gene expression</article-title><source>Bioinformatics</source><year>2004</year><volume>20</volume><issue>15</issue><fpage>2429</fpage><lpage>2437</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/bth267</pub-id><pub-id pub-id-type="pmid">15087314</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><name><surname>Draminski</surname><given-names>M</given-names></name><name><surname>Rada-Iglesias</surname><given-names>A</given-names></name><name><surname>Enroth</surname><given-names>S</given-names></name><name><surname>Wadelius</surname><given-names>C</given-names></name><name><surname>Koronacki</surname><given-names>J</given-names></name><name><surname>Komorowski</surname><given-names>J</given-names></name><article-title>Monte Carlo feature selection for supervised classification</article-title><source>Bioinformatics</source><year>2008</year><volume>24</volume><fpage>110</fpage><lpage>117</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/btm486">http://www.bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/btm486</ext-link>]</comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btm486</pub-id><pub-id pub-id-type="pmid">18048398</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><name><surname>Guyon</surname><given-names>I</given-names></name><name><surname>Weston</surname><given-names>J</given-names></name><name><surname>Barnhill</surname><given-names>S</given-names></name><name><surname>Vapnik</surname><given-names>V</given-names></name><article-title>Gene selection for cancer classification using support vector machines</article-title><source>Machine Learning</source><year>2002</year><volume>46</volume><fpage>389</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1023/A:1012487302797</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><name><surname>Nguyen</surname><given-names>DV</given-names></name><name><surname>Rocke</surname><given-names>DM</given-names></name><article-title>Tumor classification by partial least squares using microarray gene expression data</article-title><source>Bioinformatics</source><year>2002</year><volume>18</volume><issue>1</issue><fpage>39</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/18.1.39</pub-id><pub-id pub-id-type="pmid">11836210</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><name><surname>H&#x000f6;skuldsson</surname><given-names>A</given-names></name><article-title>PLS regression methods</article-title><source>J Chemom</source><year>1988</year><volume>2</volume><issue>3</issue><fpage>211</fpage><lpage>228</lpage><pub-id pub-id-type="doi">10.1002/cem.1180020306</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><name><surname>Yang</surname><given-names>K</given-names></name><name><surname>Cai</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Lin</surname><given-names>G</given-names></name><article-title>A stable gene selection in microarray data analysis</article-title><source>BMC Bioinf</source><year>2006</year><volume>7</volume><fpage>228</fpage><pub-id pub-id-type="doi">10.1186/1471-2105-7-228</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><name><surname>Gutkin</surname><given-names>M</given-names></name><name><surname>Dror</surname><given-names>G</given-names></name><collab>Shamir1 R</collab><article-title>SlimPLS: A method for feature selection in gene expression-based disease classification</article-title><source>PLoS One</source><year>2009</year><volume>4</volume><issue>7</issue></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><name><surname>Boulesteix</surname><given-names>A</given-names></name><name><surname>Slawski</surname><given-names>M</given-names></name><article-title>Stability and aggregation of ranked gene lists</article-title><source>Brief Bioinform</source><year>2009</year><volume>10</volume><issue>5</issue><fpage>556</fpage><lpage>568</lpage><pub-id pub-id-type="doi">10.1093/bib/bbp034</pub-id><pub-id pub-id-type="pmid">19679825</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><name><surname>Boulesteix</surname><given-names>A</given-names></name><name><surname>Strobl</surname><given-names>C</given-names></name><name><surname>Augustin</surname><given-names>T</given-names></name><name><surname>Daumer</surname><given-names>M</given-names></name><article-title>Evaluating Microarray-based classifiers: an overview</article-title><source>Cancer Informatics</source><year>2008</year><volume>6</volume><fpage>77</fpage><lpage>97</lpage><pub-id pub-id-type="pmid">19259405</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><name><surname>Efron</surname><given-names>B</given-names></name><article-title>Bootstrap methods: another look look at the jackknife</article-title><source>Ann Stat</source><year>1979</year><volume>7</volume><fpage>1</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1214/aos/1176344552</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><name><surname>Braga-Neto</surname><given-names>U</given-names></name><name><surname>Dougherty</surname><given-names>ER</given-names></name><article-title>Is cross-validation valid for small-sample microarray classification?</article-title><source>Bioinformatics</source><year>2004</year><volume>20</volume><issue>3</issue><fpage>374</fpage><lpage>380</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btg419</pub-id><pub-id pub-id-type="pmid">14960464</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><name><surname>Garcia-Bilbao</surname><given-names>A</given-names></name><name><surname>Armananzas</surname><given-names>R</given-names></name><name><surname>Ispizua</surname><given-names>Z</given-names></name><name><surname>Calvo</surname><given-names>B</given-names></name><name><surname>Alonso-Varona</surname><given-names>A</given-names></name><name><surname>Inza</surname><given-names>I</given-names></name><name><surname>Larranaga</surname><given-names>P</given-names></name><name><surname>Lopez Vivanco</surname><given-names>G</given-names></name><name><surname>Suarez-Merino</surname><given-names>B</given-names></name><name><surname>Betanzos</surname><given-names>M</given-names></name><article-title>Identification of a biomarker panel for colorectal cancer diagnosis</article-title><source>BMC Cancer</source><year>2012</year><volume>12</volume><fpage>43</fpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/22280244">http://www.ncbi.nlm.nih.gov/pubmed/22280244</ext-link>]</comment><pub-id pub-id-type="doi">10.1186/1471-2407-12-43</pub-id><pub-id pub-id-type="pmid">22280244</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><name><surname>Abraham</surname><given-names>G</given-names></name><name><surname>Kowalczyk</surname><given-names>A</given-names></name><name><surname>Loi</surname><given-names>S</given-names></name><name><surname>Haviv</surname><given-names>I</given-names></name><name><surname>Zobel</surname><given-names>J</given-names></name><article-title>Prediction of breast cancer prognosis using gene set statistics provides signature stability and biological context</article-title><source>BMC Bioinformatics</source><year>2010</year><volume>11</volume><fpage>277</fpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2895626&#x00026;tool=pmcentrez&#x00026;rendertype=abstract">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2895626&#x00026;tool=pmcentrez&#x00026;rendertype=abstract</ext-link>]</comment><pub-id pub-id-type="doi">10.1186/1471-2105-11-277</pub-id><pub-id pub-id-type="pmid">20500821</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><name><surname>Arma&#x000f1;anzas</surname><given-names>R</given-names></name><name><surname>Inza</surname><given-names>IN</given-names></name><name><surname>Larra&#x000f1;aga</surname><given-names>P</given-names></name><article-title>Detecting reliable gene interactions by a hierarchy of Bayesian network classifiers</article-title><source>Comput Methods Programs Biomed</source><year>2008</year><volume>91</volume><issue>2</issue><fpage>110</fpage><lpage>121</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/18433926">http://www.ncbi.nlm.nih.gov/pubmed/18433926</ext-link>]</comment><pub-id pub-id-type="doi">10.1016/j.cmpb.2008.02.010</pub-id><pub-id pub-id-type="pmid">18433926</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><name><surname>Fu</surname><given-names>WJ</given-names></name><name><surname>Carroll</surname><given-names>RJ</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><article-title>Estimating misclassification error with small samples via bootstrap cross-validation</article-title><source>Bioinformatics</source><year>2005</year><volume>21</volume><issue>9</issue><fpage>1979</fpage><lpage>1986</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/15691862">http://www.ncbi.nlm.nih.gov/pubmed/15691862</ext-link>]</comment><pub-id pub-id-type="doi">10.1093/bioinformatics/bti294</pub-id><pub-id pub-id-type="pmid">15691862</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><name><surname>Meuwissen</surname><given-names>TH</given-names></name><name><surname>Goddard</surname><given-names>ME</given-names></name><article-title>Bootstrapping of gene-expression data improves and controls the false discovery rate of differentially expressed genes</article-title><source>Genet Sel evol GSE</source><year>2004</year><volume>36</volume><issue>2</issue><fpage>191</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1186/1297-9686-36-2-191</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="other"><name><surname>Efron</surname><given-names>N</given-names></name><name><surname>Intrator</surname><given-names>N</given-names></name><article-title>The effect of noisy bootstrapping on the robustness of supervised classification of gene expression data</article-title><year>2004</year><comment>[<ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1423002">http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1423002</ext-link>]</comment></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><name><surname>Dvison</surname><given-names>A</given-names></name><name><surname>Hinkley</surname><given-names>D</given-names></name><name><surname>Schechtman</surname><given-names>E</given-names></name><article-title>Efficient bootstrap simulation</article-title><source>Biometrika</source><year>1986</year><volume>73</volume><issue>3</issue><fpage>555</fpage><lpage>566</lpage></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><name><surname>Hall</surname><given-names>P</given-names></name><article-title>Performance of balanced bootstrap resampling in distribution function and Quantile problems</article-title><source>Probability Theory</source><year>1990</year><volume>85</volume><fpage>239</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1007/BF01277983</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><name><surname>Efron</surname><given-names>B</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name><article-title>Improvements on cross-validation: the 632+ bootstrap method</article-title><source>J Amer Statist Assoc</source><year>1997</year><volume>92</volume><fpage>548</fpage><lpage>560</lpage></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><name><surname>Efron</surname><given-names>B</given-names></name><article-title>Estimating the error rate of a prediction rule: improvement on cross-validation</article-title><source>J Amer Stat Assoc</source><year>1983</year><volume>78</volume><issue>382</issue><fpage>316</fpage><lpage>331</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.jstor.org/stable/2288636?origin=crossref">http://www.jstor.org/stable/2288636?origin=crossref</ext-link>]</comment><pub-id pub-id-type="doi">10.1080/01621459.1983.10477973</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><name><surname>Wold</surname><given-names>H</given-names></name><article-title>Soft modeling: the basic design and some extensions</article-title><source>Syst Under Indirect Observation</source><year>1982</year><volume>2</volume><fpage>589</fpage><lpage>591</lpage></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><name><surname>Tibshirani</surname><given-names>R</given-names></name><article-title>Regression shrinkage and selection via the lasso</article-title><source>J R Stat Soc Ser B Methodological</source><year>1996</year><volume>58</volume><fpage>267</fpage><lpage>288</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.jstor.org/stable/2346178">http://www.jstor.org/stable/2346178</ext-link>]</comment></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><name><surname>Hoerl</surname><given-names>AE</given-names></name><article-title>Application of ridge analysis to regression problems</article-title><source>Chem Eng Prog</source><year>1962</year><volume>58</volume><fpage>54</fpage><lpage>59</lpage></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><name><surname>Chong</surname><given-names>IG</given-names></name><name><surname>Jun</surname><given-names>CH</given-names></name><article-title>Performance of some variable selection methods when multicollinearity is present</article-title><source>Chemom Intell Lab Systs</source><year>2005</year><volume>78</volume><issue>1-2</issue><fpage>103</fpage><lpage>112</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.chemolab.2004.12.011">http://dx.doi.org/10.1016/j.chemolab.2004.12.011</ext-link>]</comment><pub-id pub-id-type="doi">10.1016/j.chemolab.2004.12.011</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><name><surname>Nguyen</surname><given-names>DV</given-names></name><name><surname>Rocke</surname><given-names>DM</given-names></name><article-title>Multi-class cancer classification via partial least squares with gene expression profiles</article-title><source>Bioinformatics</source><year>2002</year><volume>18</volume><issue>9</issue><fpage>1216</fpage><lpage>1226</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.bioinformatics.oupjournals.org/cgi/doi/10.1093/bioinformatics/18.9.1216">http://www.bioinformatics.oupjournals.org/cgi/doi/10.1093/bioinformatics/18.9.1216</ext-link>]</comment><pub-id pub-id-type="doi">10.1093/bioinformatics/18.9.1216</pub-id><pub-id pub-id-type="pmid">12217913</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><name><surname>Boulesteix</surname><given-names>AL</given-names></name><article-title>PLS dimension reduction for classification with microarray data</article-title><source>Stat Appl Genet Mol Biol</source><year>2004</year><volume>3</volume><issue>Article33</issue><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/17049027">http://www.ncbi.nlm.nih.gov/pubmed/17049027</ext-link>]</comment></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><name><surname>Gidskehaug</surname><given-names>L</given-names></name><name><surname>Anderssen</surname><given-names>E</given-names></name><name><surname>Flatberg</surname><given-names>A</given-names></name><name><surname>Alsberg</surname><given-names>BK</given-names></name><article-title>A framework for significance analysis of gene expression data using dimension reduction methods</article-title><source>BMC Bioinf</source><year>2007</year><volume>8</volume><fpage>346+</fpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/1471-2105-8-346">http://dx.doi.org/10.1186/1471-2105-8-346</ext-link>]</comment><pub-id pub-id-type="doi">10.1186/1471-2105-8-346</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><name><surname>Johansson</surname><given-names>D</given-names></name><name><surname>Lindgren</surname><given-names>P</given-names></name><name><surname>Berglund</surname><given-names>A</given-names></name><article-title>A multivariate approach applied to microarray data for identification of genes with cell cycle-coupled transcription</article-title><source>Bioinformatics</source><year>2003</year><volume>19</volume><issue>4</issue><fpage>467</fpage><lpage>473</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.bioinformatics.oupjournals.org/cgi/doi/10.1093/bioinformatics/btg017">http://www.bioinformatics.oupjournals.org/cgi/doi/10.1093/bioinformatics/btg017</ext-link>]</comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btg017</pub-id><pub-id pub-id-type="pmid">12611801</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><name><surname>Martens</surname><given-names>H</given-names></name><article-title>Modified Jack-knife estimation of parameter uncertainty in bilinear modelling by partial least squares regression (PLSR)</article-title><source>Food Quality Preference</source><year>2000</year><volume>11</volume><issue>1-2</issue><fpage>5</fpage><lpage>16</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://linkinghub.elsevier.com/retrieve/pii/S0950329399000397">http://linkinghub.elsevier.com/retrieve/pii/S0950329399000397</ext-link>]</comment><pub-id pub-id-type="doi">10.1016/S0950-3293(99)00039-7</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><name><surname>Boulesteix</surname><given-names>AL</given-names></name><name><surname>Strimmer</surname><given-names>K</given-names></name><article-title>Partial least squares: a versatile tool for the analysis of high-dimensional genomic data</article-title><source>Briefings Bioinf</source><year>2007</year><volume>8</volume><fpage>32</fpage><lpage>44</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/16772269">http://www.ncbi.nlm.nih.gov/pubmed/16772269</ext-link>]</comment></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><name><surname>Musumarra</surname><given-names>G</given-names></name><name><surname>Barresi</surname><given-names>V</given-names></name><name><surname>Condorelli</surname><given-names>DF</given-names></name><name><surname>Fortuna</surname><given-names>CG</given-names></name><name><surname>Scir&#x0010d;</surname><given-names>S</given-names></name><article-title>Potentialities of multivariate approaches in genome-based cancer research: identification of candidate genes for new diagnostics by PLS discriminant analysis</article-title><source>J Chemom</source><year>2004</year><volume>18</volume><issue>34</issue><fpage>125</fpage><lpage>132</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://doi.wiley.com/10.1002/cem.846">http://doi.wiley.com/10.1002/cem.846</ext-link>]</comment><pub-id pub-id-type="doi">10.1002/cem.846</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><name><surname>Barker</surname><given-names>M</given-names></name><name><surname>Rayens</surname><given-names>W</given-names></name><article-title>Partial least squares for discrimination</article-title><source>J Chemom</source><year>2003</year><volume>17</volume><issue>3</issue><fpage>166</fpage><lpage>173</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://doi.wiley.com/10.1002/cem.785">http://doi.wiley.com/10.1002/cem.785</ext-link>]</comment><pub-id pub-id-type="doi">10.1002/cem.785</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><name><surname>Helland</surname><given-names>IS</given-names></name><article-title>On the structure of partial least squares regression</article-title><source>Commun Stat Simul Comput</source><year>1988</year><volume>17</volume><issue>2</issue><fpage>581</fpage><lpage>607</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.informaworld.com/openurl?genre=article&#x00026;doi=10.1080/03610918808812681&#x00026;magic=crossref">http://www.informaworld.com/openurl?genre=article&#x00026;doi=10.1080/03610918808812681&#x00026;magic=crossref</ext-link>]</comment><pub-id pub-id-type="doi">10.1080/03610918808812681</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><name><surname>Geladi</surname><given-names>P</given-names></name><name><surname>Kowalski</surname><given-names>BR</given-names></name><article-title>Partial least-squares regresion: a tutorial</article-title><source>Analytica Chimica Acta</source><year>1986</year><volume>185</volume><fpage>1</fpage><lpage>17</lpage></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><name><surname>De Jong</surname><given-names>S</given-names></name><article-title>SIMPLS: An alternative approach to partial least squares regression</article-title><source>Chemometrics Intell Lab Syst</source><year>1993</year><volume>18</volume><fpage>25</fpage><lpage>263</lpage></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><name><surname>He</surname><given-names>H</given-names></name><name><surname>Jazdzewski</surname><given-names>K</given-names></name><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Liyanarachchi</surname><given-names>S</given-names></name><name><surname>Nagy</surname><given-names>R</given-names></name><name><surname>Volinia</surname><given-names>S</given-names></name><name><surname>Calin</surname><given-names>GA</given-names></name><name><surname>Liu</surname><given-names>Cg</given-names></name><name><surname>Franssila</surname><given-names>K</given-names></name><name><surname>Suster</surname><given-names>S</given-names></name><etal/><article-title>The role of microRNA genes in papillary thyroid carcinoma</article-title><source>Proc Nat Acad Sci USA</source><year>2005</year><volume>102</volume><issue>52</issue><fpage>19075</fpage><lpage>19080</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1323209&#x00026;tool=pmcentrez&#x00026;rendertype=abstract">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1323209&#x00026;tool=pmcentrez&#x00026;rendertype=abstract</ext-link>]</comment><pub-id pub-id-type="doi">10.1073/pnas.0509603102</pub-id><pub-id pub-id-type="pmid">16365291</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><name><surname>VanStaveren</surname><given-names>WCG</given-names></name><name><surname>Solis</surname><given-names>DW</given-names></name><name><surname>Delys</surname><given-names>L</given-names></name><name><surname>Duprez</surname><given-names>L</given-names></name><name><surname>Andry</surname><given-names>G</given-names></name><name><surname>Franc</surname><given-names>B</given-names></name><name><surname>Thomas</surname><given-names>G</given-names></name><name><surname>Libert</surname><given-names>F</given-names></name><name><surname>Dumont</surname><given-names>JE</given-names></name><name><surname>Detours</surname><given-names>V</given-names></name><etal/><article-title>Human thyroid tumor cell lines derived from different tumor types present a common dedifferentiated phenotype</article-title><source>Cancer Res</source><year>2007</year><volume>67</volume><issue>17</issue><fpage>8113</fpage><lpage>8120</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/17804723">http://www.ncbi.nlm.nih.gov/pubmed/17804723</ext-link>]</comment><pub-id pub-id-type="doi">10.1158/0008-5472.CAN-06-4026</pub-id><pub-id pub-id-type="pmid">17804723</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>T</given-names></name><name><surname>Li</surname><given-names>C</given-names></name><name><surname>Ogihara</surname><given-names>M</given-names></name><article-title>Evaluating reproducibility of differential expression discoveries in microarray studies by considering correlated molecular changes</article-title><source>Bioinformatics</source><year>2009</year><volume>25</volume><issue>13</issue><fpage>1662</fpage><lpage>1668</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btp295</pub-id><pub-id pub-id-type="pmid">19417058</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><name><surname>Fujarewicz</surname><given-names>K</given-names></name><article-title>A multigene approach to differentiate papillary thyroid carcinoma from benign lesions: gene selection using bootstrap-based Support Vector Machines</article-title><source>Endocrine - Related Cancer</source><year>2007</year><volume>14</volume><fpage>809</fpage><lpage>826</lpage><pub-id pub-id-type="doi">10.1677/ERC-06-0048</pub-id><pub-id pub-id-type="pmid">17914110</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><name><surname>Bhattacharjee</surname><given-names>Aaa</given-names></name><article-title>Classification of human lung carcinomas by mRNA expression profiling reveals distinct adenocarcinoma subclasses</article-title><source>PNAS</source><year>2001</year><volume>98</volume><issue>24</issue><fpage>13790</fpage><lpage>13795</lpage><pub-id pub-id-type="doi">10.1073/pnas.191502998</pub-id><pub-id pub-id-type="pmid">11707567</pub-id></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><name><surname>Ferrari</surname><given-names>F</given-names></name><name><surname>Bortoluzzi</surname><given-names>S</given-names></name><name><surname>Coppe</surname><given-names>A</given-names></name><name><surname>Sirota</surname><given-names>A</given-names></name><name><surname>Safran</surname><given-names>Maa</given-names></name><article-title>Novel definition files for human GeneChips based on GeneAnnot</article-title><source>BMC Bioinf</source><year>2007</year><volume>8</volume><issue>446</issue></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><name><surname>Armstrong</surname><given-names>S</given-names></name><name><surname>Staunton</surname><given-names>J</given-names></name><name><surname>Silverman</surname><given-names>L</given-names></name><name><surname>Pieters</surname><given-names>R</given-names></name><name><surname>den Boer</surname><given-names>M</given-names></name><name><surname>Minden</surname><given-names>M</given-names></name><name><surname>Sallan</surname><given-names>S</given-names></name><name><surname>Lander</surname><given-names>E</given-names></name><name><surname>Golub</surname><given-names>T</given-names></name><name><surname>Korsmeyer</surname><given-names>S</given-names></name><article-title>MLL translocations specify a distinct gene expression profile that distinguishes a unique leukemia</article-title><source>Nat Genet</source><year>2002</year><volume>30</volume><fpage>41</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1038/ng765</pub-id><pub-id pub-id-type="pmid">11731795</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><name><surname>Khan</surname><given-names>J</given-names></name><name><surname>Wei</surname><given-names>J</given-names></name><name><surname>Ringner</surname><given-names>M</given-names></name><name><surname>Saal</surname><given-names>L</given-names></name><name><surname>Ladanyi</surname><given-names>M</given-names></name><name><surname>Westermann</surname><given-names>F</given-names></name><name><surname>Berthold</surname><given-names>F</given-names></name><name><surname>Schwab</surname><given-names>M</given-names></name><name><surname>Antonescu</surname><given-names>C</given-names></name><name><surname>Peterson</surname><given-names>C</given-names></name><name><surname>Meltzer</surname><given-names>P</given-names></name><article-title>Classification and diagnostic prediction of cancers using gene expression profiling and artificial neural networks</article-title><source>Nat Med</source><year>2001</year><volume>7</volume><fpage>673</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1038/89044</pub-id><pub-id pub-id-type="pmid">11385503</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><name><surname>Detours</surname><given-names>V</given-names></name><name><surname>Wattel</surname><given-names>S</given-names></name><name><surname>Venet</surname><given-names>D</given-names></name><name><surname>Hutsebaut</surname><given-names>N</given-names></name><name><surname>Bogdanova</surname><given-names>T</given-names></name><name><surname>Tronko</surname><given-names>MD</given-names></name><name><surname>Dumont</surname><given-names>JE</given-names></name><name><surname>Franc</surname><given-names>B</given-names></name><name><surname>Thomas</surname><given-names>G</given-names></name><name><surname>Maenhaut</surname><given-names>C</given-names></name><article-title>Absence of a specific radiation signature in post-Chernobyl thyroid cancers</article-title><source>British J Cancer</source><year>2005</year><volume>92</volume><issue>8</issue><fpage>1545</fpage><lpage>1552</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2362019&#x00026;tool=pmcentrez&#x00026;rendertype=abstract">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2362019&#x00026;tool=pmcentrez&#x00026;rendertype=abstract</ext-link>]</comment><pub-id pub-id-type="doi">10.1038/sj.bjc.6602521</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><name><surname>Jarzab</surname><given-names>B</given-names></name><name><surname>Wiench</surname><given-names>M</given-names></name><name><surname>Fujarewicz</surname><given-names>K</given-names></name><name><surname>Simek</surname><given-names>K</given-names></name><name><surname>Jarzab</surname><given-names>M</given-names></name><name><surname>Oczko-Wojciechowska</surname><given-names>M</given-names></name><name><surname>Wloch</surname><given-names>J</given-names></name><name><surname>Czarniecka</surname><given-names>A</given-names></name><name><surname>Chmielik</surname><given-names>E</given-names></name><name><surname>Lange</surname><given-names>D</given-names></name><etal/><article-title>Gene expression profile of papillary thyroid cancer: sources of variability and diagnostic implications</article-title><source>Cancer Res</source><year>2005</year><volume>65</volume><issue>4</issue><fpage>1587</fpage><lpage>1597</lpage><comment>[<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/15735049">http://www.ncbi.nlm.nih.gov/pubmed/15735049</ext-link>]</comment><pub-id pub-id-type="doi">10.1158/0008-5472.CAN-04-3078</pub-id><pub-id pub-id-type="pmid">15735049</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><name><surname>Fujarewicz</surname><given-names>K</given-names></name><name><surname>Kimmel</surname><given-names>M</given-names></name><name><surname>Rzeszowska-Wolny</surname><given-names>J</given-names></name><name><surname>Swierniak</surname><given-names>A</given-names></name><article-title>A note on classification of gene expression data using support vector machines</article-title><source>J Biol Syst</source><year>2003</year><volume>11</volume><fpage>43</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1142/S0218339003000658</pub-id></mixed-citation></ref></ref-list></back></article>