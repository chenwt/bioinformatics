<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d2 20140930//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 2?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id><journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id><journal-title-group><journal-title>BMC Bioinformatics</journal-title></journal-title-group><issn pub-type="epub">1471-2105</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">4640241</article-id><article-id pub-id-type="publisher-id">795</article-id><article-id pub-id-type="doi">10.1186/s12859-015-0795-6</article-id><article-categories><subj-group subj-group-type="heading"><subject>Software</subject></subj-group></article-categories><title-group><article-title>TOGGLE: toolbox for generic NGS analyses</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Monat</surname><given-names>C&#x000e9;cile</given-names></name><address><email>cecile.monat@ird.fr</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Tranchant-Dubreuil</surname><given-names>Christine</given-names></name><address><email>christine.tranchant@ird.fr</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Kougbeadjo</surname><given-names>Ayit&#x000e9;</given-names></name><address><email>ayite.kougbeadjo@cirad.fr</email></address><xref ref-type="aff" rid="Aff2"/></contrib><contrib contrib-type="author"><name><surname>Farcy</surname><given-names>C&#x000e9;dric</given-names></name><address><email>cedric.farcy@cirad.fr</email></address><xref ref-type="aff" rid="Aff2"/></contrib><contrib contrib-type="author"><name><surname>Ortega-Abboud</surname><given-names>Enrique</given-names></name><address><email>enrique.ortega-abboud@cirad.fr</email></address><xref ref-type="aff" rid="Aff2"/></contrib><contrib contrib-type="author"><name><surname>Amanzougarene</surname><given-names>Souhila</given-names></name><address><email>souhila.amanzougarene@ird.fr</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Ravel</surname><given-names>S&#x000e9;bastien</given-names></name><address><email>sebastien.ravel@cirad.fr</email></address><xref ref-type="aff" rid="Aff3"/></contrib><contrib contrib-type="author"><name><surname>Agbessi</surname><given-names>Mawuss&#x000e9;</given-names></name><address><email>mawusse.agbessi@ird.fr</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Orjuela-Bouniol</surname><given-names>Julie</given-names></name><address><email>julie.orjuela@adnid.fr</email></address><xref ref-type="aff" rid="Aff4"/></contrib><contrib contrib-type="author"><name><surname>Summo</surname><given-names>Maryline</given-names></name><address><email>maryline.summo@cirad.fr</email></address><xref ref-type="aff" rid="Aff2"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Sabot</surname><given-names>Fran&#x000e7;ois</given-names></name><address><email>francois.sabot@ird.fr</email></address><xref ref-type="aff" rid="Aff1"/></contrib><aff id="Aff1"><label/>UMR DIADE IRD/UM, 911 Avenue Agropolis, Montpellier Cedex 5, F-34934 France </aff><aff id="Aff2"><label/>UMR AGAP CIRAD/INRA/SupAgro, TA A-108/03 - Avenue Agropolis, Montpellier Cedex 5, F-34398 France </aff><aff id="Aff3"><label/>UMR-BGPI CIRAD TA A-54/K, Campus International de Baillarguet, Montpellier Cedex 5, F-34398 France </aff><aff id="Aff4"><label/>ADNid, Cap Alpha, Avenue de l&#x02019;Europe, Clapiers, F-34830 France </aff></contrib-group><pub-date pub-type="epub"><day>9</day><month>11</month><year>2015</year></pub-date><pub-date pub-type="pmc-release"><day>9</day><month>11</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>16</volume><elocation-id>374</elocation-id><history><date date-type="received"><day>14</day><month>5</month><year>2015</year></date><date date-type="accepted"><day>24</day><month>10</month><year>2015</year></date></history><permissions><copyright-statement>&#x000a9; Monat et al.; licensee BioMed Central. 2015</copyright-statement><license license-type="open-access"><license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p>The explosion of NGS (Next Generation Sequencing) sequence data requires a huge effort in Bioinformatics methods and analyses. The creation of dedicated, robust and reliable pipelines able to handle dozens of samples from raw <italic>FASTQ</italic> data to relevant biological data is a time-consuming task in all projects relying on NGS. To address this, we created a generic and modular toolbox for developing such pipelines.</p></sec><sec><title>Results</title><p>TOGGLE (<italic>TOolbox for Generic nGs anaLysEs</italic>) is a suite of tools able to design pipelines that manage large sets of NGS softwares and utilities. Moreover, TOGGLE offers an easy way to manipulate the various options of the different softwares through the pipelines in using a single basic configuration file, which can be changed for each assay without having to change the code itself. We also describe one implementation of TOGGLE in a complete analysis pipeline designed for SNP discovery for large sets of genomic data, ready to use in different environments (from a single machine to HPC clusters).</p></sec><sec><title>Conclusion</title><p>TOGGLE speeds up the creation of robust pipelines with reliable log tracking and data flow, for a large range of analyses. Moreover, it enables Biologists to concentrate on the biological relevance of results, and change the experimental conditions easily. The whole code and test data are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/SouthGreenPlatform/TOGGLE">https://github.com/SouthGreenPlatform/TOGGLE</ext-link>.</p></sec><sec><title>Electronic supplementary material</title><p>The online version of this article (doi:10.1186/s12859-015-0795-6) contains supplementary material, which is available to authorized users.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>NGS</kwd><kwd>Toolbox</kwd><kwd>Pipeline</kwd><kwd>Flexible</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2015</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background</title><p>Since the appearance of Next Generation Sequencing (NGS) technologies, a large number of bioinformatics softwares and methods have been developed and publicly released to work with these massive sequence data [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Depending on the type of data and experiments, multiple steps may be required such as quality control, adapter removal or trimming or both, mapping, variant detection, read counting and so on, and dedicated software may be used for each step. Thus, biologists have to perform a lot of chained manipulations in order to obtain the final information for their research. The vast majority of bioinformatics softwares are command-lines tools, generally designed to work on powerful computers and High-Performance Calculation (HPC) infrastructures. Bioinformaticians have developed dedicated pipelines for specific experiments, using those bioinformatics softwares, as well as combinations of home-made filters (using conditional <italic>if</italic>) and loops (using the classical <italic>while</italic>) [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR4">4</xref>]. However, those scripts are generally monolithic, in the sense that they cannot easily be transferred from one installation to another, or from one experimental subject to the following (different species, different conditions, etc.). Moreover, even if some flexibility is offered to the user by modification of several options before launching, these modifications are generally not trivial, requiring either a long list in the command line, or provision of a complex option file. In addition, writing a new pipeline <italic>from scratch</italic> is labor-intensive and time-consuming, especially if all safeguards for file format, software execution, or file transfer are implemented each time.</p><p>The TOGGLE suite (for <italic>TOolbox for Generic nGs anaLysEs</italic>) was developed to optimize the creation of new NGS analysis workflows. What we propose here is a set of packages designed for fast implementation of robust and reliable pipelines. Each package represents either a NGS software manipulation or a set of dedicated tools (see Table <xref rid="Tab1" ref-type="table">1</xref>). These packages are written in <italic>Perl</italic>, with unitary modules the most generic possible. TOGGLE is able to manage hundreds of samples at once, and is not limited to one application. It can be used on DNAseq, RNA-Seq, smallRNA, GBS, and any other sequence data. It can be installed on a variety of infrastructure, from a simple laptop computer to a large HPC cluster. Finally, the TOGGLE assays and options are based on a unique configuration file, that can be easily changed and adapted to each run. The tool and test data are available on GitHub: <ext-link ext-link-type="uri" xlink:href="https://github.com/SouthGreenPlatform/TOGGLE">https://github.com/SouthGreenPlatform/TOGGLE</ext-link>. A <italic>Docker</italic> image for immediate installation is available (<ext-link ext-link-type="uri" xlink:href="http://bioinfo-web.mpl.ird.fr/toggle/toggle.tgz">http://bioinfo-web.mpl.ird.fr/toggle/toggle.tgz</ext-link>), as well as an user-space install script (<ext-link ext-link-type="uri" xlink:href="http://bioinfo-web.mpl.ird.fr/toggle/installTOGGLE.sh">http://bioinfo-web.mpl.ird.fr/toggle/installTOGGLE.sh</ext-link>).
<table-wrap id="Tab1"><label>Table 1</label><caption><p>List of the different packages and main modules. If any other modules exist but are not presented here, multiple dots are shown</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Packages (nb of modules)</th><th align="left">Modules</th><th align="left">Functions</th></tr></thead><tbody><tr><td align="left">bwa (5)</td><td align="left">bwaIndex</td><td align="left">Indexing the reference Fasta file</td></tr><tr><td align="left"/><td align="left">bwaAln</td><td align="left">Create the alignment for <italic>FASTQ</italic> sequences</td></tr><tr><td align="left"/><td align="left">bwaSampe</td><td align="left">Create the <italic>SAM</italic> file for pair-end sequences</td></tr><tr><td align="left"/><td align="left">bwaSamse</td><td align="left">Create the <italic>SAM</italic> file for single-end sequences</td></tr><tr><td align="left"/><td align="left">...</td><td align="left">...</td></tr><tr><td align="left">cutadapt (2)</td><td align="left">CreateConfFile</td><td align="left">Create the specific <italic>cutadapt</italic> configuration file</td></tr><tr><td align="left"/><td align="left">execution</td><td align="left">Execute <italic>cutadapt</italic> command</td></tr><tr><td align="left">fastqc (6)</td><td align="left">execution</td><td align="left">Run <italic>FastQC</italic> software</td></tr><tr><td align="left"/><td align="left">parse</td><td align="left">Parse the <italic>FastQC</italic> results</td></tr><tr><td align="left"/><td align="left">...</td><td align="left">...</td></tr><tr><td align="left">gatk (8)</td><td align="left">gatkVariantFiltrator</td><td align="left">Filter the different SNP based on specific options</td></tr><tr><td align="left"/><td align="left">gatkHaplotypeCaller</td><td align="left">Call the haplotype of each individual based on a <italic>BAM</italic> file</td></tr><tr><td align="left"/><td align="left">...</td><td align="left">...</td></tr><tr><td align="left">pairing (4)</td><td align="left">pairRecognition</td><td align="left">Allow the recognition of pairs in a set of <italic>FASTQ</italic> files</td></tr><tr><td align="left"/><td align="left">repairing</td><td align="left">Reorganize in pair two <italic>FASTQ</italic> files, extract single sequences</td></tr><tr><td align="left">picardTools (3)</td><td align="left">picardToolsMarkDuplicates</td><td align="left">Mark/eliminate different types of duplicate in a <italic>BAM</italic> file</td></tr><tr><td align="left"/><td align="left">picardToolsCreateSequenceDictionnary</td><td align="left">Create the &#x0201c;.dict&#x0201d; file of the reference</td></tr><tr><td align="left"/><td align="left">picardToolsSortSam</td><td align="left">Sort the <italic>SAM</italic> file</td></tr><tr><td align="left"/><td align="left">...</td><td align="left">...</td></tr><tr><td align="left">samTools (10)</td><td align="left">samToolsSort</td><td align="left">Sort the <italic>SAM</italic>/<italic>BAM</italic> file</td></tr><tr><td align="left"/><td align="left">samToolsIndex</td><td align="left">Index the <italic>SAM</italic>/<italic>BAM</italic> file</td></tr><tr><td align="left"/><td align="left">mergeHeader</td><td align="left">Merge the header of multiples <italic>SAM</italic>/<italic>BAM</italic> into a single one</td></tr><tr><td align="left"/><td align="left">...</td><td align="left">...</td></tr><tr><td align="left">toolbox (73)</td><td align="left">exportLog</td><td align="left">Export information into log files</td></tr><tr><td align="left"/><td align="left">checkFile</td><td align="left">Check if a file exists, is readable/writable, and is not empty</td></tr><tr><td align="left"/><td align="left">existsDir</td><td align="left">Check if a directory exists</td></tr><tr><td align="left"/><td align="left">makeDir</td><td align="left">Create a new directory</td></tr><tr><td align="left"/><td align="left">readDir</td><td align="left">Read the content of a directory</td></tr><tr><td align="left"/><td align="left">extractPath</td><td align="left">Extract the complete path of a file</td></tr><tr><td align="left"/><td align="left">extractName</td><td align="left">Create a readgroup from a file name</td></tr><tr><td align="left"/><td align="left">readFileConf</td><td align="left">Read the configuration file and return a hash</td></tr><tr><td align="left"/><td align="left">extractOptions</td><td align="left">Provide the options for a given software from the hash</td></tr><tr><td align="left"/><td align="left">run</td><td align="left">Run the command line given in argument</td></tr><tr><td align="left"/><td align="left">checkSamOrBamFormat</td><td align="left">Check if a file is a true <italic>SAM</italic>/<italic>BAM</italic> format</td></tr><tr><td align="left"/><td align="left">extractHashSoft</td><td align="left">Extract specific options for a given tool</td></tr><tr><td align="left"/><td align="left">checkNumberByWC</td><td align="left">Provide the number of sequence in a given <italic>FASTQ</italic> file</td></tr><tr><td align="left"/><td align="left">checkEncodeByASCIIcontrol</td><td align="left">Check the format of encoding in a <italic>FASTQ</italic> file</td></tr><tr><td align="left"/><td align="left">changeEncode</td><td align="left">Provide a wrapper to change the encoding of a <italic>FASTQ</italic> file</td></tr><tr><td align="left"/><td align="left">...</td><td align="left">...</td></tr></tbody></table></table-wrap></p></sec><sec id="Sec2"><title>Implementation/results and discussion</title><sec id="Sec3"><title>Packages and modules</title><p>We designed TOGGLE in a suite of more than 10 packages, gathering more than 60 different modules (functions or calling), which can be used independantly to quickly implement pipelines for NGS analyses. Each package represents either the use of a software suite (such as <italic>bwa</italic> [<xref ref-type="bibr" rid="CR5">5</xref>] or <italic>Genome Analysis ToolKit GATK</italic> [<xref ref-type="bibr" rid="CR6">6</xref>]), or a set of tools dedicated to a given operation or more general tools. Modules are <italic>Perl</italic> code wrappers for a central command or function, with a validation system for the entry file format, running command, and output (if any). Each module starts generally by calling the file format validation modules from the <italic>toolbox.pm</italic> package (for <italic>FASTQ</italic>, <italic>SAM</italic> and others), and then by sending a specific command line to the <italic>toolbox::run</italic> module. This module launches the command through the UNIX system, and will return either a given value for correct execution, a warning, or an error.</p><p>The <italic>toolbox.pm</italic> package gathers general tools and functionalities. This package will, among other things, read the <italic>software.config.txt</italic> file, manage printing of log files printing (see below) and the system command for all modules (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). The <italic>software.config.txt</italic> file can be used to manage the options for the different softwares and modules of TOGGLE. This file is constructed in a basic layout, as shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>, using the option representation specific for each software. If no specific parameters for a given software or module are provided in this file, the default values of the software/module will be used. The <italic>software.config.txt</italic> file (see Fig. <xref rid="Fig2" ref-type="fig">2</xref>) was developed with Biologist users in mind: this file is the only one to change for any option of any step of a given pipeline. The <italic>localConfig.pm</italic> package will inform of the different softwares paths (for <italic>bwa</italic> e.g.) on the user&#x02019;s local machine or server. Users can adapt the paths in this package, and can also test different versions or installations of the same software without having to change the whole pipeline code. Only those three packages/files are mandatory when creating a new script using TOGGLE.
<fig id="Fig1"><label>Fig. 1</label><caption><p>Software execution presentation. (1) Input data are submitted to a given Module. (2) The Module will construct a command line to <italic>toolbox::run</italic>. (3) The text of the command line and the run report are sent to <italic>toolbox::exportLog</italic>. (4) The output of the command (ok, error or warning) is sent back to the original Module. (5) The Module will send a report to <italic>toolbox::exportLog</italic>. (6) The output data are delivered from the Module</p></caption><graphic xlink:href="12859_2015_795_Fig1_HTML" id="MO1"/></fig><fig id="Fig2"><label>Fig. 2</label><caption><p>Softwares configuration file. The lines starting with &#x0201c;$&#x0201d; correspond to the name of the current module called (e.g. <italic>bwa aln</italic>). The lines just after list the option(s) associated with this call; the list of options is finished with an empty line. Lines starting with &#x0201c; <italic>&#x0266f;</italic>&#x0201d; are reserved for comments</p></caption><graphic xlink:href="12859_2015_795_Fig2_HTML" id="MO2"/></fig></p><p>A large part of the coding effort was to produce a logging system that can be scaled for hundreds of individual analyses run in parallel (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). The dedicated <italic>toolbox::exportLog</italic> module will recover the value transmitted by other modules to generate log information: (<italic>i</italic>) the module call succeeded; (<italic>ii</italic>) the module call started correctly but finished incorrectly; (<italic>iii</italic>) the module was not able to execute the command. The last two types of information will be recovered in the error log file (&#x0201c;.e&#x0201d;). Correct execution of the command will be written to the output log file (&#x0201c;.o&#x0201d;). The log system allows the user to check step by step the progess of the analysis.
<fig id="Fig3"><label>Fig. 3</label><caption><p>Directories tree structure. Representation of the tree of directories with the log files during the execution of <italic>globalAnalysis.pl</italic> pipeline, with the example of three individuals representing each possibility. The first one is a paired-end data, the second one is a single-end data, and the last one is a paired-end data which generate single reads during the cleaning step</p></caption><graphic xlink:href="12859_2015_795_Fig3_HTML" id="MO3"/></fig></p><p>Adding new modules or packages is relatively simple, with a sample package provided with the complete suite. Linking to the different tools (running and logging system), as well as the replacement of a given module by another in a pipeline is easy to perform. A template for a new pipeline design is also provided.</p></sec><sec id="Sec4"><title>Example of implementation</title><p>All the modules can be arranged to easily generate robust pipelines for NGS analyses. As an example, we provide two functional pipelines: an RNAseq data one (not detailed here) and a DNAseq pipeline for single and paired-end <italic>Illumina</italic> genomic data for SNP and InDel detection in any eukaryotic diploid species. This latter, that we describe here in details, is based on four scripts: <italic>pairAnalysis.pl</italic>, <italic>singleAnalysis.pl</italic>, <italic>mergeAnalysis.pl</italic> and <italic>globalAnalysis.pl</italic> (Fig. <xref rid="Fig4" ref-type="fig">4</xref>). The first three can be launched independently, while the last, <italic>globalAnalysis.pl</italic>, is a turn-key pipeline which launches and manages the three others (see Additional file <xref rid="MOESM1" ref-type="media">1</xref>).
<fig id="Fig4"><label>Fig. 4</label><caption><p>Pipeline DNAseq presentation. Basic overview of the <italic>pairAnalysis.pl</italic>, <italic>singleAnalysis.pl</italic>, <italic>mergeAnalysis.pl</italic> pipelines, and of the wrapping <italic>globalAnalysis.pl</italic> pipeline. Each colored box represents a given module, and each color a specific package. See text for the corresponding steps. A more complete figure is available on the TOGGLE website</p></caption><graphic xlink:href="12859_2015_795_Fig4_HTML" id="MO4"/></fig></p><p>Both start with <italic>FASTQ</italic> format validation (purple boxes in Fig. <xref rid="Fig4" ref-type="fig">4</xref>), followed by a quality control using the <italic>FastQC</italic> software (yellow boxes in Fig. <xref rid="Fig4" ref-type="fig">4</xref>) [<xref ref-type="bibr" rid="CR7">7</xref>], and a cleaning step performed by the <italic>CutAdapt</italic> software [<xref ref-type="bibr" rid="CR8">8</xref>] (sand boxes). For <italic>pairAnalysis.pl</italic>, an additional &#x0201c;repairing&#x0201d; stage (red boxes in Fig. <xref rid="Fig4" ref-type="fig">4</xref>) re-associates the paired-end reads and exports the single-end reads (which may be produced by the cleaning step) to the <italic>singleAnalysis.pl</italic> script independently from <italic>CutAdapt</italic>. This step may be excluded when using the last version of <italic>CutAdapt</italic> and its pair-end mode, but this is not yet implemented in TOGGLE. After cleaning, both scripts follow the same stages again, with specific parameters: mapping using <italic>bwa aln</italic> (blue boxes; <italic>bwa MEM</italic> module is also available) [<xref ref-type="bibr" rid="CR5">5</xref>]; sorting, cleaning and indexing of the <italic>BAM</italic> files using <italic>PicardTools</italic> [<xref ref-type="bibr" rid="CR9">9</xref>] and <italic>SAMtools</italic> [<xref ref-type="bibr" rid="CR10">10</xref>] (brown and green boxes, respectively); local realignment with the <italic>GATK</italic> (orange boxes) [<xref ref-type="bibr" rid="CR6">6</xref>]; and finally removal of duplicates using <italic>PicardTools</italic> (brown boxes). The mapping is performed here using the <italic>bwa aln/sampe/samse</italic> back-track version. It is possible to switch to the <italic>bwa mem</italic> version by changing the code, as this module is already provided in the <italic>bwa.pm</italic> package. However, we decided to remain on the back-track version in this pipeline, as it is used in our labs and allows comparison with older mapping data. The data are then treated through the third script <italic>mergeAnalysis.pl</italic>, for Single Nucleotide Polymorphism (SNP) and Insertion/Deletions (InDels) calling using <italic>HaplotypeCaller</italic>, followed by the sorting and quality filtering of the obtained variants. All of these steps are performed using <italic>GATK</italic>, and are multiple sample variant calling. The final Variant Call Format (<italic>VCF</italic>) file is cleaned and filtered as much as possible through generic Bioinformatics tools, but subsequent specific analyses may be required to optimize it for specific purposes (e.g. SNP identification for CHiP creation, population genetics or breeding).</p><p>In order to automate these steps for multiple samples, we created the <italic>globalAnalysis.pl</italic> script (in currently two versions: one linear and the second one parallelized for <italic>SGE</italic> type architecture). This script will also organize the data into different directories with a specific tree structure (Fig. <xref rid="Fig3" ref-type="fig">3</xref>) defined to facilitate access to intermediate files.</p><p>The <italic>globalAnalysis.pl</italic> script will deal with a unique directory where the whole raw <italic>FASTQ</italic> data are stored, without correspondance of names between the two paired files (the forward can be named <italic>Ulysse</italic> and the reverse <italic>Enterprise</italic>). The script will use the <italic>pairing::pairRecognition.pm</italic> module (red boxes in Fig. <xref rid="Fig4" ref-type="fig">4</xref>) to associate files of paired-end data. The first sequence ID (specific for each run) is used to create the pairs, and we validated this association step of more than 150 paired and single files. It creates independent folders for each sample/individual, on which <italic>pairAnalysis.pl</italic> or <italic>singleAnalysis.pl</italic> will be launched according to the data type. After these analyses, <italic>globalAnalysis.pl</italic> will recover the final <italic>BAM</italic> file and its index for each sample, and will execute the <italic>mergeAnalysis.pl</italic> script as described earlier (see Fig. <xref rid="Fig4" ref-type="fig">4</xref>).</p><p>All those scripts are associated with an indicator file, <italic>individuSoft.txt</italic>, which inform which step of the analysis has been launched. This indicator file also permits to create the various logs files. Indeed we constructed different level of log files: at global level (GLOBAL_ANALYSIS_date on Fig. <xref rid="Fig3" ref-type="fig">3</xref>); at sample/individuals level (indX_global_log on Fig. <xref rid="Fig3" ref-type="fig">3</xref>), and at package per individual level (indX_package_log on Fig. <xref rid="Fig3" ref-type="fig">3</xref>).</p><p>This pipeline is a classical one for DNAseq analyses from <italic>FASTQ</italic> sequences to <italic>BAM</italic> files then <italic>VCF</italic> files, but with a lot of control regarding file structure and format, and is easy to manage in terms of specific and global options through the <italic>software.config.txt</italic> file. Moreover, it can be used with any reference genome (provided as a <italic>FASTA</italic> file). A RNAseq pipeline is also provided in the TOGGLE suite, based on a <italic>TopHat</italic> and <italic>HTSeq</italic> [<xref ref-type="bibr" rid="CR11">11</xref>] approach (see Additional file <xref rid="MOESM1" ref-type="media">1</xref>).</p></sec><sec id="Sec5"><title>Parallelization</title><p>TOGGLE can manage parallelized jobs, and may be implemented on HPC cluster machines. Concurrent jobs can be launched using the <italic>globalAnalysisSGE.pl</italic> script for example, which will launch all individual <italic>pairAnalysis.pl</italic> (or <italic>singleAnalysis.pl</italic>) instances in different jobs. The specific SGE parameters for all individual jobs can be specified in the option file. For the moment, the main level of the paralellization is based on the sample level (each individual) only. We are conscious this is a main drawback compared to system such as <italic>HugeSeq</italic> [<xref ref-type="bibr" rid="CR4">4</xref>] or <italic>Churchill</italic> [<xref ref-type="bibr" rid="CR3">3</xref>] (see below). However, TOGGLE was designed to requested a very limited number of mandatory softwares/configuration outside of bioinformatics one. Thus it could be deployed on any kind of infrastructure. Nevertheless, in future versions we plan to develop a finer approach using a <italic>MapReduce</italic>/embarrassingly parallel approach, splitting each sample in multiples subsamples at the different levels (<italic>FASTQ</italic>, <italic>SAM/BAM</italic>, <italic>VCF</italic>), in a similar way to <italic>Churchill</italic> [<xref ref-type="bibr" rid="CR3">3</xref>].</p><p>Still, the current scripts do not manage the parallelization based on specific options. If a given parameter in the option file specifies a certain number of parallel threads (e.g. <italic>bwa aln &#x0201c;-t&#x0201d; option</italic>), and if the SGE options provided do not require the same number of cores, more than one thread per core will be launched, which could have a major impact on the general efficiency of the job (up to server crash) if too much threads per core are requested.</p></sec><sec id="Sec6"><title>Comparison with already available pipeline tools</title><p>Different pipelines or pipeline development tools exist for NGS data. The graphical systems (such as <italic>Galaxy</italic> [<xref ref-type="bibr" rid="CR12">12</xref>], <italic>Taverna</italic> [<xref ref-type="bibr" rid="CR13">13</xref>], <italic>Tavaxy</italic> [<xref ref-type="bibr" rid="CR14">14</xref>]) are limited in their options or the available tools, and are generally not able to reach the scale of thousands of samples. The command-line based systems are more versatile (see Table <xref rid="Tab2" ref-type="table">2</xref>), but harder to use.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Comparison with the different pipelining systems available</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Function</th><th align="left">TOGGLE</th><th align="left">
<italic>GATK-Queue</italic>
</th><th align="left">
<italic>HugeSeq</italic>
</th><th align="left">
<italic>Churchill</italic>
</th><th align="left">
<italic>GotCloud</italic>
</th><th align="left">
<italic>bcbio-nextgen</italic>
</th></tr></thead><tbody><tr><td align="left">Raw FASTQ Data</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y<sup>a</sup>
</td></tr><tr><td align="left">Reference indexing</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y<sup>a</sup>
</td></tr><tr><td align="left">FASTQ to final Data</td><td align="left">Y</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td></tr><tr><td align="left">Multiple Samples Calling</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td></tr><tr><td align="left">Modularity</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td></tr><tr><td align="left">Between Sample Paralellization</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td></tr><tr><td align="left">Within Sample Parallelization</td><td align="left">Y/N<sup>b</sup>
</td><td align="left">Y<sup>b</sup>
</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td></tr><tr><td align="left">Structural Variant Analysis</td><td align="left">N</td><td align="left">N</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td></tr><tr><td align="left">Annotation</td><td align="left">Y<sup>a</sup>
</td><td align="left">Y</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td></tr><tr><td align="left">Scalability</td><td align="left">Y</td><td align="left">Y</td><td align="left">N</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td></tr><tr><td align="left">Evolutivity</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td><td align="left">Y</td></tr></tbody></table><table-wrap-foot><p>
<italic>Y</italic> signals that a feature is present, <italic>N</italic> is absent. <italic>Evolutivity</italic> means the possibility to add future module or functions to the system</p><p>
<sup>a</sup>Available as separated steps</p><p>
<sup>b</sup>Depending the considered step</p></table-wrap-foot></table-wrap></p><p><italic>GATK-Queue</italic> [<xref ref-type="bibr" rid="CR6">6</xref>] is a scripting framework for the <italic>Genome Analysis ToolKit</italic>, which treats <italic>SAM/BAM</italic> or <italic>VCF</italic> files using <italic>GATK</italic> tools. <italic>GATK-Queue</italic> is based on the <italic>Scala</italic> language, and can create simple scripts. However, it is limited to <italic>GATK</italic> tools and will start only after mapping.</p><p>The <italic>HugeSeq</italic> pipeline [<xref ref-type="bibr" rid="CR4">4</xref>] uses a <italic>MapReduce</italic>-like approach on HPC clusters to optimize the calculation of genomic variants from a set of a few already cleaned <italic>FASTQ</italic> data. The scripts are fixed, and parameters can be changed only in hard code modifications or through an extensive and complex command-line. Moreover, a lot of external commands have to be performed before analyses (e.g. creation of reference index and dictionary).</p><p><italic>Churchill</italic> [<xref ref-type="bibr" rid="CR3">3</xref>] also uses an embarassingly parallel approach in order to achieve <italic>MapReduce</italic> performance. It is dedicated mainly to identification of genomic variants, and scripts are hard coded and can not be modified. It is possible to switch between different mappers and variant callers using a dedicated option file. However, the index and dictionaries for the references have to be created independently, and pair recognition is based only on file names. The whole path for all <italic>FASTQ</italic> files must be provided, and not all options are available for all softwares. Finally, <italic>Churchill</italic> is freely available for academic purposes, as the other ones, but is not open-source.</p><p><italic>GotCloud</italic> [<xref ref-type="bibr" rid="CR15">15</xref>] is a set of pipelines dedicated to massive NGS analyses, from already cleaned sequence data to association results. It is dedicated to detection of genomics variations, and can switch between mappers or callers. The options system is also based on a single file, but requires that the user knows the <italic>GotCloud</italic> version for each software option. Moreover, it runs only on clusters or in the Cloud (an Amazon EC2 instance is possible), and the name of all <italic>FASTQ</italic> files has to be provided.</p><p>The <italic>bcbio-nextgen</italic> framework [<xref ref-type="bibr" rid="CR16">16</xref>], written in <italic>Python</italic>, is highly modular, and is similar to TOGGLE. Different mappers and callers are already available, and others can be add easily. The framework can be used for germline variants, somatic variants and RNA-Seq, as for TOGGLE. However, the reference sequences are limitated to a fixed set, and even if it is possible to add new items, the system requests those references to be listed.</p><p>Compared to the similar frameworks currently available, the current implementations of TOGGLE scripts work on DNA and RNA, and begin with a set of raw <italic>FASTQ</italic> in a given folder. It will automate all steps, from identification of pairs (if any), creation of indexes and dictionaries for the reference, data cleaning and so on. The end-users only have to modify the basic option file <italic>software.config.txt</italic>, in which the very same options as for the command line softwares need to be written. TOGGLE can be extended easily for new bricks and software plugins, and new scripts for dedicated analyses can be assembled quickly. Moreover, TOGGLE can be installed in the user space (without admin rights) as well as at the system level, from a simple laptop to a HPC cluster or in the Cloud.</p></sec><sec id="Sec7"><title>Installation</title><p>Power users can install TOGGLE following the manual provided on GitHub <ext-link ext-link-type="uri" xlink:href="https://github.com/SouthGreenPlatform/TOGGLE">https://github.com/SouthGreenPlatform/TOGGLE</ext-link>. We are aware that installing all dependencies and working versions of a such large number of softwares is generally problematic and complex. Therefore, we provide alternative methods for installation, a <italic>Docker</italic> image (available at <ext-link ext-link-type="uri" xlink:href="http://bioinfo-web.mpl.ird.fr/toggle/toggle.tgz">http://bioinfo-web.mpl.ird.fr/toggle/toggle.tgz</ext-link>) and a <italic>bash</italic> script (available on the GitHub and at <ext-link ext-link-type="uri" xlink:href="http://bioinfo-web.mpl.ird.fr/toggle/TOGGLEinstall.sh">http://bioinfo-web.mpl.ird.fr/toggle/TOGGLEinstall.sh</ext-link>). The <italic>Docker</italic> image, based on the basic Ubuntu 14.04 image from <italic>Docker</italic> Hub, is ready to run <italic>Out of the box</italic> any NGS data transferred in the container. The <italic>bash</italic> script can be run at user space level and will download all the versions that work with the current version of TOGGLE, and will adapt the different paths for TOGGLE to work. Nevertheless, for an optimized and stable installation, we recommend a more precise installation as detailed on GitHub.</p></sec></sec><sec id="Sec8"><title>Conclusion</title><p>TOGGLE is a combination of tools for large-scale NGS analyses of DNA and RNAseq data. Users can easily modify the different options of the numerous softwares using the <italic>software.config.txt</italic> file, without going through the code for each step. Users who want to use the general scripts provided in the suite just have to launch the <italic>globalAnalysis.pl</italic> pipeline on the raw <italic>FASTQ</italic> files (in a single folder) and wait to get the <italic>BAM</italic> and <italic>VCF</italic> files. The efficient log files provide information and statistics on the data and pipeline progress quickly, as well as on potential errors or warnings. Thus, users can concentrate on the biological relevance of the results rather than on technical aspects, even if using a huge amount of data.</p><p>Bioinformaticians can rapidly write new packages and modules useful for Biologists using a highly reliable system. The addition of new modules is fast, and they can be easily linked to the logging system. A lot of tools are available already, and we will add new modules for structural variant analyses, with softwares such as <italic>NovelSeq</italic> [<xref ref-type="bibr" rid="CR17">17</xref>] or <italic>BreakDancer</italic> [<xref ref-type="bibr" rid="CR18">18</xref>] in the near future.</p></sec><sec id="Sec9"><title>Availability and requirement</title><p><list list-type="bullet"><list-item><p><bold>Project name:</bold> TOGGLE</p></list-item><list-item><p><bold>Project home page:</bold><ext-link ext-link-type="uri" xlink:href="https://github.com/SouthGreenPlatform/TOGGLE">https://github.com/SouthGreenPlatform/TOGGLE</ext-link></p></list-item><list-item><p><bold>Operating system:</bold> Linux</p></list-item><list-item><p><bold>Programming Language:</bold><italic>Perl</italic></p></list-item><list-item><p><bold>Other requirements:</bold><italic>Java</italic> 1.7, <italic>bwa</italic> 0.7.2 or higher, <italic>SAMtools</italic> 0.1.18 or higher, <italic>CutAdapt</italic> 1.2.1 or higher, <italic>FastqC</italic> 0.11.1 or higher, <italic>PicardTools</italic> 1.124 or higher, GATK 3.3x or higher, <italic>Perl</italic> modules: <italic>Data::Dumper</italic>, <italic>Data::Translate</italic>, <italic>Test:More</italic>, <italic>Test::Deep</italic>, <italic>Capture::Tiny</italic>.</p></list-item><list-item><p><bold>License:</bold> GNU GPLv3/CeCill-C</p></list-item></list></p></sec></body><back><app-group><app id="App1"><sec id="Sec10"><title>Additional file</title><p><media position="anchor" xlink:href="12859_2015_795_MOESM1_ESM.pdf" id="MOESM1"><label>Additional file 1</label><caption><p>
<bold>Complete scheme of the</bold>
<bold><italic>globalAnalysis.pl</italic></bold>
<bold> script.</bold> Colored boxes correspond to analysis steps, with color related to a given package (see text for more information). White and black boxes correspond to input/output files. The <italic>globalAnalysis.pl</italic> script will determine the state of each sample (single or pair), then launch the corresponding subscript, and finally will gather all corrected BAM files to the <italic>mergeAnalysis.pl</italic> script that will perform the multiple sample calling. (PDF 60 kb)</p></caption></media></p></sec></app></app-group><fn-group><fn><p><bold>Competing interests</bold></p><p>The authors declare that they have no competing interests.</p></fn><fn><p><bold>Authors&#x02019; contributions</bold></p><p>CM: blueprint, code of modules and packages, code of pipelines, coordination, writing of the manuscript. CTD: blueprint, code of modules and packages, code of pipelines, correction of the manuscript. AK: code of modules and packages, code of pipelines. MS: code of modules and packages. CF: code of modules and packages. MA: code of modules and packages. JOB: code of modules and packages. SR: code of modules and packages. SA: code of modules and packages, code of RNAseq pipeline. EOA: code of modules and packages, installation scripts. FS: initiator of the program, code of modules and packages, <italic>Docker</italic> image, coordination, correction of the manuscript. All authors read and approved the final manuscript.</p></fn></fn-group><ack><title>Acknowledgements</title><p>Authors want to thank Ndomassi Tando for his great help for various software installations, the different <italic>&#x003b2;</italic>-testers that perform the first true data tests, the other members of the SouthGreen platform (<ext-link ext-link-type="uri" xlink:href="http://www.southgreen.fr/">http://www.southgreen.fr/</ext-link>) for their help, and Dr Tomas Harrop for his input in manuscript correction. We would like also to greatly thanks our reviewers for their very helpful comments in improving the mansucript. CM was supported by a grant from the French National Research Agency ANR (AfriCrop project <italic>&#x0266f;</italic> ANR-13-BSV7-0017). AK was supported by a grant from the Agropolis Fondation (This project is supported by AgropolisFondationunder the reference ID 1403-026 through the &#x0226a; Investissementsd&#x02019;avenir &#x0226b; programme(LabexAgro:ANR-10-LABX-0001-01)). MA was supported by a &#x0201c;FloriPalm&#x0201d; Specific Research Agreement between CIRAD and a FASSB and &#x0201c;PalMarkers&#x0201d; research contract between CIRAD and PalmElit SAS. SA was supported by the &#x0201c;PalMarkers&#x0201d; research contract between CIRAD and PalmElit SAS.</p></ack><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bao</surname><given-names>S</given-names></name><name><surname>Jiang</surname><given-names>R</given-names></name><name><surname>Kwan</surname><given-names>W</given-names></name><name><surname>Wang</surname><given-names>B</given-names></name><name><surname>Ma</surname><given-names>X</given-names></name><name><surname>Song</surname><given-names>Y</given-names></name></person-group><article-title>Evaluation of next-generation sequencing software in mapping and assembly</article-title><source>J Hum Genet</source><year>2011</year><volume>56</volume><fpage>406</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1038/jhg.2011.43</pub-id><?supplied-pmid 21525877?><pub-id pub-id-type="pmid">21525877</pub-id></element-citation></ref><ref id="CR2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pabinger</surname><given-names>S</given-names></name><name><surname>Dander</surname><given-names>A</given-names></name><name><surname>Fischer</surname><given-names>M</given-names></name><name><surname>Snajder</surname><given-names>R</given-names></name><name><surname>Sperk</surname><given-names>M</given-names></name><name><surname>Efremova</surname><given-names>M</given-names></name><etal/></person-group><article-title>A survey of tools for variant analysis of next-generation genome sequencing data</article-title><source>Brief Bioinform</source><year>2014</year><volume>15</volume><issue>2</issue><fpage>256</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1093/bib/bbs086</pub-id><?supplied-pmid 23341494?><pub-id pub-id-type="pmid">23341494</pub-id></element-citation></ref><ref id="CR3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kelly</surname><given-names>BJ</given-names></name><name><surname>Fitch</surname><given-names>JR</given-names></name><name><surname>Hu</surname><given-names>Y</given-names></name><name><surname>Corsmeier</surname><given-names>DJ</given-names></name><name><surname>Zhong</surname><given-names>H</given-names></name><name><surname>Wetzel</surname><given-names>AN</given-names></name><etal/></person-group><article-title>Churchill: an ultra-fast, deterministic, highly scalable and balanced parallelization strategy for the discovery of human genetic variation in clinical and population-scale genomics</article-title><source>Genome Biol</source><year>2015</year><volume>16</volume><issue>1</issue><fpage>6</fpage><pub-id pub-id-type="doi">10.1186/s13059-014-0577-x</pub-id><?supplied-pmid 25600152?><pub-id pub-id-type="pmid">25600152</pub-id></element-citation></ref><ref id="CR4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lam</surname><given-names>HYK</given-names></name><name><surname>Pan</surname><given-names>C</given-names></name><name><surname>Clark</surname><given-names>MJ</given-names></name><name><surname>Lacroute</surname><given-names>P</given-names></name><name><surname>Chen</surname><given-names>R</given-names></name><name><surname>Haraksingh</surname><given-names>R</given-names></name><etal/></person-group><article-title>Detecting and annotating genetic variations using the HugeSeq pipeline</article-title><source>Nat Biotechnol</source><year>2012</year><volume>30</volume><issue>3</issue><fpage>226</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1038/nbt.2134</pub-id><?supplied-pmid 22398614?><pub-id pub-id-type="pmid">22398614</pub-id></element-citation></ref><ref id="CR5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Durbin</surname><given-names>R</given-names></name></person-group><article-title>Fast and accurate short read alignment with burrows-wheeler transform</article-title><source>Bioinformatics</source><year>2009</year><volume>25</volume><fpage>1754</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btp324</pub-id><?supplied-pmid 19451168?><pub-id pub-id-type="pmid">19451168</pub-id></element-citation></ref><ref id="CR6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKenna</surname><given-names>A</given-names></name><name><surname>Hanna</surname><given-names>M</given-names></name><name><surname>Banks</surname><given-names>E</given-names></name><name><surname>Sivachenko</surname><given-names>A</given-names></name><name><surname>Cibulskis</surname><given-names>K</given-names></name><name><surname>Kernytsky</surname><given-names>A</given-names></name><etal/></person-group><article-title>The genome analysis toolkit: a mapreduce framework for analyzing next-generation dna sequencing data</article-title><source>Genome Res</source><year>2010</year><volume>20</volume><fpage>1297</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1101/gr.107524.110</pub-id><?supplied-pmid 20644199?><pub-id pub-id-type="pmid">20644199</pub-id></element-citation></ref><ref id="CR7"><label>7</label><mixed-citation publication-type="other">FASTQC. <ext-link ext-link-type="uri" xlink:href="http://www.bioinformatics.babraham.ac.uk/projects/fastqc/">http://www.bioinformatics.babraham.ac.uk/projects/fastqc/</ext-link>.</mixed-citation></ref><ref id="CR8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>M</given-names></name></person-group><article-title>Cutadapt removes adapter sequences from high-throughput sequencing reads</article-title><source>EMBnet J</source><year>2011</year><volume>17</volume><fpage>10</fpage><lpage>2</lpage><pub-id pub-id-type="doi">10.14806/ej.17.1.200</pub-id></element-citation></ref><ref id="CR9"><label>9</label><mixed-citation publication-type="other">PicardTools. <ext-link ext-link-type="uri" xlink:href="http://broadinstitute.github.io/picard/index.html">http://broadinstitute.github.io/picard/index.html</ext-link>.</mixed-citation></ref><ref id="CR10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Handsaker</surname><given-names>B</given-names></name><name><surname>Wysoker</surname><given-names>A</given-names></name><name><surname>Fennell</surname><given-names>T</given-names></name><name><surname>Ruan</surname><given-names>J</given-names></name><name><surname>Homer</surname><given-names>N</given-names></name><etal/></person-group><article-title>The sequence alignment/map format and samtools</article-title><source>Bioinformatics</source><year>2009</year><volume>25</volume><fpage>2078</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btp352</pub-id><?supplied-pmid 19505943?><pub-id pub-id-type="pmid">19505943</pub-id></element-citation></ref><ref id="CR11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anders</surname><given-names>S</given-names></name><name><surname>Pyl</surname><given-names>PT</given-names></name><name><surname>Huber</surname><given-names>W</given-names></name></person-group><article-title>HTSeq-a Python framework to work with high-throughput sequencing data</article-title><source>Bioinformatics</source><year>2015</year><volume>31</volume><issue>2</issue><fpage>166</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btu638</pub-id><?supplied-pmid 25260700?><pub-id pub-id-type="pmid">25260700</pub-id></element-citation></ref><ref id="CR12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goecks</surname><given-names>J</given-names></name><name><surname>Nekrutenko</surname><given-names>A</given-names></name><name><surname>Taylor</surname><given-names>JEA</given-names></name></person-group><article-title>Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences</article-title><source>Genome Biol</source><year>2010</year><volume>11</volume><fpage>86</fpage><pub-id pub-id-type="doi">10.1186/gb-2010-11-8-r86</pub-id></element-citation></ref><ref id="CR13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oinn</surname><given-names>T</given-names></name><name><surname>Addis</surname><given-names>M</given-names></name><name><surname>Ferris</surname><given-names>J</given-names></name><name><surname>Marvin</surname><given-names>D</given-names></name><name><surname>Senger</surname><given-names>M</given-names></name><name><surname>Greenwood</surname><given-names>M</given-names></name><etal/></person-group><article-title>Taverna: a tool for the composition and enactment of bioinformatics workflows</article-title><source>Bioinformatics (Oxford, England)</source><year>2004</year><volume>20</volume><issue>17</issue><fpage>3045</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/bth361</pub-id></element-citation></ref><ref id="CR14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abouelhoda</surname><given-names>M</given-names></name><name><surname>Issa</surname><given-names>SA</given-names></name><name><surname>Ghanem</surname><given-names>M</given-names></name></person-group><article-title>Tavaxy: Integrating Taverna and Galaxy workflows with cloud computing support</article-title><source>BMC Bioinformatics</source><year>2012</year><volume>13</volume><issue>1</issue><fpage>77</fpage><pub-id pub-id-type="doi">10.1186/1471-2105-13-77</pub-id><?supplied-pmid 22559942?><pub-id pub-id-type="pmid">22559942</pub-id></element-citation></ref><ref id="CR15"><label>15</label><mixed-citation publication-type="other">Jun G, Wing MK, Abecasis GR, Kang HM. An efficient and scalable analysis framework for variant extraction and refinement from population scale DNA sequence data. Genome Res. 2015:176552&#x02013;114. doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1101/gr.176552.114">10.1101/gr.176552.114</ext-link>.</mixed-citation></ref><ref id="CR16"><label>16</label><mixed-citation publication-type="other">Bcbio-nextgen. <ext-link ext-link-type="uri" xlink:href="https://github.com/chapmanb/bcbio-nextgen">https://github.com/chapmanb/bcbio-nextgen</ext-link>.</mixed-citation></ref><ref id="CR17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hajirasouliha</surname><given-names>I</given-names></name><name><surname>Hormozdiari</surname><given-names>F</given-names></name><name><surname>Alkan</surname><given-names>C</given-names></name><name><surname>Kidd</surname><given-names>J</given-names></name><name><surname>Birol</surname><given-names>I</given-names></name><name><surname>Eichler</surname><given-names>E</given-names></name><etal/></person-group><article-title>Detection and characterization of novel sequence insertions using paired-end next-generation sequencing</article-title><source>Bioinformatics</source><year>2010</year><volume>26</volume><fpage>1277</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btq152</pub-id><?supplied-pmid 20385726?><pub-id pub-id-type="pmid">20385726</pub-id></element-citation></ref><ref id="CR18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>K</given-names></name><name><surname>Wallis</surname><given-names>J</given-names></name><name><surname>McLellan</surname><given-names>M</given-names></name><name><surname>Larson</surname><given-names>D</given-names></name><name><surname>Kalicki</surname><given-names>J</given-names></name><name><surname>Pohl</surname><given-names>C</given-names></name><etal/></person-group><article-title>Breakdancer: an algorithm for high-resolution mapping of genomic structural variation</article-title><source>Nat Methods</source><year>2009</year><volume>6</volume><fpage>677</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1363</pub-id><?supplied-pmid 19668202?><pub-id pub-id-type="pmid">19668202</pub-id></element-citation></ref></ref-list></back></article>