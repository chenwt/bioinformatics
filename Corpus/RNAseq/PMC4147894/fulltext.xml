<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName journalpublishing.dtd?><?SourceDTD.Version 2.3?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 2?><front><journal-meta><journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id><journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id><journal-id journal-id-type="publisher-id">bioinformatics</journal-id><journal-id journal-id-type="hwp">bioinfo</journal-id><journal-title-group><journal-title>Bioinformatics</journal-title></journal-title-group><issn pub-type="ppub">1367-4803</issn><issn pub-type="epub">1367-4811</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">4147894</article-id><article-id pub-id-type="pmid">25161221</article-id><article-id pub-id-type="doi">10.1093/bioinformatics/btu441</article-id><article-id pub-id-type="publisher-id">btu441</article-id><article-categories><subj-group subj-group-type="heading"><subject>Eccb 2014 Proceedings Papers Committee</subject><subj-group subj-group-type="heading"><subject>Original Papers</subject><subj-group subj-group-type="heading"><subject>Sequencing and Sequence Analysis for Genomics</subject></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Towards a piRNA prediction using multiple kernel fusion and support vector machine</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Brayet</surname><given-names>Jocelyn</given-names></name><xref ref-type="aff" rid="btu441-AFF1"><sup>1</sup></xref><xref ref-type="aff" rid="btu441-AFF1"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Zehraoui</surname><given-names>Farida</given-names></name><xref ref-type="aff" rid="btu441-AFF1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Jeanson-Leh</surname><given-names>Laurence</given-names></name><xref ref-type="aff" rid="btu441-AFF1"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Israeli</surname><given-names>David</given-names></name><xref ref-type="aff" rid="btu441-AFF1"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Tahi</surname><given-names>Fariza</given-names></name><xref ref-type="aff" rid="btu441-AFF1"><sup>1</sup></xref><xref ref-type="corresp" rid="btu441-COR1">*</xref></contrib><aff id="btu441-AFF1"><sup>1</sup>IBISC EA 4526, UEVE/Genopole, IBGBI, 23 bv. de France, 91000 Evry, France and <sup>2</sup>Genethon, 1, bis rue de l&#x02019;Internationale, 91002 Evry Cedex, France</aff></contrib-group><author-notes><corresp id="btu441-COR1">*To whom correspondence should be addressed.</corresp></author-notes><pub-date pub-type="ppub"><day>01</day><month>9</month><year>2014</year></pub-date><pub-date pub-type="epub"><day>22</day><month>8</month><year>2014</year></pub-date><pub-date pub-type="pmc-release"><day>22</day><month>8</month><year>2014</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on the							<pub-date pub-type="epub"/>. --><volume>30</volume><issue>17</issue><fpage>i364</fpage><lpage>i370</lpage><permissions><copyright-statement>&#x000a9; The Author 2014. Published by Oxford University Press.</copyright-statement><copyright-year>2014</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/4.0"><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p></license></permissions><abstract><p><bold>Motivation:</bold> Piwi-interacting RNA (piRNA) is the most recently discovered and the least investigated class of Argonaute/Piwi protein-interacting small non-coding RNAs. The piRNAs are mostly known to be involved in protecting the genome from invasive transposable elements. But recent discoveries suggest their involvement in the pathophysiology of diseases, such as cancer. Their identification is therefore an important task, and computational methods are needed. However, the lack of conserved piRNA sequences and structural elements makes this identification challenging and difficult.</p><p><bold>Results:</bold> In the present study, we propose a new modular and extensible machine learning method based on multiple kernels and a support vector machine (SVM) classifier for piRNA identification. Very few piRNA features are known to date. The use of a multiple kernels approach allows editing, adding or removing piRNA features that can be heterogeneous in a modular manner according to their relevance in a given species. Our algorithm is based on a combination of the previously identified features [sequence features (k-mer motifs and a uridine at the first position) and piRNAs cluster feature] and a new telomere/centromere vicinity feature. These features are heterogeneous, and the kernels allow to unify their representation. The proposed algorithm, named <italic>piRPred</italic>, gives promising results on <italic>Drosophila</italic> and <italic>Human</italic> data and outscores previously published piRNA identification algorithms.</p><p><bold>Availability and implementation</bold>: <italic>piRPred</italic> is freely available to non-commercial users on our Web server EvryRNA <ext-link ext-link-type="uri" xlink:href="http://EvryRNA.ibisc.univ-evry.fr">http://EvryRNA.ibisc.univ-evry.fr</ext-link></p><p><bold>Contact:</bold>
<email>tahi@ibisc.univ-evry.fr</email></p></abstract><counts><page-count count="7"/></counts></article-meta></front><body><sec><title>1 INTRODUCTION</title><p>Using computational approaches is a practical manner to identify potential non-coding RNAs (ncRNAs), which can be experimentally studied further. Many methods have been developed for the <italic>in silico</italic> prediction of several types of ncRNAs such as microRNAs (miRNAs).</p><p>The Piwi protein-interacting RNA (piRNA) is the most recently discovered and the least characterized class of Argonaute (Ago)/Piwi protein-interacting small ncRNA. Unlike the broad expression of miRNA in most cells and tissue types, piRNA expression is highly enriched in the germline. Like miRNA, piRNA molecules are associated with proteins of the Ago/Piwi family to execute sequence-specific gene silencing. Additionally, piRNA molecules may fine-tune gene expression by mediating epigenetic modifications of heterochromatin. The germline-enriched expression pattern and the finding that mutating the piRNA biogenesis pathway resulted in sterility demonstrated the critical impact of the Piwi&#x02013;piRNA pathway exert on germline development and function (<xref rid="btu441-B5" ref-type="bibr">Carmell <italic>et al.</italic>, 2007</xref>; <xref rid="btu441-B8" ref-type="bibr">Deng and Lin, 2002</xref>; <xref rid="btu441-B15" ref-type="bibr">Kuramochi-Miyagawa <italic>et al.</italic>, 2004</xref>). In addition to their activity in the germline, accumulating recent data have suggested piRNA expression and biological activity in somatic cells as well, and recent discoveries suggest the involvement of piRNAs in diseases such as cancer (<xref rid="btu441-B20" ref-type="bibr">Mei <italic>et al.</italic>, 2013</xref>). Therefore, an updated vision suggests a wider definition of piRNA expression and biological function in both germline and somatic cells (<xref rid="btu441-B21" ref-type="bibr">Peng and Lin, 2013</xref>; <xref rid="btu441-B23" ref-type="bibr">Ross <italic>et al.</italic>, 2014</xref>).</p><p>The piRNAs are the largest and most heterogeneous class of the small ncRNA family, exceeding 2 million distinct piRNA species in the mouse (<xref rid="btu441-B18" ref-type="bibr">Lau <italic>et al.</italic>, 2006</xref>). Initial identification and characterization of mammalian piRNAs were achieved by experimental approaches that combined the isolation of Piwi protein-interacting sequences and/or deep sequencing of germline-enriched short RNA sequences (<xref rid="btu441-B1" ref-type="bibr">Aravin <italic>et al.</italic>, 2006</xref>; <xref rid="btu441-B9" ref-type="bibr">Girard <italic>et al.</italic>, 2006</xref>; <xref rid="btu441-B27" ref-type="bibr">Watanabe <italic>et al.</italic>, 2006</xref>). Although this methodology appeared productive, it could not exhaustively cover the entire repertoire of piRNA molecules in a specific organism. In particular, tissue-specific and low copy number-expressed piRNA could not be fully detected using this methodology.</p><p>Unlike miRNAs, piRNAs lack clear secondary structure motifs, and primary sequence conservation, except for enrichment for the presence of a uridine nucleotide at the 5&#x02032; first position of the transcript (<xref rid="btu441-B19" ref-type="bibr">Le Thomas <italic>et al.</italic>, 2014</xref>). One hallmark characteristic of piRNA sequences, that are of 24&#x02013;35 nt of length, is that most of them are encoded in genome clusters ranging from 1 to &#x0003e;100 kb long. There are both monodirectional clusters encoding piRNAs on one strand, and bidirectional clusters whose halves encode piRNAs on opposite strands and whose transcription starts in the opposite direction from a centrally located promoter (<xref rid="btu441-B4" ref-type="bibr">Brennecke <italic>et al.</italic>, 2007</xref>; <xref rid="btu441-B18" ref-type="bibr">Lau <italic>et al.</italic>, 2006</xref>). Brennecke <italic>et al.</italic> have also reported that in <italic>Drosophila</italic>, piRNAs have the tendency to be expressed near telomere and centromere regions on the chromosome (<xref rid="btu441-B4" ref-type="bibr">Brennecke <italic>et al.</italic>, 2007</xref>; <xref rid="btu441-B19" ref-type="bibr">Le Thomas <italic>et al.</italic>, 2014</xref>).</p><p>The lack of conserved characteristics makes the identification of piRNAs by computational methods a difficult challenge. Only a few methods have been developed to predict piRNAs. These methods can be classified into two classes. The first one uses a linear classification algorithm to predict individual piRNAs (<xref rid="btu441-B31" ref-type="bibr">Zhang <italic>et al.</italic>, 2011</xref>), and the second one is based on clustering approaches to predict piRNA clusters from RNAseq sequences (<xref rid="btu441-B14" ref-type="bibr">Jung <italic>et al.</italic>, 2014</xref>; <xref rid="btu441-B22" ref-type="bibr">Rosenkranz and Zischler, 2012</xref>). Zhang <italic>et al.</italic> group proposed a method based on the use of k-mer strings for the identification of motifs in piRNA sequences. All the 1&#x02013;5 nt strings are considered, including 4 1-mer strings (A, C, G and T), 16 2-mer strings, 64 3-mer strings, 256 4-mer strings and 1024 5-mer strings. A total of 1364 strings are obtained and used for classifying piRNA and non-piRNA sequences. Two algorithms have been proposed for predicting piRNA clusters from RNAseq data: proTRAC (<xref rid="btu441-B22" ref-type="bibr">Rosenkranz and Zischler, 2012</xref>) and piClust (<xref rid="btu441-B14" ref-type="bibr">Jung <italic>et al.</italic>, 2014</xref>). The proTRAC algorithm is based on a statistical probabilistic analysis. It analyzes mapped sequence reads and identifies clusters based on significant deviations from a uniform piRNA distribution, using different types of information, including the density of mapped reads, strand asymmetry, frequency of putative piRNA loci with U at the first position of the sequence, or A at Position 10. On the other hand, the piClust algorithm uses a density-based clustering approach without assuming any parametric distribution and considers the actual interdistance between mapped reads for the determination of clustering, with results that were claimed to outperform the proTRAC algorithm.</p><p>Taken together, previous piRNA prediction algorithms were based on the following features: (i) transcript length of 24&#x02013;35 nt, (ii) nucleotide bias at Position 1 of G expression, (iii) localization in clusters and (iv) differential frequencies of certain k-mer sequences. To the best of our knowledge, however, none of the previous publications have attempted to combine all of these features together. Exploiting all these features could improve the results obtained by the existing algorithms.</p><p>In this article, we propose a computational approach to combine heterogeneous types of piRNA features. We developed a machine learning method based on the fusion of multiple kernels and support vector machines (SVMs) (<xref rid="btu441-B25" ref-type="bibr">Vapnik, 1995</xref>), a well-known machine learning method that has been widely used in diverse areas of bioinformatics. SVM is a kernel-based learner, which can find non-liner boundaries between data classes by using kernels. Using kernel methods makes it possible to represent the original data by using a matrix representation, called a kernel matrix. Symmetric positive definite kernel matrices encode the similarity between sequences in their respective input space. This implies that the heterogeneous features can all be replaced by appropriately kernel matrices. This allows the elimination of the data heterogeneity. Constructing the same representation for all datasets and integrating these representations is the main intuition behind kernel fusion methods. In recent years, several machine learning methods have been proposed to exploit different information sources using kernels (<xref rid="btu441-B11" ref-type="bibr">G&#x000f6;nen and Alpayd, 2011</xref>). Research in multiple kernel learning (MKL) has focused on both developing new formulations as well as optimizing them. Different formulations are required to address the needs of different applications. Most of the methods using these formulations propose to learn the combined kernels by tuning automatically the kernel weights (<xref rid="btu441-B11" ref-type="bibr">G&#x000f6;nen and Alpayd, 2011</xref>). Early work focused on learning the kernel as a linear combination of given base kernels (<xref rid="btu441-B17" ref-type="bibr">Lanckriet <italic>et al.</italic>, 2004</xref>). Non-linear kernel combinations (<xref rid="btu441-B7" ref-type="bibr">Cortes <italic>et al.</italic>, 2009</xref>), such as products of kernels and mixtures of polynomials, have also been shown to be appropriate in certain domains. Many of these formulations can be easily cast in the generalized MKL (GMKL) framework proposed in (<xref rid="btu441-B26" ref-type="bibr">Varma and Babu, 2009</xref>).</p><p>In the piRNA prediction problem, the use of multiple kernels makes it possible to propose a modular and extensible method. Thus, new kernels representing newly discovered piRNA characteristics can easily be added. Because the research on piRNAs is at its beginning, it is important to have methods that can integrate new knowledge about this RNA. The multiple kernel method also has the advantage of allowing exploration of characteristics, even when these are not yet validated, which is helpful in this context. Thus, it could be possible to ignore an implemented kernel if it turns out not to be useful and/or corresponds to a false knowledge. Our method is therefore adaptive, the user being able to consider the appropriate kernels according to the data type and studied species.</p><p>To summarize, we have developed an extensible and adaptive classification method for piRNA prediction, which is distinct from the existing methods in several aspects: (i) several kernels that represent heterogeneous feature sets are built and used, (ii) a new type of feature is explored, (iii) the characteristic of piRNAs to occur in clusters on the chromosome is coded in a kernel to use it in a supervised way and (iv) a non-linear classifier approach is used, which is more suitable for real-world data.</p><p>Here we describe our multiple kernel-based SVM algorithm, called <italic>piRPred</italic>, and we report the results that we have obtained, that are promising.</p></sec><sec><title>2 METHODS</title><p>We have developed a new classification tool to identify piRNAs. Our algorithm takes as input a set of sequences, and returns for each sequence 1 if it is a piRNA, and 0 if not.</p><p>A very important step in machine learning classifiers is the feature characterization. In the present version of our algorithm, we use four principal piRNA features, one of which has not yet been exploited in any computational method. To deal with the heterogeneity of the features, we use different kernels to represent them. Each class of features corresponds to one kernel. To perform the classification, we use two approaches. In the first one, we simply average the kernels and then use the SVM. In the second one, we use a multiple kernel formulation of the SVM that can learn automatically the weights of each kernel.</p><sec id="SEC2.1"><title>2.1 piRNA features and kernel description</title><p>One principal reason for difficulty in predicting piRNAs is their lack of conservation in structure and sequence. PiRNAs are very diverse: hundreds of thousands of unique piRNA sequences do not show any structure or sequence motif similarities, except for a bias for a uridine residue at the first base (<xref rid="btu441-B19" ref-type="bibr">Le Thomas <italic>et al.</italic>, 2014</xref>). The other known and admitted characteristic of piRNAs is that they appear in clusters on the genome. This is why the tentative for computational methods for piRNA identification are methods that predict clusters of piRNAs (<xref rid="btu441-B14" ref-type="bibr">Jung <italic>et al.</italic>, 2014</xref>; <xref rid="btu441-B22" ref-type="bibr">Rosenkranz and Zischler, 2012</xref>). In <xref rid="btu441-B4" ref-type="bibr">Brennecke <italic>et al.</italic> (2007)</xref>, it is also stated that in <italic>Drosophila</italic>, piRNA clusters can span up to 200 kb and are located in pericentromeric and subtelomeric regions. Finally, it has been shown in (<xref rid="btu441-B31" ref-type="bibr">Zhang <italic>et al.</italic>, 2011</xref>) that a set of k-mer motifs have different frequencies in piRNA and non-piRNA sequences. Thus, in the present version of our algorithm, we consider the following features:
<list list-type="order"><list-item><p>The frequency of certain k-mer motifs.</p></list-item><list-item><p>The presence of a uridine base at the first position of the sequence.</p></list-item><list-item><p>The distance to centromeric and telomeric regions of the chromosome.</p></list-item><list-item><p>The occurrence of piRNAs in clusters on the genome.</p></list-item></list>
</p><p>We define three kernels: one kernel representing the two first features, and two kernels representing the third and the fourth kernels, respectively. Each kernel is a square similarity matrix of size <inline-formula><mml:math id="I1"><mml:mrow><mml:mi>N</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>, <italic>N</italic> being the size of the training dataset (including positive and negative samples), and the building process is performed as following: for each sequence, we built a vector (or a matrix) representing the feature. A square distance matrix is then constructed by calculating the Euclidian distances between the vectors (or Frobenius distances between matrices). From this matrix, we calculate the Gaussian kernel:
<disp-formula id="btu441-M1"><label>(1)</label><mml:math id="MM1"><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>exp</mml:mi><mml:mo>&#x02061;</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi>x</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msup><mml:mo stretchy="false">|</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msup></mml:mrow></mml:math></disp-formula>
The estimation of the value of <italic>&#x003b3;</italic> is done using the method described below in Section 2.3.</p><sec id="SEC2.1.1"><title>2.1.1 K-mer string and uridine position</title><p>K-mers refer to specific k-tuple or k-grams of nucleic acid or amino acid sequences that can be used to identify certain regions within biomolecules. To characterize piRNA sequences, we consider k-mer strings, as performed by (<xref rid="btu441-B31" ref-type="bibr">Zhang <italic>et al.</italic>, 2011</xref>). We make use of the results obtained by Zhang <italic>et al.</italic>, which indicate that 32 k-mer stings (2 4-mer and 30 5-mer) are differentially present in piRNA and non-piRNA sequences. We thus calculated, for each sequence, a vector containing the frequencies of these 32 k-mers in the sequence.</p><p>To this kernel, we added information about the presence or the absence of a uridine base at the first position of the sequence. We consider this piRNA characteristic as a learning feature instead of a filter to avoid eliminating the sequences that do not present this characteristic. Not all piRNAs present this characteristic; we analyzed the piRNA sequences of Human and <italic>Drosophila</italic> available in piRNABank (<xref rid="btu441-B16" ref-type="bibr">Lakshmi and Agrawal, 2008</xref>; <ext-link ext-link-type="uri" xlink:href="http://pirnabank.ibab.ac.in/">http://pirnabank.ibab.ac.in/</ext-link>), and, respectively, 79.68 and 65.93% of Human and <italic>Drosophila</italic> piRNAs have a uridine at their first position. Each sequence is then represented by a vector of 33 dimensions: the first dimension represents the information on the uridine base, and the other 32 dimensions represent the k-mer frequencies. We then compute a Gaussian kernel using these vectors.</p></sec><sec id="SEC2.1.2"><title>2.1.2 Distances to pericentromeric and subtelomeric regions</title><p>The second kernel corresponds to the distance of the sequence to the pericentromeric and subtelomeric regions of the genome. We built a 4D feature vector, which represents the distance to each of these regions on each strand of each chromosome (see <xref ref-type="fig" rid="btu441-F1">Fig. 1</xref>): the distance to the first telomere (t1), the distance to the second telomere (t2), the distance to one side of the centromere (c1) and the distance to the other side of the centromere (c2).
<fig id="btu441-F1" position="float"><label>Fig. 1.</label><caption><p>A chromosome with telomeric and centromeric regions</p></caption><graphic xlink:href="btu441f1p"/></fig></p><p>When the sequence is in a telomeric or centromeric region, the value of the distance is infinity, as well as when the sequence is not in the analyzed strand and chromosome. When a sequence appears in different positions in the genome, the minimal value for each of the four distances is used. The Gaussian kernel is then calculated with these minimal values.</p></sec><sec id="SEC2.1.3"><title>2.1.3 piRNA clusters using k-nearest neighbor sequences</title><p>To take into consideration the cluster location on the chromosome of piRNAs in a supervised manner, we propose a new kernel, which takes into account the neighbors of each sequence in the genome. The neighbors in our approach represent the closest sequences that are located on the same chromosome as the target sequence and contained in the training set. We propose to find the <italic>k</italic>-nearest neighbors of each sequence and then to construct a <inline-formula><mml:math id="I2"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x000d7;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> matrix containing the distances between all the sequences (the target sequence and its <italic>k</italic>-nearest neighbors). Each matrix represents a density &#x02018;context&#x02019; of a target sequence in the training set without using the labels of the neighbors. We then compute the Frobenius distances between the obtained matrices, and a Gaussian kernel is computed using these distances.</p><p>The value of <italic>k</italic> depends on the number of piRNAs contained in a cluster. This value is variable. Cluster size varies between two and several hundred (<xref rid="btu441-B9" ref-type="bibr">Girard <italic>et al.</italic>, 2006</xref>). By default, we set this value to 4 (see Section 3.5). It is, however, a parameter that can be changed by the user.</p></sec></sec><sec id="SEC2.2"><title>2.2 SVM and kernel fusion</title><p>The SVM is a widely used classifier in bioinformatics. It is a discriminative classifier proposed for binary classification problems (<xref rid="btu441-B25" ref-type="bibr">Vapnik, 1995</xref>). It defines a hyperplane that divides the space into two sides according to the sign of a discriminant function. The boundary between regions classified as positives and negatives is called the decision boundary of the classifier. The decision boundary defined by a hyperplane is said to be linear because it is linear in the input examples. A classifier with a linear decision boundary is called a linear classifier. Conversely, when the decision boundary of a classifier depends on the data in a non-linear way, the classifier is said to be non-linear. The SVM chooses the separating hyperplane that maximizes the margin (the hyperplane that leaves as much room as possible between the hyperplane and the closest examples). In addition to performing linear classification, SVM can efficiently perform a non-linear classification using kernels.</p><p>Many MKL formulations have been proposed, and some have been proven effective in several applications (<xref rid="btu441-B11" ref-type="bibr">G&#x000f6;nen and Alpayd, 2011</xref>). The simple way to combine kernels is to use fixed rules without any parameters like computing the mean of the kernels and then applying SVM. The GMKL (<xref rid="btu441-B26" ref-type="bibr">Varma and Babu, 2009</xref>) is a general purpose optimizer capable of handling a wide range of formulations and admits fairly general kernel parameterization. <xref rid="btu441-B13" ref-type="bibr">Jain <italic>et al.</italic> (2012)</xref> propose to speed up GMKL optimization by an order of magnitude in many cases. They achieve this by designing an alternative optimizer based on spectral projected gradient (SPG) descent (<xref rid="btu441-B3" ref-type="bibr">Birgin <italic>et al.</italic>, 2000</xref>). SPG is particularly well suited to large-scale problems because it builds a coarse approximation efficiently and without any memory overhead. We have used a free SVM software package called LIBSVM (<xref rid="btu441-B6" ref-type="bibr">Chang and Lin, 2011</xref>) for the averaged kernel approach and the SPG-GMKL software (<xref rid="btu441-B13" ref-type="bibr">Jain <italic>et al.</italic>, 2012</xref>) for the MKL approach.</p></sec><sec id="SEC2.3"><title>2.3 Kernel parameter selection</title><p>Determining the kernel parameters for the SVM is a problem in practice. A popular method for defining the kernel parameters is the grid search method (<xref rid="btu441-B12" ref-type="bibr">Hsu and Lin, 2002</xref>). The classifier is trained with different kernel parameters, and the parameters that provide the best results are chosen. This makes the training process time-consuming, especially when there are large datasets. To avoid this problem, the choices concerning parameter settings are often driven by heuristics. An example of a heuristic is to select the value of <italic>&#x003b3;</italic> that should be relative to the variance of the data, but this is rarely the best choice. An alternative to classic grid search is to define the parameter <italic>&#x003b3;</italic> using the between-cluster distances in the feature space (<xref rid="btu441-B29" ref-type="bibr">Wu and Wang, 2009</xref>). For each kernel parameter value, we calculate a distance index and choose the value, which leads to the best separation index. This index represents the separation degree of the classes in the feature space. The between-cluster distances in the sample space is defined by
<disp-formula id="btu441-M2"><label>(2)</label><mml:math id="MM2"><mml:mrow><mml:mi>&#x003b4;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="true">(</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="I3"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="I4"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> are the positive and negative classes, respectively, and <inline-formula><mml:math id="I5"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="I6"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> are sample sizes of <inline-formula><mml:math id="I7"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="I8"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula>, respectively. The corresponding distance measure <inline-formula><mml:math id="I9"><mml:mrow><mml:msub><mml:mi>&#x003b4;</mml:mi><mml:mi>F</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in the feature space using the kernel similarity matrix K is:
<disp-formula id="btu441-M3"><label>(3)</label><mml:math id="MM3"><mml:mrow><mml:msub><mml:mi>&#x003b4;</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:math></disp-formula>
where
<disp-formula><mml:math id="UM1"><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:munder><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02212;</mml:mo></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:munder></mml:mrow></mml:munder><mml:mi>K</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02212;</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
<disp-formula><mml:math id="UM2"><mml:mrow><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:munder><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>q</mml:mi><mml:mo>&#x02212;</mml:mo></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:munder></mml:mrow></mml:munder><mml:mi>K</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>q</mml:mi><mml:mo>&#x02212;</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mi>l</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
and
<disp-formula><mml:math id="UM3"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mstyle displaystyle="true"><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:munder><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#x02212;</mml:mo></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mo>+</mml:mo></mml:msub></mml:mrow></mml:munder></mml:mrow></mml:munder><mml:mi>K</mml:mi></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>+</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>&#x02212;</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mo>+</mml:mo></mml:msub><mml:msub><mml:mi>l</mml:mi><mml:mo>&#x02212;</mml:mo></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
</p></sec></sec><sec><title>3 RESULTS AND DISCUSSION</title><sec id="SEC3.1"><title>3.1 Training datasets</title><p>We use different sets of positive and negative data to perform the cross-validation and the prediction tests on Human and <italic>Drosophila</italic> species.</p><p>Positive data are taken from piRNABank (<xref rid="btu441-B16" ref-type="bibr">Lakshmi and Agrawal, 2008</xref>; (<ext-link ext-link-type="uri" xlink:href="http://pirnabank.ibab.ac.in/">http://pirnabank.ibab.ac.in/</ext-link>). The piRNABank currently contains 23 439 and 22 336 non-redundant piRNA sequences of Human and <italic>Drosophila</italic> genomes, respectively.</p><p>We built the negative dataset with non-redundant sequences of several types:
<list list-type="bullet"><list-item><p>Sequences of size between 25 and 33 nt corresponding to portions at 5&#x02032; of transfer RNA (tRNA) sequences, that are taken from tRNA database (<ext-link ext-link-type="uri" xlink:href="http://lowelab.ucsc.edu/GtRNAdb/">http://lowelab.ucsc.edu/GtRNAdb/</ext-link>).</p></list-item><list-item><p>Sequences corresponding to mature miRNAs and taken from miRBase (<ext-link ext-link-type="uri" xlink:href="http://www.mirbase.org/">http://www.mirbase.org/</ext-link>, version 20).</p></list-item><list-item><p>Sequences of size between 25 and 33 nt chosen randomly from the exonic regions of protein-coding genes taken from Ensembl Genes 75 database through Biomart (<ext-link ext-link-type="uri" xlink:href="http://www.ensembl.org/biomart">http://www.ensembl.org/biomart</ext-link>)</p></list-item></list>
</p><p>The Human negative dataset and the <italic>Drosophila</italic> negative dataset contain, respectively, 59 947 and 16 243 non-redundant sequences, composed of 590 and 301 sequences of tRNA portions, 2576 and 698 sequences of mature miRNAs and 56 781 and 15 244 sequences of exonic regions.</p><p>For training samples, we randomly selected five positive datasets and five negative datasets each composed of 7500 Human sequences, and five positive datasets and five negative datasets each composed of 5000 <italic>Drosophila</italic> sequences. We also selected randomly 2500 positive sequences for each Human and <italic>Drosophila</italic>, other than the ones used in the training step, to test our algorithm on classifying new sequences.</p><p>Finally, for each sequence, we gathered the following information: the name (id), the nucleotide sequence, the strand (&#x02018;+&#x02019; or &#x02018;&#x02212;&#x02019;), the chromosome ID and the position on the chromosome.</p></sec><sec id="SEC3.2"><title>3.2 Measures</title><p>To evaluate the classification performance, we use several statistical measures: accuracy <italic>ACC</italic>, sensitivity <italic>SE</italic>, specificity <italic>SP</italic> and positive predictive value <italic>PPV</italic>. These measures are defined as follows:
<list list-type="bullet"><list-item><p>Accuracy <inline-formula><mml:math id="I10"><mml:mrow><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, which measures the percentage of samples that are correctly classified.</p></list-item><list-item><p>Sensitivity <inline-formula><mml:math id="I11"><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, which measures the accuracy on positive samples.</p></list-item><list-item><p>Specificity <inline-formula><mml:math id="I12"><mml:mrow><mml:mi>S</mml:mi><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, which measures the accuracy on negative samples.</p></list-item><list-item><p>Positive predictive value <inline-formula><mml:math id="I13"><mml:mrow><mml:mi>P</mml:mi><mml:mi>P</mml:mi><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, which measures the percentage of correctly classified positive samples among all positive-classified ones.</p></list-item></list>
where <italic>TP</italic>, <italic>FP</italic>, <italic>TN</italic> and <italic>FN</italic> are the numbers of true-positive, false-positive, true-negative and false-negative predictions, respectively.</p></sec><sec id="SEC3.3"><title>3.3 Cross-validation results on our training datasets</title><p>The evaluation of our method is conducted through a 5-fold cross-validation on Human and <italic>Drosophila</italic> datasets. Because we have large sets of data, we also performed a 10-fold cross-validation, and the results are similar to the ones obtained with the 5-fold cross-validation. The experiment was repeated five times, considering at each time a matrix containing 7500 (respectively 5000) positive sequences and 7500 (respectively 5000) negative sequences for Human (respectively <italic>Drosophila</italic>).</p><p>The value of <italic>&#x003b3;</italic> in the Gaussian kernel (see Section 2) is estimated to 1.73 in Human and 1.79 in <italic>Drosophila</italic> for the first kernel (k-mer kernel), to 8.73e-17 in Human and 4.67e-17 in <italic>Drosophila</italic> for the second one (position kernel) and to 4.48e-13 for Human and 5.21e-12 for <italic>Drosophila</italic> for the third one (<italic>k</italic>-nearest neighbors kernel).</p><p>To evaluate the relevance of the defined kernels, we tested our method using each of the three kernels, and then the combination of the three kernels by the kernels mean method and by the SPG-GMKL method (see Section 2.2). The cross-validation results obtained on our training datasets of Human and <italic>Drosophila</italic> are given in <xref ref-type="table" rid="btu441-T1">Table 1</xref>. <italic>Km</italic> represents the kernel implementing the k-mer and the uridine features (see Section 2.1.1), <italic>Kd</italic> represents the kernel implementing the distance of the sequences from pericentromeric and subtelomeric regions on the chromosome (see Section 2.1.2) and <italic>Kn</italic> represents the kernel implementing the <italic>k</italic>-nearest neighbors sequences (see Section 2.1.3). The tool developed by Zhang and collaborators (<xref rid="btu441-B31" ref-type="bibr">Zhang <italic>et al.</italic>, 2011</xref>), based on the k-mer method, was tested and compared with our method. To test it under the same conditions as our tool, it was re-trained on our datasets, and a 5-fold cross-validation was performed. The results are also given in <xref ref-type="table" rid="btu441-T1">Table 1</xref>. The classification results are evaluated using the measures given above (Section 3.2), and the best score for each measure is given in bold.
<table-wrap id="btu441-T1" position="float"><label>Table 1.</label><caption><p>Cross-validation results obtained by our method (using different combinations of kernels) and by Zhang <italic>et al.</italic> method in Human and <italic>Drosophila</italic> training datasets</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="2" colspan="1">Method</th><th align="center" colspan="4" rowspan="1"><bold>Human</bold><hr/></th><th align="center" colspan="4" rowspan="1"><bold>Drosophila</bold><hr/></th></tr><tr><th rowspan="1" colspan="1">ACC</th><th rowspan="1" colspan="1">SP</th><th rowspan="1" colspan="1">SE</th><th rowspan="1" colspan="1">PPV</th><th rowspan="1" colspan="1">ACC</th><th rowspan="1" colspan="1">SP</th><th rowspan="1" colspan="1">SE</th><th rowspan="1" colspan="1">PPV</th></tr></thead><tbody align="left"><tr><td rowspan="1" colspan="1"><italic>Km</italic></td><td rowspan="1" colspan="1">0.76 &#x000b1; 0.03</td><td rowspan="1" colspan="1">0.75 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.81 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.75 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.67 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.70 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.65 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.66 &#x000b1; 0.02</td></tr><tr><td rowspan="1" colspan="1"><italic>Kd</italic></td><td rowspan="1" colspan="1">0.61 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.55 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.72 &#x000b1; 0.03</td><td rowspan="1" colspan="1">0.59 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.86 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.88 &#x000b1; 0.03</td><td rowspan="1" colspan="1">0.83 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.86 &#x000b1; 0.02</td></tr><tr><td rowspan="1" colspan="1"><italic>Kn</italic></td><td rowspan="1" colspan="1">0.74 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.82 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.67 &#x000b1; 0.03</td><td rowspan="1" colspan="1">0.80 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.83 &#x000b1; 0.03</td><td rowspan="1" colspan="1">0.82 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.83 &#x000b1; 0.04</td><td rowspan="1" colspan="1">0.82 &#x000b1; 0.01</td></tr><tr><td rowspan="1" colspan="1"><italic>Km/Kd/Kn mean</italic></td><td rowspan="1" colspan="1">0.81 &#x000b1; 0.03</td><td rowspan="1" colspan="1">0.82 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.78 &#x000b1; 0.03</td><td rowspan="1" colspan="1">0.81 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.87 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.93 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.81 &#x000b1; 0.03</td><td rowspan="1" colspan="1">0.91 &#x000b1; 0.02</td></tr><tr><td rowspan="1" colspan="1"><italic>Km/Kd/Kn SPG-GMKL</italic></td><td rowspan="1" colspan="1"><bold>0.86 &#x000b1; 0.02</bold></td><td rowspan="1" colspan="1"><bold>0.84 &#x000b1; 0.01</bold></td><td rowspan="1" colspan="1"><bold>0.88 &#x000b1; 0.03</bold></td><td rowspan="1" colspan="1"><bold>0.85 &#x000b1; 0.02</bold></td><td rowspan="1" colspan="1"><bold>0.89 &#x000b1; 0.03</bold></td><td rowspan="1" colspan="1"><bold>0.95 &#x000b1; 0.02</bold></td><td rowspan="1" colspan="1"><bold>0.83 &#x000b1; 0.03</bold></td><td rowspan="1" colspan="1"><bold>0.94 &#x000b1; 0.03</bold></td></tr><tr><td rowspan="1" colspan="1">Zhang <italic>et al.</italic></td><td rowspan="1" colspan="1">0.58 &#x000b1; 0.05</td><td rowspan="1" colspan="1">0.82 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.30 &#x000b1; 0.04</td><td rowspan="1" colspan="1">0.63 &#x000b1; 0.03</td><td rowspan="1" colspan="1">0.69 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.92 &#x000b1; 0.01</td><td rowspan="1" colspan="1">0.45 &#x000b1; 0.02</td><td rowspan="1" colspan="1">0.85 &#x000b1; 0.01</td></tr></tbody></table><table-wrap-foot><fn id="btu441-TF1"><p><italic>Note</italic>: ACC, accuracy; SP, specificity; SE, sensitivity; PPV, positive predictive value. In bold: The highest value in each column.</p></fn></table-wrap-foot></table-wrap></p><p>As shown in <xref ref-type="table" rid="btu441-T1">Table 1</xref>, the results obtained by piRPred with the SPG-GMKL method as well as with the kernels mean method are &#x0003e;0.8 in almost all measurements for both Human and <italic>Drosophila</italic>. Our results are clearly better than the ones reported by Zhang <italic>et al.</italic> Their tool fails on our training datasets, particularly on Human data. The accuracy is close to 0.5, the value of a random classification. Besides, the sensitivity is &#x0003c;0.5 both for Human and <italic>Drosophila</italic>, which means that it fails to identify positive piRNAs. Interestingly, using just the single <italic>Km</italic> kernel gives better results than those obtained using Zhang&#x02019;s method, which confirms the superior performance of our non-linear classifier SVM in comparison with the linear classification method proposed by Zhang <italic>et al.</italic></p><p>As expected, results are slightly different between Human and <italic>Drosophila</italic> sequences, reflecting species differences in the used features. This is, for instance, the case of the <italic>Kd</italic> kernel that produces better results in <italic>Drosophila</italic> than in Human. This kernel represents the characteristic for piRNA sequences to be close to telomere/centromere regions; characteristic that was reported in <italic>Drosophila</italic> (<xref rid="btu441-B4" ref-type="bibr">Brennecke <italic>et al.</italic>, 2007</xref>), but to our knowledge, not (yet?) confirmed in Human. Therefore, it is not clear whether applying this kernel in Human will be beneficial or not. The results obtained in <italic>Drosophila</italic> demonstrated positive results (values &#x02265;0.82), thus confirming its utility in <italic>Drosophila</italic>. Somewhat surprisingly, slightly positive results were obtained also in Human (values &#x0003e;0.5), suggesting that distances of piRNAs to telomere and centromere regions are significant (statistically) also in Human, although to a much lower level than in <italic>Drosophila</italic>. Inversely, <italic>Km</italic> kernel gives better results in Human than in <italic>Drosophila</italic>, suggesting better relevance of the corresponding features, i.e. the differential frequencies of certain k-mer motifs and the occurrence of a uridine at the first position. These results agree on one hand with the study we did on the uridine feature (see Section 2.1.1), which shows that the percentage of sequences containing a uridine at the first position is higher in Human than in <italic>Drosophila</italic> (79.68 and 65.93% respectively), and on another hand with the results published in (<xref rid="btu441-B31" ref-type="bibr">Zhang <italic>et al.</italic>, 2011</xref>), where a better performance of the k-mer method on Human than on <italic>Drosophila</italic> was shown. Surprisingly, however, the results obtained by Zhang <italic>et al.</italic> method, when we retrain it on our data, give completely opposite results. This is probably because our <italic>Drosophila</italic> training dataset is bigger than the one used by Zhang <italic>et al.</italic> (composed of 987 sequences), whereas our human training dataset is smaller than the one used by Zhang <italic>et al.</italic> (composed of 32 046 sequences).</p><p>Finally, the combination of the three kernels presents an advantage over each single kernel in almost all measures in both Human and <italic>Drosophila</italic>, showing a certain relevance of their combination. Besides, using the SPG-GMKL method for combining the kernels is clearly more beneficial than performing a simple mean of the kernels. Therefore, we chose as a model for our piRPred algorithm the one calculated by the SPG-GMKL method.</p></sec><sec id="SEC3.4"><title>3.4 Predictive sensitivity on new sequences</title><p>For both Human and <italic>Drosophila</italic>, we investigated our algorithm on 2500 piRNA sequences distinct from the ones used in the training step. Again, this was done in comparison with the Zhang <italic>et al.</italic> method, for which we tested both the online tool available on the web server (<ext-link ext-link-type="uri" xlink:href="http://122.228.158.106/piRNA/analysis.php">http://122.228.158.106/piRNA/analysis.php</ext-link>), as well as the model obtained after re-training on our datasets. The results are given in <xref ref-type="table" rid="btu441-T2">Table 2</xref>.
<table-wrap id="btu441-T2" position="float"><label>Table 2.</label><caption><p>Predictive performance of our method (<italic>piRPred</italic>) on Human and <italic>Drosophila</italic> sequences in comparison with the Zhang <italic>et al.</italic> method</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="2" colspan="1">Method</th><th align="center" colspan="2" rowspan="1"><bold>Human</bold><hr/></th><th align="center" colspan="2" rowspan="1"><bold>Drosophila</bold><hr/></th></tr><tr><th rowspan="1" colspan="1">TP</th><th rowspan="1" colspan="1">SE</th><th rowspan="1" colspan="1">TP</th><th rowspan="1" colspan="1">SE</th></tr></thead><tbody align="left"><tr><td rowspan="1" colspan="1"><italic>piRPred</italic></td><td rowspan="1" colspan="1"><bold>1989</bold></td><td rowspan="1" colspan="1"><bold>0.80</bold></td><td rowspan="1" colspan="1"><bold>2146</bold></td><td rowspan="1" colspan="1"><bold>0.86</bold></td></tr><tr><td rowspan="1" colspan="1">Zhang <italic>et al.</italic> method on web server</td><td rowspan="1" colspan="1">1953</td><td rowspan="1" colspan="1">0.78</td><td rowspan="1" colspan="1">1636</td><td rowspan="1" colspan="1">0.65</td></tr><tr><td rowspan="1" colspan="1">Zhang <italic>et al.</italic> method retrained</td><td rowspan="1" colspan="1">849</td><td rowspan="1" colspan="1">0.34</td><td rowspan="1" colspan="1">1568</td><td rowspan="1" colspan="1">0.63</td></tr></tbody></table><table-wrap-foot><fn id="btu441-TF2"><p><italic>Note</italic>: TP, true-positive predictions; SE, sensitivity. In bold: The highest value in each column.</p></fn></table-wrap-foot></table-wrap></p><p>The prediction results obtained by <italic>piRPred</italic> and by Zhang <italic>et al.</italic> method are in agreement with those obtained in the cross-validation. They show clearly superior performance of our algorithm. The re-trained version of Zhang <italic>et al.</italic> method fails completely to predict the given sequences as piRNAs. However, when using the web server version, the results are better. The reason could be because Zhang and collaborators trained their method on a very large set of data (173 090 sequences including 32 046 Human sequences and 987 <italic>Drosophila</italic> sequences), that probably include the studied sequences.</p></sec><sec id="SEC3.5"><title>3.5 Robustness regarding the value of <italic>k</italic> in the <italic>k</italic>-nearest neighbors kernel</title><p>The value of <italic>k</italic> in the <italic>k</italic>-nearest neighbors kernel (<italic>Kn</italic>) represents the number of piRNAs in a cluster on a chromosome strand. This value is variable, as can be seen in the piRNABank. Some clusters contain only two or three piRNAs on a strand, whereas others contain several hundreds (<xref rid="btu441-B9" ref-type="bibr">Girard <italic>et al.</italic>, 2006</xref>).</p><p>To determine the value of <italic>k</italic>, we performed several tests, and the results obtained with different values of <italic>k</italic> are given in <xref ref-type="fig" rid="btu441-F2">Figures 2</xref> and <xref ref-type="fig" rid="btu441-F3">3</xref>. For computational purposes, we decided to choose the smallest value for which the accuracy is maximal. As we can see in both <xref ref-type="fig" rid="btu441-F2">Figures 2</xref> and <xref ref-type="fig" rid="btu441-F3">3</xref>, the accuracy remains fairly stable from the value <italic>k</italic> = 4. Therefore, we chose the value <italic>k</italic> = 4 as the default value. In the case of Human, we have also made this choice to improve the specificity, which is low with the other two kernels. As we can see in <xref ref-type="fig" rid="btu441-F2">Figure 2</xref>, the specificity is higher than the sensitivity from <inline-formula><mml:math id="I14"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02243;</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="I15"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02243;</mml:mo><mml:mn>17</mml:mn></mml:mrow></mml:math></inline-formula> and is lower than the sensitivity from <inline-formula><mml:math id="I16"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02243;</mml:mo><mml:mn>27</mml:mn></mml:mrow></mml:math></inline-formula>. In the case of <italic>Drosophila</italic>, the four measures are fairly stable for any value of <italic>k</italic>, from <italic>k</italic> = 4 (see <xref ref-type="fig" rid="btu441-F3">Figure 3</xref>).
<fig id="btu441-F2" position="float"><label>Fig. 2.</label><caption><p>Results obtained by the <italic>k</italic>-nearest neighbors kernel with different values of <italic>k</italic> on Human training datasets</p></caption><graphic xlink:href="btu441f2p"/></fig>
<fig id="btu441-F3" position="float"><label>Fig. 3.</label><caption><p>Results obtained by the <italic>k</italic>-nearest neighbors kernel with different values of <italic>k</italic> on <italic>Drosophila</italic> training datasets</p></caption><graphic xlink:href="btu441f3p"/></fig></p><p>This parameter is still tuned by the user, and other choices can be made depending on the features used and on the need to improve the sensitivity or the specificity.</p></sec></sec><sec><title>4 CONCLUSION</title><p>The present study aimed at the development of a novel algorithm for the identification of piRNA sequences. We propose a multiple kernel fusion and an SVM-based approach that allows to use heterogeneous features, each kernel implementing a class of features. Our approach is therefore modular, extensible and adaptive, allowing the implementation of new features or the use of more appropriate ones (depending on the species). In the context of piRNAs, which have not been studied as extensively as miRNAs, for instance, it is appreciable to be able to take into account new knowledge and discoveries on these RNAs.</p><p>Because of the lack of known conserved characteristics of piRNA sequences (except the occurrence of a uridine base at the first position) and structure (there is no known structure for piRNAs), their identification by computational methods is a difficult task. To our knowledge, only one computational method, based on k-mer motifs, has been reported in the literature for piRNA prediction (<xref rid="btu441-B31" ref-type="bibr">Zhang <italic>et al.</italic>, 2011</xref>). Two other methods have been reported, based on the characteristic of piRNAs to occur in clusters in the genome (<xref rid="btu441-B14" ref-type="bibr">Jung <italic>et al.</italic>, 2014</xref>; <xref rid="btu441-B22" ref-type="bibr">Rosenkranz and Zischler, 2012</xref>), which identify piRNA clusters from deep sequencing data.</p><p>In the present study, we have provided a few new elements. We have suggested and confirmed a new feature for piRNA identification, which is the distance to telomere/centromere regions, which was reported on <italic>Drosophila</italic> (<xref rid="btu441-B4" ref-type="bibr">Brennecke <italic>et al.</italic>, 2007</xref>; <xref rid="btu441-B19" ref-type="bibr">Le Thomas <italic>et al.</italic>, 2014</xref>). We then tested this feature in combination with previously published features in the context of a modular algorithm, and surprisingly, we were able to identify its utility not only in <italic>Drosophila</italic> but also in Human. Last, we provide a computational tool for piRNA identification that gives better results than the previously published Zhang <italic>et al.</italic> method (<xref rid="btu441-B31" ref-type="bibr">Zhang <italic>et al.</italic>, 2011</xref>).</p><p>One of our further perspectives is to continue our investigation by finding other characteristics of piRNAs that would allow us to define new kernels and thus to improve the prediction results. We plan, for instance, to consider a characteristic of piRNA clusters highlighted by a computational analysis performed in the mouse by <xref rid="btu441-B2" ref-type="bibr">Betel <italic>et al.</italic> (2013)</xref>, who suggest that 25% of piRNA clusters are bracketed by inverted repeats of varying length.</p><p>One of our other perspectives for improving our classification results is to perform the training step on all known piRNAs, i.e. on piRNA sequences of piRNABank, and to build kernels with all these sequences. For this classification problem with large training dataset, accuracy, training and testing speed and memory usage are the main concerns. One solution is to combine the SVM to a Nystr&#x000f6;m methods (<xref rid="btu441-B10" ref-type="bibr">Gittens and Mahoney, 2013</xref>; <xref rid="btu441-B30" ref-type="bibr">Zhang <italic>et al.</italic>, 2012</xref>) commonly used to obtain good-quality low-rank approximations of large kernel matrices.</p><p>In the present study, we have proposed a new <italic>k</italic>-nearest neighbors kernel, which represents the cluster structure in the training set. To improve the classification results, we will extend these cluster structure to the test set, using transductive or semi-supervised learning algorithms (<xref rid="btu441-B28" ref-type="bibr">Weston <italic>et al.</italic>, 2005</xref>). We can also use the labels of the neighbors by exploiting collective classification (<xref rid="btu441-B24" ref-type="bibr">Sen <italic>et al.</italic>, 2008</xref>) approaches.</p><p>Finally, in the present version of <italic>piRPred</italic>, the input is a set of sequences, with the position of each sequence in the genome, including the &#x02018;+&#x02019; or &#x02018;&#x02212;&#x02019; strand, the chromosome ID and the position on the chromosome. The algorithm returns 1 or 0 for each given sequence; 1 if it is predicted as a piRNA, 0 if not. We are currently working on an extension of the input and the output of our algorithm to (i) consider deep sequencing data as input and (ii) return clusters of piRNAs. Thanks to the kernel of <italic>k</italic>-nearest neighbors, building clusters that contain close piRNA sequences in the genome is feasible.</p><p><italic>Funding</italic>: This study was financially supported by the <funding-source>Association Fran&#x000e7;aise contre les Myopathies (AFM)</funding-source></p><p><italic>Conflict of Interest</italic>: none declared.</p></sec></body><back><ref-list><title>REFERENCES</title><ref id="btu441-B1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aravin</surname><given-names>A</given-names></name><etal/></person-group><article-title>A novel class of small RNAs bind to MILI protein in mouse testes</article-title><source>Nature</source><year>2006</year><volume>442</volume><fpage>203</fpage><lpage>207</lpage><pub-id pub-id-type="pmid">16751777</pub-id></element-citation></ref><ref id="btu441-B2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Betel</surname><given-names>D</given-names></name><etal/></person-group><article-title>Computational analysis of mouse piRNA sequence and biogenesis</article-title><source>Cancer Lett.</source><year>2013</year><volume>336</volume><fpage>46</fpage><lpage>52</lpage><pub-id pub-id-type="pmid">23603435</pub-id></element-citation></ref><ref id="btu441-B3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Birgin</surname><given-names>EG</given-names></name><etal/></person-group><article-title>Nonmonotone spectral projected gradient methods on convex sets</article-title><source>SIAM J. Optim.</source><year>2000</year><volume>10</volume><issue>4</issue><fpage>1196</fpage><lpage>1211</lpage></element-citation></ref><ref id="btu441-B4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brennecke</surname><given-names>J</given-names></name><etal/></person-group><article-title>Discrete small RNA-generating loci as master regulators of transposon activity in <italic>Drosophila</italic></article-title><source>Cell</source><year>2007</year><volume>128</volume><fpage>1089</fpage><lpage>1103</lpage><pub-id pub-id-type="pmid">17346786</pub-id></element-citation></ref><ref id="btu441-B5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carmell</surname><given-names>M</given-names></name><etal/></person-group><article-title>MIWI2 is essential for spermatogenesis and repression of transposons in the mouse male germline</article-title><source>Cell</source><year>2007</year><volume>12</volume><fpage>503</fpage><lpage>514</lpage></element-citation></ref><ref id="btu441-B6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>C-C</given-names></name><name><surname>Lin</surname><given-names>C-J</given-names></name></person-group><article-title>LIBSVM: a library for support vector machines</article-title><source>ACM Trans. Intell. Syst. Technol.</source><year>2011</year><volume>2</volume><fpage>1</fpage><lpage>27</lpage></element-citation></ref><ref id="btu441-B7"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cortes</surname><given-names>C</given-names></name><etal/></person-group><person-group person-group-type="editor"><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Schuurmans</surname><given-names>D</given-names></name></person-group><article-title>Learning non-linear combinations of kernels</article-title><source>Advances in Neural Information Processing Systems (NIPS) 22</source><year>2009</year><fpage>396</fpage><lpage>404</lpage></element-citation></ref><ref id="btu441-B8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>W</given-names></name><name><surname>Lin</surname><given-names>H</given-names></name></person-group><article-title>miwi, a murine homolog of piwi, encodes a cytoplasmic protein essential for spermatogenesis</article-title><source>Dev. Cell</source><year>2002</year><volume>2</volume><fpage>819</fpage><lpage>830</lpage><pub-id pub-id-type="pmid">12062093</pub-id></element-citation></ref><ref id="btu441-B9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Girard</surname><given-names>A</given-names></name><etal/></person-group><article-title>A germline-specific class of small RNAs binds mammalian Piwi proteins</article-title><source>Nature</source><year>2006</year><volume>442</volume><fpage>199</fpage><lpage>202</lpage><pub-id pub-id-type="pmid">16751776</pub-id></element-citation></ref><ref id="btu441-B10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gittens</surname><given-names>A</given-names></name><name><surname>Mahoney</surname><given-names>MW</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Dasgupta</surname><given-names>S</given-names></name><name><surname>Mcallester</surname><given-names>D</given-names></name></person-group><article-title>Revisiting the Nystrom method for improved large-scale machine learning</article-title><source>Proceedings of the 30th International Conference on Machine Learning (ICML-13)</source><year>2013</year><volume>Vol. 28</volume><publisher-name>JMLR Workshop and Conference Proceedings</publisher-name><fpage>567</fpage><lpage>575</lpage></element-citation></ref><ref id="btu441-B11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>G&#x000f6;nen</surname><given-names>M</given-names></name><name><surname>Alpayd</surname><given-names>E</given-names></name></person-group><article-title>Multiple kernel learning algorithms</article-title><source>J. Mach. Learn. Res.</source><year>2011</year><volume>12</volume><fpage>2211</fpage><lpage>2268</lpage></element-citation></ref><ref id="btu441-B12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hsu</surname><given-names>C-W</given-names></name><name><surname>Lin</surname><given-names>C-J</given-names></name></person-group><article-title>A comparison of methods for multiclass support vector machines</article-title><source>Trans. Neur. Netw.</source><year>2002</year><volume>13</volume><fpage>415</fpage><lpage>425</lpage></element-citation></ref><ref id="btu441-B13"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jain</surname><given-names>A</given-names></name><etal/></person-group><article-title>SPF-GMKL: generalized multiple kernel learning with a million kernels</article-title><source>Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</source><year>2012</year><comment>KDD&#x02019;12, ACM, New York, NY, USA, pp 750&#x02013;758</comment></element-citation></ref><ref id="btu441-B14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jung</surname><given-names>I</given-names></name><etal/></person-group><article-title>piClust: a density based piRNA clustering algorithm</article-title><source>Comput. Biol. Chem.</source><year>2014</year><volume>50</volume><fpage>60</fpage><lpage>67</lpage><pub-id pub-id-type="pmid">24656595</pub-id></element-citation></ref><ref id="btu441-B15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuramochi-Miyagawa</surname><given-names>S</given-names></name><etal/></person-group><article-title>Mili, a mammalian member of piwi family gene, is essential for spermatogenesis</article-title><source>Developmental</source><year>2004</year><volume>131</volume><fpage>839</fpage><lpage>849</lpage></element-citation></ref><ref id="btu441-B16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lakshmi</surname><given-names>SS</given-names></name><name><surname>Agrawal</surname><given-names>S</given-names></name></person-group><article-title>piRNABank: a web resource on classified and clustered Piwi-interacting RNAs</article-title><source>Nucleic Acids Res.</source><year>2008</year><volume>36</volume><fpage>D173</fpage><lpage>D177</lpage><pub-id pub-id-type="pmid">17881367</pub-id></element-citation></ref><ref id="btu441-B17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lanckriet</surname><given-names>GRG</given-names></name><etal/></person-group><article-title>Learning the kernel matrix with semidefinite programming</article-title><source>J. Mach. Learn. Res.</source><year>2004</year><volume>5</volume><fpage>27</fpage><lpage>72</lpage></element-citation></ref><ref id="btu441-B18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>N</given-names></name><etal/></person-group><article-title>Characterization of the piRNA complex from rat testes</article-title><source>Science</source><year>2006</year><volume>313</volume><fpage>363</fpage><lpage>367</lpage><pub-id pub-id-type="pmid">16778019</pub-id></element-citation></ref><ref id="btu441-B19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le Thomas</surname><given-names>A</given-names></name><etal/></person-group><article-title>To be or not to be a piRNA: genomic origin and processing of piRNAs</article-title><source>Genome Biol.</source><year>2014</year><volume>15</volume><fpage>204</fpage><pub-id pub-id-type="pmid">24467990</pub-id></element-citation></ref><ref id="btu441-B20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mei</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Novel dimensions of pirnas in cancer</article-title><source>Cancer Lett.</source><year>2013</year><volume>336</volume><fpage>46</fpage><lpage>52</lpage><pub-id pub-id-type="pmid">23603435</pub-id></element-citation></ref><ref id="btu441-B21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>J</given-names></name><name><surname>Lin</surname><given-names>H</given-names></name></person-group><article-title>Beyond transposons: the epigenetic and somatic functions of the Piwi-piRNA mechanism</article-title><source>Curr. Opin. Cell Biol.</source><year>2013</year><volume>25</volume><fpage>190</fpage><lpage>194</lpage><pub-id pub-id-type="pmid">23465540</pub-id></element-citation></ref><ref id="btu441-B22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenkranz</surname><given-names>D</given-names></name><name><surname>Zischler</surname><given-names>H</given-names></name></person-group><article-title>proTRAC&#x02013;a software for probabilistic piRNA cluster detection, visualization and analysis</article-title><source>BMC Bioinformatics</source><year>2012</year><volume>13</volume><fpage>5</fpage><pub-id pub-id-type="pmid">22233380</pub-id></element-citation></ref><ref id="btu441-B23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ross</surname><given-names>R</given-names></name><etal/></person-group><article-title>PIWI proteins and PIWI-interacting RNAs in the soma</article-title><source>Nature</source><year>2014</year><volume>505</volume><fpage>353</fpage><lpage>359</lpage><pub-id pub-id-type="pmid">24429634</pub-id></element-citation></ref><ref id="btu441-B24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sen</surname><given-names>P</given-names></name><etal/></person-group><article-title>Collective classification in network data</article-title><source>AI Magazine</source><year>2008</year><volume>29</volume><fpage>93</fpage><lpage>106</lpage></element-citation></ref><ref id="btu441-B25"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vapnik</surname><given-names>VN</given-names></name></person-group><source>The Nature of Statistical Learning Theory</source><year>1995</year><publisher-loc>New York, NY, USA</publisher-loc><publisher-name>Springer-Verlag</publisher-name></element-citation></ref><ref id="btu441-B26"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Varma</surname><given-names>M</given-names></name><name><surname>Babu</surname><given-names>BR</given-names></name></person-group><article-title>More generality in efficient multiple kernel learning</article-title><source>Proceedings of the 26th Annual International Conference on Machine Learning</source><year>2009</year><comment>ICML&#x02019;09, ACM, New York, NY, USA, pp 1065&#x02013;1072</comment></element-citation></ref><ref id="btu441-B27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watanabe</surname><given-names>T</given-names></name><etal/></person-group><article-title>Identification and characterization of two novel classes of small RNAs in the mouse germline: retrotransposon-derived siRNAs in oocytes and germline small RNAs in testes</article-title><source>Genes Dev.</source><year>2006</year><volume>20</volume><fpage>1732</fpage><lpage>1743</lpage><pub-id pub-id-type="pmid">16766679</pub-id></element-citation></ref><ref id="btu441-B28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weston</surname><given-names>J</given-names></name><etal/></person-group><article-title>Semi-supervised protein classification using cluster kernels</article-title><source>Bioinformatics</source><year>2005</year><volume>21</volume><fpage>3241</fpage><lpage>3247</lpage><pub-id pub-id-type="pmid">15905279</pub-id></element-citation></ref><ref id="btu441-B29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>K-P</given-names></name><name><surname>Wang</surname><given-names>S-D</given-names></name></person-group><article-title>Choosing the kernel parameters for support vector machines by the inter-cluster distance in the feature space</article-title><source>Pattern Recognit.</source><year>2009</year><volume>42</volume><fpage>710</fpage><lpage>717</lpage></element-citation></ref><ref id="btu441-B30"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>K</given-names></name><etal/></person-group><person-group person-group-type="editor"><name><surname>Lawrence</surname><given-names>ND</given-names></name><name><surname>Girolami</surname><given-names>M</given-names></name></person-group><article-title>Scaling up kernel SVM on limited resources: a low-rank linearization approach</article-title><source>AISTATS of JMLR Proceedings</source><year>2012</year><volume>Vol. 22</volume><fpage>1425</fpage><lpage>1434</lpage><comment><ext-link ext-link-type="uri" xlink:href="http://JMLR.org">http://JMLR.org</ext-link> (30 July 2014, date last accessed)</comment></element-citation></ref><ref id="btu441-B31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y</given-names></name><etal/></person-group><article-title>A k-mer scheme to predict piRNAs and characterize locust piRNAs</article-title><source>Bioinformatics</source><year>2011</year><volume>27</volume><fpage>771</fpage><lpage>776</lpage><pub-id pub-id-type="pmid">21224287</pub-id></element-citation></ref></ref-list></back></article>