<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.2.0//EN//XML?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName art520.dtd?><?SourceDTD.Version 5.2.0?><?ConverterInfo.XSLTName elsevier2nlmx2.xsl?><?ConverterInfo.Version 2?><?origin publisher?><?FILEmeta_CSBJ40 xml ?><?FILEmain xml ?><?FILEmain pdf ?><?FILEgr1 jpg ?><?FILEgr2 jpg ?><?FILEgr3 jpg ?><?FILEgr4 jpg ?><?FILEgr5 jpg ?><?FILEgr6 jpg ?><?FILEgr7 jpg ?><?FILEgr8 jpg ?><?FILEmmc1 zip ?><?FILEmmc2 docx ?><?FILEmmc3 docx ?><?FILEmmc4 docx ?><?FILEmmc5 xlsx ?><?FILEmmc6 xlsx ?><?FILEmmc7 xlsx ?><?FILEmmc8 xlsx ?><front><journal-meta><journal-id journal-id-type="nlm-ta">Comput Struct Biotechnol J</journal-id><journal-id journal-id-type="iso-abbrev">Comput Struct Biotechnol J</journal-id><journal-title-group><journal-title>Computational and Structural Biotechnology Journal</journal-title></journal-title-group><issn pub-type="epub">2001-0370</issn><publisher><publisher-name>Research Network of Computational and Structural Biotechnology</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">4720014</article-id><article-id pub-id-type="publisher-id">S2001-0370(14)00042-7</article-id><article-id pub-id-type="doi">10.1016/j.csbj.2014.11.001</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>A case study for cloud based high throughput analysis of NGS data using the globus genomics system</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Bhuvaneshwar</surname><given-names>Krithika</given-names></name><xref rid="af0005" ref-type="aff">a</xref></contrib><contrib contrib-type="author"><name><surname>Sulakhe</surname><given-names>Dinanath</given-names></name><xref rid="af0010" ref-type="aff">b</xref><xref rid="af0015" ref-type="aff">c</xref></contrib><contrib contrib-type="author"><name><surname>Gauba</surname><given-names>Robinder</given-names></name><xref rid="af0005" ref-type="aff">a</xref></contrib><contrib contrib-type="author"><name><surname>Rodriguez</surname><given-names>Alex</given-names></name><xref rid="af0010" ref-type="aff">b</xref></contrib><contrib contrib-type="author"><name><surname>Madduri</surname><given-names>Ravi</given-names></name><xref rid="af0010" ref-type="aff">b</xref><xref rid="af0015" ref-type="aff">c</xref></contrib><contrib contrib-type="author"><name><surname>Dave</surname><given-names>Utpal</given-names></name><xref rid="af0010" ref-type="aff">b</xref><xref rid="af0015" ref-type="aff">c</xref></contrib><contrib contrib-type="author"><name><surname>Lacinski</surname><given-names>Lukasz</given-names></name><xref rid="af0010" ref-type="aff">b</xref><xref rid="af0015" ref-type="aff">c</xref></contrib><contrib contrib-type="author"><name><surname>Foster</surname><given-names>Ian</given-names></name><xref rid="af0010" ref-type="aff">b</xref><xref rid="af0015" ref-type="aff">c</xref></contrib><contrib contrib-type="author"><name><surname>Gusev</surname><given-names>Yuriy</given-names></name><xref rid="af0005" ref-type="aff">a</xref></contrib><contrib contrib-type="author"><name><surname>Madhavan</surname><given-names>Subha</given-names></name><email>sm696@georgetown.edu</email><xref rid="af0005" ref-type="aff">a</xref><xref rid="cr0005" ref-type="corresp">&#x0204e;</xref></contrib></contrib-group><aff id="af0005"><label>a</label>Innovation Center for Biomedical Informatics (ICBI), Georgetown University, Washington, DC 20007, USA</aff><aff id="af0010"><label>b</label>Computation Institute, University of Chicago, Argonne National Laboratory, 60637, USA</aff><aff id="af0015"><label>c</label>Globus Genomics, USA</aff><author-notes><corresp id="cr0005"><label>&#x0204e;</label>Corresponding author at: Innovation Center for Biomedical Informatics (ICBI), Georgetown University Medical Center, 2115 Wisconsin Ave NW, Suite 110, Washington, DC 20007, USA. <email>sm696@georgetown.edu</email></corresp></author-notes><pub-date pub-type="pmc-release"><day>07</day><month>11</month><year>2014</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on <pub-date						pub-type="epub">.--><pub-date pub-type="collection"><year>2015</year></pub-date><pub-date pub-type="epub"><day>07</day><month>11</month><year>2014</year></pub-date><volume>13</volume><fpage>64</fpage><lpage>74</lpage><history><date date-type="received"><day>29</day><month>8</month><year>2014</year></date><date date-type="rev-recd"><day>31</day><month>10</month><year>2014</year></date><date date-type="accepted"><day>3</day><month>11</month><year>2014</year></date></history><permissions><copyright-statement>&#x000a9; 2014 Bhuvaneshwar et al. Published by Elsevier B.V. on behalf of the Research Network of Computational and Structural Biotechnology.</copyright-statement><copyright-year>2014</copyright-year><copyright-holder/><license license-type="CC BY" xlink:href="http://creativecommons.org/licenses/by/3.0/"><license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/3.0/).</license-p></license></permissions><abstract><p>Next generation sequencing (NGS) technologies produce massive amounts of data requiring a powerful computational infrastructure, high quality bioinformatics software, and skilled personnel to operate the tools. We present a case study of a practical solution to this data management and analysis challenge that simplifies terabyte scale data handling and provides advanced tools for NGS data analysis. These capabilities are implemented using the &#x0201c;Globus Genomics&#x0201d; system, which is an enhanced Galaxy workflow system made available as a service that offers users the capability to process and transfer data easily, reliably and quickly to address end-to-endNGS analysis requirements. The Globus Genomics system is built on Amazon&#x000a0;'s cloud computing infrastructure. The system takes advantage of elastic scaling of compute resources to run multiple workflows in parallel and it also helps meet the scale-out analysis needs of modern translational genomics research.</p></abstract><kwd-group><title>Keywords</title><kwd>Next generation sequencing</kwd><kwd>Galaxy</kwd><kwd>Cloud computing</kwd><kwd>Translational research</kwd></kwd-group></article-meta></front><body><sec id="s0005"><label>1</label><title>Introduction</title><sec id="s0010"><label>1.1</label><title>Background</title><p>The popularity of next generation sequencing (NGS) grew exponentially since 2007 due to faster, more accurate and affordable sequencing <xref rid="bb0005" ref-type="bibr">[1]</xref>. Initial studies were focused on comparing data and analysis results from NGS technologies with those from traditional polymerase chain reaction (PCR) and Sanger sequencing methods. Since then, we have come a long way in understanding how different it is from traditional methods and genome wide association studies (GWAS). The potential of NGS is now being tapped in a wide variety of applications including re-sequencing, functional genomics, translational research, and clinical genomics <xref rid="bb0010" ref-type="bibr">[2]</xref>, <xref rid="bb0015" ref-type="bibr">[3]</xref>.</p><p>Focusing on NGS applications for translational research, the most basic use cases involve comparison of two cohorts &#x02014; a case and control group with added complexity for longitudinal studies and meta-analyses. Such use cases require medium to large sample sizes, ranging from hundreds to thousands of samples, to be able to derive statistically significant results <xref rid="bb0020" ref-type="bibr">[4]</xref>. As these large-scale genomic studies become a reality, high throughput data storage, management and computation for large sample sizes are becoming increasingly challenging.</p><p>Current high performance computing (HPC) solutions in the genomics area involve clusters and grids, which are distributed systems targeted towards users who prefer a command line interface. These HPC solutions are not cheap because they require support and maintenance. University based clusters are shared resources with many competing users. To support maximum usage of these expensive clusters, the jobs are queued, and it becomes a buffer for managing IT capacity. For NGS applications that use medium to large sized samples, researchers would have to wait until enough resources become available; the time needed to complete processing becomes unpredictable. Users could potentially avoid queues by using grids, which are a collection of resources from different locations; but the cost of constructing a grid is high and its architecture and management is complex. Cloud computing leverages virtual technology to provide computational resources to users and this virtualization helps better utilize resources <xref rid="bb0025" ref-type="bibr">[5]</xref>. Its shared computing environment and pay-as-you-go storage can greatly benefit geographically dispersed teams working on the same dataset. There are a number of providers that offer cloud based solutions, some of them include Amazon <xref rid="bb0030" ref-type="bibr">[6]</xref>, Google <xref rid="bb0035" ref-type="bibr">[7]</xref>, and Microsoft <xref rid="bb0040" ref-type="bibr">[8]</xref>. The need for cloud computing for genomic analysis has been well-described by leaders in bioinformatics and computational biology <xref rid="bb0020" ref-type="bibr">[4]</xref>, <xref rid="bb0045" ref-type="bibr">[9]</xref>, <xref rid="bb0050" ref-type="bibr">[10]</xref> due to its flexibility, scalability and lower costs. This has been proven by the fact that many medical institutes and centers in the US and around the world have already embraced it <xref rid="bb0055" ref-type="bibr">[11]</xref>, <xref rid="bb0060" ref-type="bibr">[12]</xref>, <xref rid="bb0065" ref-type="bibr">[13]</xref>, <xref rid="bb0070" ref-type="bibr">[14]</xref>, <xref rid="bb0075" ref-type="bibr">[15]</xref>, <xref rid="bb0080" ref-type="bibr">[16]</xref>. NGS analyses are well-suited for the cloud since data upload (of input files) to an Amazon cloud instance does not incur any extra charge and data download (of output files) becomes relatively inexpensive as only a small percentage of output is needed for downstream analysis <xref rid="bb0085" ref-type="bibr">[17]</xref>, <xref rid="bb0090" ref-type="bibr">[18]</xref>. There are several cloud service models: (a)Infrastructure as a service (IaaS) offers compute, storage and network resources as a service, (b)Platform as a service (PaaS) that runs applications on the cloud and hides infrastructure implementation details from the user, and (c)Software as a service (SaaS) that provides software and databases as a service. SaaS eliminates the need to install and maintain the software. It also allows users to run HPCprograms on the cloud through graphical interfaces, and may be a promising solution for NGS analysis for biologists and researchers <xref rid="bb0025" ref-type="bibr">[5]</xref>, <xref rid="bb0095" ref-type="bibr">[19]</xref>.</p><p>While a few large genomics sequencing centers such as the National Institutes of Health (NIH) and major academic centers have developed custom solutions relying on significant investment in local computation infrastructure, an increasing number of universities and academic institutions across the US are facing challenges due to increasing interest and demand from researchers to utilize NGS technology. These small to medium size biomedical research entities neither have the capabilities to implement local computing infrastructures, nor are they able to rapidly expand their capabilities depending on sequencing data management needs. Additionally, there is an increasingly urgent need for adequate software support and management systems capable of providing reliable and scalable support for the ever-increasing influxof NGS data. Some academic centers have been developing customized software solutions, which are often coupled with commercial computing infrastructures such as Mercury <xref rid="bb0100" ref-type="bibr">[20]</xref> utilizing Amazon Web Services cloud via the DNAnexus <xref rid="bb0105" ref-type="bibr">[21]</xref> platform. However there is clearly a lack of standardized and affordable NGS management solutions on the cloud to support the growing needs of translational genomics research.</p></sec><sec id="s0015"><label>1.2</label><title>Existing commercial and non-commercial solutions</title><p>Before choosing the Globus Genomics system <xref rid="bb0110" ref-type="bibr">[22]</xref> for our case study, we briefly explored various commercial systems that offer solutions including Partek <xref rid="bb0115" ref-type="bibr">[23]</xref>, DNAnexus <xref rid="bb0105" ref-type="bibr">[21]</xref>, CLC Bio <xref rid="bb0120" ref-type="bibr">[24]</xref>, DNASTAR<xref rid="bb0125" ref-type="bibr">[25]</xref>, Maverix Biomics <xref rid="bb0130" ref-type="bibr">[26]</xref>, Seven Bridges <xref rid="bb0135" ref-type="bibr">[27]</xref> and Golden Helix <xref rid="bb0140" ref-type="bibr">[28]</xref>. At the time we explored these commercial tools, only a few of these systems had cloud based solutions for large scale batch processing and such solutions were too expensive for an academic center to adopt. Galaxy, however is an open source web based platform for bioinformatics analysis <xref rid="bb0145" ref-type="bibr">[29]</xref>, <xref rid="bb0150" ref-type="bibr">[30]</xref>. It provides users with an easy-to-use web interface that allows users to create complex biological workflows by simply dragging-and-dropping tools into its &#x0201c;workflow canvas&#x0201d;. The settings and parameters for each tool can be customized by the user. After upload of data, the workflow gets submitted to their backend analysis server. The completed analysis results can be viewed, published (made public), or shared with other users. Galaxy has an expanding repository of tools in its &#x0201c;Tool Shed&#x0201d; <xref rid="bb0155" ref-type="bibr">[31]</xref>. It provides an extensible framework and allows many software tools to be integrated into the platform. An active community of developers ensures that the latest tools are available through the Galaxy Tool Shed. The biggest advantage of the Galaxy framework is that it automatically and transparently tracks analysis details, and allows results to be documented, downloaded, shared, and published with complete provenance, guaranteeing transparency and reproducibility.</p><p>A public Galaxy instance operated by Penn State University <xref rid="bb0160" ref-type="bibr">[32]</xref> allows thousands of users to perform hundreds of thousands of analyses each month. This is a great solution for biologists analyzing small genomes, but the free public resource has data transfer and compute usage limits and hence is not suitable for large datasets. A CloudMan framework helps researchers run their own Galaxy server on a cloud infrastructure <xref rid="bb0165" ref-type="bibr">[33]</xref>. However, CloudMan still requires users to understand the operating complexities of cloud computing, an expertise that most researchers lack. Although Galaxy is easy to use, it has data upload, storage and data manipulation bottlenecks, especially for large datasets. It can analyze only sample at a time, and does not take complete advantage of the elastic cloud compute capabilities (<xref rid="ec0005" ref-type="supplementary-material">Supplementary File 1a</xref>, <xref rid="f0040" ref-type="fig">Supplementary File 1b</xref>). This limitation of Galaxy is due to its dependence on a single shared file system. When processing large datasets across distributed compute resources, this limitation represents a significant bottleneck <xref rid="bb0110" ref-type="bibr">[22]</xref>.</p></sec><sec id="s0020"><label>1.3</label><title>Motivation</title><p>This paper presents a case study for using a cloud based computational environment for the processing and analysis of terabyte scale NGS data. The paper is designed to provide guidance to the users ofNGS analysis software on how to address the scalability and reproducibility issues with the existing NGS pipelines when dealing with very large volumes of translational research data.</p><p>Analyzing whole genome, exome, or transcriptome sequencing datafor a large number of human subjects samples requires the ability to transfer data from multiple samples into the analysis system (batchprocessing) and run them simultaneously (parallel processing) so as to complete the analysis in a few hours as opposed to days or weeks on a compute-intensive resource that could scale elastically (i.e.,increasing and decreasing compute capacity in response to changing demand). The Globus Genomics system has these necessary features designed for AWS, and is the focus of this case study.</p><p>This case study covers an Amazon cloud based data management software solution for next generation sequencing using the Globus Genomics architecture, which extends the existing Galaxy workflow system to overcome the barrier of scalability. We present three NGS workflows to illustrate the data management and sharing capabilities of the Globus Genomics system, and the novel cloud scheduling architecture that can scale analyses elastically across a dynamic pool of cloud nodes. The NGS workflows involve medium to large scale genomics data presented through the Globus Genomics architecture; providing a fast and scalable solution for pre-processing, analysis, andsharing of large NGS data sets typical for translational genomics projects.</p><p>The Globus Genomics system was developed at the Computation Institute, University of Chicago.The Innovation Center for Biomedical informatics (ICBI) at Georgetown University has collaborated with the Globus Genomics team on a pilot project to develop and test several NGS workflows and has summarized our experiences in this paper.</p></sec></sec><sec id="s0025"><label>2</label><title>Methods</title><sec id="s0030"><label>2.1</label><title>The globus genomics system overview</title><p>The Globus Genomics system is a data management and analysis platform built on top of the Galaxy platform to take advantage of Galaxy's best features, and overcome Galaxy's data transfer, storage and data manipulation bottlenecks and limitations. It also provides additional features such as faster computation times, advanced data security, and support and maintenance of the system. It is offered as a Software as a service (SaaS) that eliminates the need to install and maintain the software, and allows users to run HPC workflows on the cloud through graphical interfaces; so users don't have to worry about any operating complexities <xref rid="bb0110" ref-type="bibr">[22]</xref>, <xref rid="bb0170" ref-type="bibr">[34]</xref>. By leveraging Galaxy, which is an existing, functional platform with multiple users in the translational research community, the Globus Genomics system maximizes the use of existing capabilities while adding multiple new features that will enable a wider community use, not just for NGS analysis but all other types of datasets as well. <xref rid="f0005" ref-type="fig">Fig.&#x000a0;1</xref> shows a summary of architecture diagram of the system.</p><sec id="s0035"><label>2.1.1</label><title>How the globus genomics system provides faster computation times</title><p>The Globus Genomics system is implemented using Amazon's cloud computing infrastructure. One of the important features of the system is the optimization for selecting the right instance types for the analytical tools. An Amazon web services (AWS) instance type comprises varying combinations of multi-core processors, memory, storage, and networking capacity <xref rid="bb0175" ref-type="bibr">[35]</xref>, <xref rid="bb0180" ref-type="bibr">[36]</xref>.</p><p>As part of the managed service, the Globus Genomics team creates computational profiles for various analytical tools used within the platform to ensure optimal and efficient execution on the AWS. When any new tool is added to the platform, all the critical details required for best performance of the tool, such as the number of compute coresand memory requirements, are collected and documented as a computational profile for that tool. For example, for BWA alignment tool <xref rid="bb0185" ref-type="bibr">[37]</xref>, a compute instance with 16 cores and 32&#x000a0;GB RAM was found to provide best performance for the tool. These computational profiles are used to dynamically launch appropriate compute nodes (AWS Spot instances <xref rid="bb0190" ref-type="bibr">[38]</xref>) for a given analytical tool thus making sure the node can run the tool efficiently and within the best possible execution time.</p><p>The system takes advantage of elastic scaling of compute clusters using Amazon (Elastic Compute Cloud) EC2 <xref rid="bb0125" ref-type="bibr">[25]</xref>. Elastic scaling refers to the automatic scaling up or down of compute resources based on demand and pre-defined conditions to maximize performance, and minimize costs <xref rid="bb0195" ref-type="bibr">[39]</xref>. The Globus Genomics system provides parallelism at the workflow level, such that multiple workflows can be submitted in parallel, and new compute resources are added to the pool on demand. It also allows tools to use multi-threaded parallelism by launching the appropriate multi-core nodes as per the profile for that tool. The system uses HTCondor <xref rid="bb0130" ref-type="bibr">[26]</xref>, a queue based scheduler for efficient scheduling ofthese pipelines over many processors and can run multiple tasks simultaneously for faster computation <xref rid="bb0170" ref-type="bibr">[34]</xref>, <xref rid="bb0200" ref-type="bibr">[40]</xref>.</p></sec><sec id="s0040"><label>2.1.2</label><title>How the globus genomics system provides improved data transfer capabilities</title><p>Efficient and reliable data transfer is a critical feature in handling large volumes of sequence data. In addition to data transfer, we need robust authentication and authorization mechanisms in place to ensure data security. In order to address these requirements, the Globus Genomics system is integrated with Globus Transfer <xref rid="bb0205" ref-type="bibr">[41]</xref> and Globus Nexus <xref rid="bb0210" ref-type="bibr">[42]</xref> services for transfer and identity and group management capabilities.</p><p>Globus Transfer is a service that provides high-performance and secure data transfer between endpoints. An &#x0201c;endpoint&#x0201d; refers to the point where data transfer occurs to and from the Globus Genomics system, and can be a local desktop, data center, external hard drive, or Amazon storage buckets (Amazon S3). Globus Transfer provides managed transfer capabilities (users don't have to wait and manage the transfers and the service provides automated fault recovery), tuning parameters to maximize bandwidth, managing security configurations, and notifications service for error and success <xref rid="bb0115" ref-type="bibr">[23]</xref>. In addition to thetransfers, it also provides sharing capability to share data in place without the overhead of moving data to the cloud. Within the Globus Genomics system, the Globus Transfer service has been integrated with Galaxy using the REpresentational State Transfer Application Programming Interface (REST API). This enables users to perform large-scale data transfers between remote source endpoints and the Amazon cloud where Galaxy is hosted.</p><p>The Globus Genomics system leverages the Globus Nexus' identity and group management services. Globus Nexus integration handles the authentication operations ensuring secure access to data. It provides Single Sign On (SSO) across the entire infrastructure and when transferring data to/from other endpoints thus allowing Globus Genomics users to sign in using their preferred identity. Globus Genomics also uses the groups within Globus Nexus to control access to a particular project's instance or to limit access to data, applications and workflows.</p><p>User authentication in the Globus Genomics system follows the typical OAuth2 workflow where by a user is redirected to authenticate using Globus Nexus (where they can use their preferred identity provider), and then the user is redirected back to the Globus Genomics instance with a limited time access token which is mapped to the Galaxy session and the Globus username. Thus users don't have to create new account with the Galaxy component and their Globus username is used across various components of the system (Transfer and Galaxy). This mapped information is used by Globus transfer service to perform data transfer on the user's behalf.</p><p>Globus Transfer leverages Globus GridFTP <xref rid="bb0215" ref-type="bibr">[43]</xref> an open source, standards-based <xref rid="bb0220" ref-type="bibr">[44]</xref> technology for reliable, high performance, secure data transfer; and its superiority over other technologies has been well-established <xref rid="bb0225" ref-type="bibr">[45]</xref>, <xref rid="bb0230" ref-type="bibr">[46]</xref>, <xref rid="bb0235" ref-type="bibr">[47]</xref>. <xref rid="ec0015" ref-type="supplementary-material">Supplementary File 2</xref> shows a performance comparison of a number of data transfer technologies done by the Globus Genomics team.</p><p>These Globus platform services are used by many large computing facilities including XSEDE<xref rid="bb0240" ref-type="bibr">[48]</xref>, KBase <xref rid="bb0245" ref-type="bibr">[49]</xref>, and other national centers including Semel Institute at UCLA,NYU Langone Medical Center, STAR Experiment at Brookhaven National Lab, University of Colorado, and NERSC (National Energy Research Scientific Computing Center) <xref rid="bb0250" ref-type="bibr">[50]</xref>. The 1000 Genomes project <xref rid="bb0255" ref-type="bibr">[51]</xref>, <xref rid="bb0260" ref-type="bibr">[52]</xref> and EBI's European Nucleotide Archive <xref rid="bb0265" ref-type="bibr">[53]</xref> now offer data download options using the Globus Transfer system. As of September 2014, there are about 25,000 Globus Platform users that have transferred about 1 billion files which is about 60PBs of data.</p></sec><sec id="s0045"><label>2.1.3</label><title>Additional features &#x02014; batch submission</title><p>For NGS applications for translational research, it becomes a necessity to be able to process batches of samples together. If the computational infrastructure, storage and data transfer capabilities are not powerful and fast enough, it may take many weeks or months to process NGS data. The Globus Genomics team has implemented a batch submission capability that allows users to submit large batches of samples for analysis in parallel.</p><p>Called the &#x0201c;batch submit&#x0201d; workflow, it has been implemented as a Galaxy tool within the Globus Genomics system and leverages Galaxy APIs to submit batches of input sequences. Users are required to complete a tab-delimited file template file for each analytical pipeline, where rows represent the different samples to be submitted and columns represent the parameters to be set at run-time. When &#x0201c;batch submit&#x0201d; is submitted, the desired workflow is executed on each sample in parallel. Using the computational profile, each tool in the workflow is optimized to run in the best available compute node (i.e. compute intensive jobs can be submitted to a multiple core node and memory intensive jobs can be executed on high RAM nodes). Thus, multiple samples can use multiple core nodes in parallel to efficiently execute the analysis. The tool also takes advantage of Galaxy's workflow tracking system, and once the batch is submitted successfully, users can track the analysis of each sample separately in its own history within Galaxy.</p><p>Another important feature of batch submission is that the data transfers can also be included as part of the workflows. Thus, there is no need to pre-stage the data and each run in the batch can transfer its own input and output data to and from a remote endpoint using Globus Transfer.</p><p>This combination of on-demand cloud computing resources and batch submission capabilities makes the Globus Genomics system a powerful platform for NGS data analysis at scale.</p></sec><sec id="s0050"><label>2.1.4</label><title>Maintenance and support</title><p>The Globus Genomics team has adopted a Software-As-A-Service SaaS <xref rid="bb0270" ref-type="bibr">[54]</xref> delivery model so that researchers can access sophisticated analysis functionality without requiring any software to be installed locally. All interaction with the software occurs through web browsers and APIs. This centrally deployed software is updated, operated and supported, a service provided by the Globus Genomics team.</p></sec><sec id="s0055"><label>2.1.5</label><title>Taking advantage of the galaxy platform for NGS analysis</title><p>The Globus Genomics system not only uses Galaxy's workflow and tracking system, but also its pipeline design tool where new pipelines can be designed by end users and deployed on the infrastructure. The Galaxy tool shed has a comprehensive collection of tools to be able to create a wide variety of workflows.</p><p>Upon request by a user, the Globus Genomics team can add tools that are not present in Galaxy's tool shed, so the user can take advantage of the latest tools without waiting for a new release of Galaxy. So wherenecessary, custom pipelines can be developed and deployed forscientists. Even though there is flexibility in creating one's own workflows, there is convenience and time saving in reusing already established public workflows.</p><p>ICBI has created and provided three ready-to-use common NGS workflows for a convenient and hassle free experience for the user without having to spend time creating workflows. These computational pipelines are widely used best practices for whole genome, whole exome and whole transcriptome data. Some well-known tools used in the best practices include Tophat <xref rid="bb0275" ref-type="bibr">[55]</xref>, Cufflinks <xref rid="bb0280" ref-type="bibr">[56]</xref>, RSEM<xref rid="bb0285" ref-type="bibr">[57]</xref>, GATK<xref rid="bb0290" ref-type="bibr">[58]</xref>, Samtools <xref rid="bb0295" ref-type="bibr">[59]</xref>, and others; many of which have been reviewed <xref rid="bb0300" ref-type="bibr">[60]</xref>, <xref rid="bb0305" ref-type="bibr">[61]</xref>. These standard workflows include data transfer of raw sequencing files into the system, alignment to genome, variant calling and other steps. The processed output files are variant calls or gene/isoform expression data that can be easily exported from the system and used for biological interpretation and drive hypothesis generation for personalized medicine research.</p><p>These workflows have been made public, and can be imported and shared within the Globus Genomics system. To demonstrate usability and efficiency, we ran these workflows on publicly available datasets, evaluated their performance and have made the results public.</p></sec></sec><sec id="s0060"><label>2.2</label><title>NGS analysis using the globus genomics system &#x02014; a case study</title><p>For a typical translational genomics project, DNA or mRNA extractedfrom multiple samples of blood/tissue is subjected to library preparation. The libraries will then undergo, for example, Illumina HiSeq sequencing, which outputs raw data in the form of fastq files. After an investigator obtains the raw sequencing files from the vendor or core lab, a number of processing steps are needed to get meaningful results for biological interpretation.</p><p>First, the user would have to manage the large amount of data that would arrive from the sequencing center via hard drives, FTP, or other means, which is a nontrivial task. Secondly, the user would have to determine the processing steps, tools, and the appropriate analysis workflow for a given data type. Even knowledgeable users who are familiar with Unix or Python would have to find a local cluster or a high performance computing environment that could handle such large data, install the tools required, and run the analysis. Depending on the sample sizes and computational power of a local machine, this process would take anywhere from a few days to weeks. And this does not include the time required to identify the appropriate set of tools, install the tools, write the necessary scripts to execute the target workflow and secure the level of resources needed for the eventual analysis. Both a novice or knowledgeable user may not want to bother with these implementation details for translational genomics research; a solution such as the Globus Genomics system can save significant time and cost.</p><p>In this case study, we ran the three readymade ICBI workflows for Whole exome sequencing (WES) data (b)Whole genome sequencing (WGS) data and (c)mRNA sequencing (RNA-seq) data on the Globus Genomics system on publicly available datasets, and evaluated their performance (cost, time and CPU). <xref rid="f0010" ref-type="fig">Fig.&#x000a0;2</xref> shows what is required of the user to run one of the ready-madeNGS workflows on the Globus Genomics system. Detailed steps are shown in <xref rid="ec0020" ref-type="supplementary-material">Supplementary File 3a</xref>.</p><p>The three analytical pipelines are: (a)Whole exome sequencing (WES) workflow (b)Whole genome sequencing (WGS) workflow and (c)mRNA sequencing (RNA-seq) workflow. These workflows are currently designed for Illumina HiSeq platforms. We are currently in the process of creating workflows for other platforms and other NGS data types.</p><sec id="s0065"><label>2.2.1</label><title>Whole Exome Wequencing (WES) and Whole Genome Sequencing (WGS) workflow</title><p>The workflow for pre-processing of WES and WGS is the same, the difference being that WES only sequences the exome region, while in WGS; the entire genome is sequenced as seen in the difference in size and content of the fastq files. (<xref rid="f0015" ref-type="fig">Fig.&#x000a0;3</xref>a shows a schematic block diagram of the workflow and <xref rid="f0015" ref-type="fig">Fig.&#x000a0;3</xref>b shows the same workflow created in the Globus Genomics system).</p><p>The fastq files are filtered based on quality using Sickle <xref rid="bb0310" ref-type="bibr">[62]</xref>. Sickle accepts gzipped fastq files as input and works effectively on paired end data for both WES and WGS data. The filtered output is aligned to a reference human genome using Bowtie2 <xref rid="bb0315" ref-type="bibr">[63]</xref>, an ultrafast, memory efficient short read aligner to create alignment files in BAM format. The BAM files are re-ordered and read groups are added using Picard <xref rid="bb0320" ref-type="bibr">[64]</xref>. PCR duplicates removed using Samtools <xref rid="bb0295" ref-type="bibr">[59]</xref>. Variants are called using Genome Analysis Toolkit (GATK) <xref rid="bb0290" ref-type="bibr">[58]</xref>. VCF-tools<xref rid="bb0325" ref-type="bibr">[65]</xref> are used toseparate the SNPs from the indels and produce two variant call format (VCF) files for each sample. These VCF files are small in size (MB range) and can be easily exported from the Globus system. Once exported, the VCF files can be used for further case&#x02013;control association tests that provide statistically significant variants, which can then be filtered to obtain a short list of non-synonymous, potentially deleterious markers. These variants can then be mapped to genomic regions and further aggregated at the levels of gene, pathways, and biological processes relevant to disease outcome.</p></sec><sec id="s0070"><label>2.2.2</label><title>Whole transcriptome sequencing (RNA-seq) workflow</title><p>For this workflow in the Globus Genomics system, RNAseq fastq files are pre-processed for quality checks using Sickle, and input to RSEM<xref rid="bb0285" ref-type="bibr">[57]</xref> a software package that uses Bowtie for alignment and estimates gene and isoform expression levels. <xref rid="f0020" ref-type="fig">Fig.&#x000a0;4</xref>a shows a schematic block diagram of the workflow and <xref rid="f0020" ref-type="fig">Fig.&#x000a0;4</xref>b shows the workflow in Globus Genomics. Variants are extracted from this data using Picard, GATK and VCF-tools as mentioned above in the form of VCF files. The advantage of variants extracted from RNA-seq data is that these have already undergone transcription and is a validation of variants from WGS data. The output of the workflow are the gene and isoform expression data and the VCF files which can be exported from the Globus system and further analyzed at the level of gene, pathways and biological processes relevant to disease outcome.</p><p>For the WES, WGS and RNA-seq workflows created for this case study, the downstream analyses steps have not been included; as the filtering and settings for downstream analysis may vary depending on the biological question in mind. Most of the downstream analysis steps can be added and executed by the user through the Galaxy interface of the Globus Genomics system.</p></sec></sec></sec><sec id="s0075"><label>3</label><title>Results</title><sec id="s0080"><label>3.1</label><title>Performance evaluation</title><sec id="s0085"><label>3.1.1</label><title>WES workflow performance</title><p>We ran the WES pipeline on a batch of 78 samples from a lung cancer study obtained from the European Bioinformatics Institute's Sequencing Read Archive (SRA) <xref rid="bb0330" ref-type="bibr">[66]</xref>, from which we downloaded the fastq files.</p><p>First, we executed the workflow on a single sample of average input size (6.5&#x000a0;GB compressed paired-end fastq files) to set the baseline, which completed in 4&#x000a0;h. Next, we executed the workflow on all samples, which ran in parallel and completed analysis in 40&#x000a0;h generating between 20&#x02013;120&#x000a0;GB of data per sample depending on the size of the fastq files. The actual execution time for the batch was about 10 times higher than running a single sample of average input size due to the I/O (disk usage for input/output files) bottlenecks. This bottleneck is introduced by the Galaxy component that requires a shared file system wherein all the jobs from multiple workflows that are run simultaneously need to read the input data from and write the intermediate outputs to the same shared file system <xref rid="bb0110" ref-type="bibr">[22]</xref>. Due to this high I/O nature of the analysis, the Globus Genomics team was able to determine that the servers being used were not optimal for this typeof analysis. They switched to a more I/O intensive node (e.g. h1.4x&#x000a0;large) and were able to reduce the total execution time for all 78 samples to about 12&#x000a0;h. The I/O intensive node uses provisioned I/O on the Elastic Block Storage (EBS) <xref rid="bb0335" ref-type="bibr">[67]</xref> when building the shared file system, which significantly improved the read/write performance. Each sample was analyzed in an average time of 10&#x000a0;h, which was closer to baseline. The input data totaled to about 400&#x000a0;GB, and the amount of data generated from running the pipeline was 2.7&#x000a0;TB. The total data handled by the system for this dataset was about 3.1&#x000a0;TB.</p><p><xref rid="f0025" ref-type="fig">Fig.&#x000a0;5</xref> shows summary of cost, time and total data generated for the analysis of 78 lung cancer samples through the exome-seq workflow executed on a single multi-core Amazon instance (non-optimal run). <xref rid="f0030" ref-type="fig">Fig.&#x000a0;6</xref> shows summary of cost, time and total data generated for the analysis of 78 lung cancer samples through the exome-seq workflow (optimal run). It shows improvement in CPU and execution time as compared to the non-optimal run. For both figures, we can see that larger input files (fastq files) generate larger intermediate and output sizes, which is typical for NGS analysis.</p><p><xref rid="ec0030" ref-type="supplementary-material">Supplementary File 4</xref>, <xref rid="ec0035" ref-type="supplementary-material">Supplementary File 5</xref>show run times for each sample in the batch job run (non I/O optimized and I/O optimized). It shows a large amount of data generated by intermediate files.</p></sec><sec id="s0090"><label>3.1.2</label><title>WGS workflow performance</title><p>To demonstrate this workflow, we ran the WGS workflow on a human breast cancer cell line dataset. We were unable to obtain fastq files for medium-large sized public WGS dataset on Illumina platform and hence chose this small dataset. This fastq file was of 80&#x000a0;GB size, it took 12&#x000a0;h to produce variants (VCF) files in a compute intensive cluster instance (cr1.8x&#x000a0;large). Details of run time for this sample is shown in <xref rid="ec0040" ref-type="supplementary-material">Supplementary File 6</xref>.</p></sec><sec id="s0095"><label>3.1.3</label><title>RNA-seq workflow performance</title><p>We ran this workflow on The Cancer Genome Atlas&#x000a0;' (TCGA's) ovarian cancer samples. We downloaded raw files from the Cancer Genomic Hub (CGhub) archive <xref rid="bb0340" ref-type="bibr">[68]</xref> and extracted fastq files from the raw files. This study has 25 samples in all, and we applied the workflow to 21 samples as 4 samples did not pass quality check. Each sample ran in parallel based on the settings in the computational profiles taking about 20&#x02013;22&#x000a0;h for each sample to generate expression files and variants, generating about 150&#x000a0;GB of data depending on size of fastq files. The intermediate files contribute the most to the overall size of data. The 21 samples were completed within 24&#x000a0;h from the time the first sample was submitted to the time the last sample completed. Overall, the input data totaled to about 480&#x000a0;GB, and the amount of data generated from running the pipeline is 2.9&#x000a0;TB. The total data the system handled for this dataset was about 3.2&#x000a0;TB.</p><p><xref rid="f0035" ref-type="fig">Fig.&#x000a0;7</xref> shows a summary of the RNA-seq analysis for the 21 samples. The Amazon spot instance <xref rid="bb0190" ref-type="bibr">[38]</xref> used for this run (cr1.8x&#x000a0;large instance) cost $0.34 per hour. <xref rid="ec0045" ref-type="supplementary-material">Supplementary file 7</xref> shows run time details for each sample in the batch run.</p><p>The graphs in <xref rid="f0025" ref-type="fig">Fig. 5</xref>, <xref rid="f0030" ref-type="fig">Fig. 6</xref>, <xref rid="f0035" ref-type="fig">Fig. 7</xref>show a linear relationship between the input size and data generated by the workflow, while for CPU time, workflow execution time with data transfer, and cost the relationship is non-linear. This is mostly due to heavy I/O utilization especially when multiple samples are written to the same disk space. As smaller samples get completed, the larger samples have less I/O issues and thus can be executed faster. This issue can be resolved by using a more I/O intensive node as previously explained.</p></sec></sec></sec><sec id="s0100"><label>4</label><title>Discussion</title><p>In a typical translational research setting a core genomics or a bioinformatics laboratory is facing the challenge of processing and analyzing a massive volume of next generation sequencing data in studies amounting hundreds of DNA or RNA samples. ICBI in collaboration with the Globus Genomics team has conducted a case study aimed at testing a data management solution by running fast, standard, scalable and reproducible bioinformatics pipelines on an enhanced Galaxy platform called the Globus Genomics system built on the Amazon cloud.</p><sec id="s0105"><label>4.1</label><title>User experience from case study</title><p>After running the case study at Georgetown ICBI, we found pros and cons with the Globus Genomics system. The main advantage was that the system was user friendly &#x02014; its user-interface is suitable for scientists who don't have programming experience. The system is especially suited for genomics cores that need to process medium to large volumes of NGS data in a short amount of time, and have to share the processed results with their respective clients. Other advantages of the system include (a)it was convenient to use since it's available on the web, we did not have to worry about updates and maintenance of system, (b)the upload of the file template into the system and batch execution for the analysis of 21 whole transcriptome files and 78 whole exome samples was not difficult, (c)we were able to track the progress in processing of each sample. The workflows could be run overnight without any supervision. Most samples completed processing overnight, which was very convenient as compared to non-cloud based systems.</p><p>We found the system to have bottlenecks as well. We had first tested the RNAseq workflow and then the Exome seq workflow. So when wescaled the analysis from 21 samples to 78 samples, we encountered I/O related issues mentioned previously. We learned that the Globus Genomics I/O becomes a bottleneck when multiple concurrent applications start accessing the same file system thus deteriorating the performance. As demonstrated in the results, using provisioned I/O on the EBS<xref rid="bb0335" ref-type="bibr">[67]</xref> when building the shared file system significantly improves the performance. While provisioned I/O can help scale the number of parallel jobs to a couple of hundred, there is a natural upper limit in the number of concurrent jobs that can be handled by the shared file system. The Globus Genomics team is currently working on better load balancing techniques and is working closely with engineers from AWS for larger scalability.</p><p>Researchers that have cited the Globus Genomics system include: the Cox lab <xref rid="bb0345" ref-type="bibr">[69]</xref> and Olopade lab <xref rid="bb0350" ref-type="bibr">[70]</xref> at University of Chicago, and the Dobyns lab at Seattle Children's Research Institute <xref rid="bb0355" ref-type="bibr">[71]</xref>. Other users ofthe system include Kansas University Medical Center <xref rid="bb0360" ref-type="bibr">[72]</xref>, Inova Translational Medicine Institute, and the Genome Sciences Institute atBoston University <xref rid="bb0365" ref-type="bibr">[73]</xref>. As of September 2014, there are about 20 institutions/research groups actively using the Globus Genomics platform.</p></sec><sec id="s0110"><label>4.2</label><title>Economics of running the analysis pipelines on the cloud</title><p>The Globus Genomics team has adopted a Software-As-A-Service SaaS <xref rid="bb0270" ref-type="bibr">[54]</xref> delivery model so that researchers can access sophisticated analysis functionality without requiring any software to be installed locally. Although this model offers cost savings over traditional approaches with multiple local software installations, some costs remain including running the service on Amazon Web Services (AWS), as well as providing any ongoing technical support.</p><p>To recover these types of costs, the Globus Genomics team hasadopted a subscription model, whereby users are charged for components of usage such as cloud compute and cloud storage as well as operational and technical support. Fortunately, with the continuous reduction in costs of cloud resources driven by economies of scale and gains in efficiency, public cloud infrastructure becomes increasingly cost effective and most importantly, provides the flexibility of on-demand resource scaling. Advantages for users include lower cost of development as only a single platform is supported, accelerated feature delivery, transparent and frequent software updates, subscription based licensing, pay-as-you-go usage, collaborative and social integration (theoption to publish and rate the workflows, so that other experts or users in the field can also rate these published workflows thus leading to best practices), and intuitive and easy to use interfaces for users.</p><p><xref rid="t0005" ref-type="table">Table&#x000a0;1</xref> shows actual costs for executing five workflows commonly used in NGS analysis using the Globus Genomics system. To minimize compute costs, the Globus Genomics team created computational profiles of the tools (as described earlier in the System Overview section) used in the analysis workflows and matched them with appropriate Amazon resources to achieve the best price/performance balance during workflow execution. The team also used spot instances <xref rid="bb0190" ref-type="bibr">[38]</xref> to scale-up to the required compute levels with the lowest cost resources.</p><p>The Globus Genomics team accounts for AWS storage costs mentioned in <xref rid="t0005" ref-type="table">Table&#x000a0;1</xref>. This allows storage of the computation results for a month, and also accounts for outbound I/O costs from moving the intermediate and final results from Amazon to local resources for downstream analysis or local archiving. While AWS charges for outbound I/O, users can transfer these intermediate and final results of analysis to their own S3 buckets or other AWS storage with no I/O costs, though they may have to pay for the actual storage itself.</p><p>At the end, 21 RNA seq samples ran in parallel (average input size 13.5&#x000a0;GB each paired-end set compressed) based on the settings in the computational profiles in about 20&#x02013;22&#x000a0;h. The total data handled by the system for this dataset was about 3.2&#x000a0;TB. 78 WES samples (average input size 5.5&#x000a0;GB each paired-end set compressed) completed execution on about 12&#x000a0;h. The total data handled by the system for this dataset wasabout 3.1&#x000a0;TB. One WGS cell line sample of 80&#x000a0;GB size completed execution in about 12&#x000a0;h. This will hopefully allow users to roughly predict the time required to complete the analysis given the workflow and size of data.</p><p>In summary, the Globus Genomics system achieves a high degree ofend-to-end automation that encompasses every stage of the data analysis lifecycle from initial data retrieval (from remote sequencing center or database by the Globus file transfer system) to on-demandresource acquisition (on Amazon EC2); specification, configuration, and reuse of multi-step processing pipelines (via Galaxy); and efficient scheduling of these pipelines over many processors (via the HTCondor scheduler <xref rid="bb0370" ref-type="bibr">[74]</xref>). The system allows researchers to perform rapid analysis of terabyte scale NGS datasets using just a web browser in a fully automated manner, with no software installation.</p></sec><sec id="s0115"><label>4.3</label><title>Conclusion and future work</title><p>The Globus Genomics architecture extends the existing Galaxy workflow system adding not only superior data management capabilities but also a novel cloud scheduling architecture that can scale analyses elastically across a dynamic pool of cloud nodes <xref rid="bb0110" ref-type="bibr">[22]</xref>.</p><p>We present three NGS workflows for medium to large scale genomic data in a Galaxy based system built on the cloud that executes these workflows across high performance compute systems. We believe that Globus Genomics is a valuable system that provides a hassle free and fast solution for pre-processing and analysis of large NGS data sets typical for translational genomics projects.</p><p>We hope to expand this system to support other NGS workflows and platforms in the future. The Globus Genomics team is also developing new features to enable cataloging of dynamic collections of data and metadata including provenance metadata. Another future direction is to provide sophisticated search capabilities to discover and analyze datasets based on user-defined and automatically extracted metadata.</p></sec></sec><sec id="s0120"><title>Funding</title><p>This work was supported by in part by the <funding-source id="gts0005">NHLBI</funding-source> grant for Globus Genomics: The Cardiovascular Research Grid [R24HL085343] and by the <funding-source id="gts0010">U.S. Department of Energy</funding-source> under contract [DE-AC02-06CH11357]. We are grateful to the generous support from Amazon, Inc., for Amazon Web Services credits that facilitated early experiments.</p></sec><sec id="s0125"><title>Data access</title><p>The results of the analysis shown in this paper can be viewed here: <ext-link ext-link-type="uri" xlink:href="http://icbi-georgetown.globusgenomics.org/" id="ir0180">http://icbi-georgetown.globusgenomics.org/</ext-link> using the following login details &#x02014; username: <ext-link ext-link-type="uri" xlink:href="mailto:testuser@test.com" id="ir0185">testuser@test.com</ext-link>, password: globus. It is a guest account, so users can anonymously access the workflows and analysis results. This is a static instance (not a demo instance) showing the results of the batch jobs run on exome-seq and RNA-seq data. Users can look into the history of each and sample and go through the output of each and every step in the workflow, to demonstrate the transparency, share-ability and reproducibility aspect of the system. Click on Shared Data &#x02014; Published Workflows to view the workflows demonstrated in this manuscript.Click on Shared Data &#x02014; Published Histories to view detailed analysis results from the WES and RNASeq batch runs.</p><p>The following are the supplementary data related to this article.<supplementary-material content-type="local-data" id="ec0005"><caption><title>Supplementary File 1a</title><p>Pros and Cons of using Galaxy (user feedback from Twitter).</p></caption><media xlink:href="mmc1.zip"/></supplementary-material><fig id="f0040"><label>Supplementary File 1b</label><caption><p>Pros and Cons of using Galaxy from online discussion.</p></caption><graphic xlink:href="gr8"/></fig><supplementary-material content-type="local-data" id="ec0015"><caption><title>Supplementary File 2</title><p>Performance comparison of GridFTP to Aspera and TCP.</p></caption><media xlink:href="mmc2.docx"/></supplementary-material><supplementary-material content-type="local-data" id="ec0020"><caption><title>Supplementary File 3a</title><p>How to run an NGS workflow inside the Globus Genomics system.</p></caption><media xlink:href="mmc3.docx"/></supplementary-material><supplementary-material content-type="local-data" id="ec0025"><caption><title>Supplementary File 3b</title><p>Example web page with instructions for batch submission.</p></caption><media xlink:href="mmc4.docx"/></supplementary-material><supplementary-material content-type="local-data" id="ec0030"><caption><title>Supplementary File 4</title><p>Per sample execution time for the analysis of 78 lung cancer samples through the exome-seq workflow (non I/O optimized).</p></caption><media xlink:href="mmc5.xlsx"/></supplementary-material><supplementary-material content-type="local-data" id="ec0035"><caption><title>Supplementary File 5</title><p>Per sample execution time for the analysis of 78 lung cancer samples through the exome-seq workflow (I/O optimized).</p></caption><media xlink:href="mmc6.xlsx"/></supplementary-material><supplementary-material content-type="local-data" id="ec0040"><caption><title>Supplementary File 6</title><p>Per sample execution time for the analysis of one sample through the WGS workflow.</p></caption><media xlink:href="mmc7.xlsx"/></supplementary-material><supplementary-material content-type="local-data" id="ec0045"><caption><title>Supplementary File 7</title><p>Per sample execution time for the analysis 21 TCGA samples through the RNA-Seq workflow.</p></caption><media xlink:href="mmc8.xlsx"/></supplementary-material></p></sec></body><back><ref-list><title>References</title><ref id="bb0005"><label>1</label><element-citation publication-type="journal" id="rf0005"><person-group person-group-type="author"><name><surname>Schuster</surname><given-names>S.C.</given-names></name></person-group><article-title>Next-generation sequencing transforms today's biology</article-title><source>Nat Methods</source><volume>5</volume><year>2008</year><fpage>16</fpage><lpage>18</lpage><pub-id pub-id-type="pmid">18165802</pub-id></element-citation></ref><ref id="bb0010"><label>2</label><element-citation publication-type="journal" id="rf0010"><person-group person-group-type="author"><name><surname>Koboldt</surname><given-names>D.C.</given-names></name><name><surname>Steinberg</surname><given-names>K.M.</given-names></name><name><surname>Larson</surname><given-names>D.E.</given-names></name><name><surname>Wilson</surname><given-names>R.K.</given-names></name><name><surname>Mardis</surname><given-names>E.R.</given-names></name></person-group><article-title>The next-generationsequencing revolution and its impact on genomics</article-title><source>Cell</source><volume>155</volume><year>2013</year><fpage>27</fpage><lpage>38</lpage><pub-id pub-id-type="pmid">24074859</pub-id></element-citation></ref><ref id="bb0015"><label>3</label><element-citation publication-type="journal" id="rf0015"><person-group person-group-type="author"><name><surname>Park</surname><given-names>J.Y.</given-names></name><name><surname>Kricka</surname><given-names>L.J.</given-names></name><name><surname>Fortina</surname><given-names>P.</given-names></name></person-group><article-title>Next-generation sequencing in the clinic</article-title><source>Nat Biotechnol</source><volume>31</volume><year>2013</year><fpage>990</fpage><lpage>992</lpage><pub-id pub-id-type="pmid">24213773</pub-id></element-citation></ref><ref id="bb0020"><label>4</label><element-citation publication-type="journal" id="rf0020"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>M.</given-names></name></person-group><article-title>Next-generation sequencing: adjusting to data overload</article-title><source>Nat Methods</source><volume>7</volume><year>2010</year><fpage>495</fpage><lpage>499</lpage></element-citation></ref><ref id="bb0025"><label>5</label><element-citation publication-type="journal" id="rf0025"><person-group person-group-type="author"><name><surname>Church</surname><given-names>P.</given-names></name><name><surname>Goscinski</surname><given-names>A.</given-names></name></person-group><article-title>A survey of cloud-based service computing solutions for mammalian genomics</article-title><source>IEEE Trans Serv Comput</source><volume>1&#x02013;1</volume><year>2014</year></element-citation></ref><ref id="bb0030"><label>6</label><element-citation publication-type="other" id="rf0135"><article-title>Amazon web services</article-title><ext-link ext-link-type="uri" xlink:href="http://aws.amazon.com/" id="ir0195">http://aws.amazon.com/</ext-link><year>June 30 2014</year></element-citation></ref><ref id="bb0035"><label>7</label><element-citation publication-type="other" id="rf0140"><article-title>Google cloud platform</article-title><ext-link ext-link-type="uri" xlink:href="https://cloud.google.com/" id="ir0200">https://cloud.google.com/</ext-link><year>Oct. 10 2014</year></element-citation></ref><ref id="bb0040"><label>8</label><element-citation publication-type="other" id="rf0145"><article-title>Microsoft Azure</article-title><ext-link ext-link-type="uri" xlink:href="https://azure.microsoft.com/en-us/" id="ir0205">https://azure.microsoft.com/en-us/</ext-link><year>Oct. 10 2014</year></element-citation></ref><ref id="bb0045"><label>9</label><element-citation publication-type="journal" id="rf0030"><person-group person-group-type="author"><name><surname>Stein</surname><given-names>L.D.</given-names></name></person-group><article-title>The case for cloud computing in genome informatics</article-title><source>Genome Biol</source><volume>11</volume><year>2010</year><fpage>207</fpage><pub-id pub-id-type="pmid">20441614</pub-id></element-citation></ref><ref id="bb0050"><label>10</label><element-citation publication-type="other" id="rf0150"><article-title>Answers to genome analysis may be in the clouds</article-title><ext-link ext-link-type="uri" xlink:href="http://www.genome.gov/27538886" id="ir0210">http://www.genome.gov/27538886</ext-link><year>Oct. 21 2014</year></element-citation></ref><ref id="bb0055"><label>11</label><element-citation publication-type="other" id="rf0155"><article-title>AWS case study &#x02014; Harvard Medical School</article-title><ext-link ext-link-type="uri" xlink:href="http://aws.amazon.com/solutions/case-studies/harvard/" id="ir0215">http://aws.amazon.com/solutions/case-studies/harvard/</ext-link><year>Oct. 8 2014</year></element-citation></ref><ref id="bb0060"><label>12</label><element-citation publication-type="other" id="rf0160"><article-title>AWS use case &#x02014; Genomic Medicine Institute, Seoul National University College of Medicine, Korea</article-title><ext-link ext-link-type="uri" xlink:href="http://aws.amazon.com/solutions/case-studies/gmi/" id="ir0220">http://aws.amazon.com/solutions/case-studies/gmi/</ext-link><year>Oct. 8 2014</year></element-citation></ref><ref id="bb0065"><label>13</label><element-citation publication-type="other" id="rf0165"><article-title>AWS case study &#x02014; Icahn School of Medicine at Mount Sinai</article-title><ext-link ext-link-type="uri" xlink:href="http://aws.amazon.com/solutions/case-studies/mt-sinai/" id="ir0225">http://aws.amazon.com/solutions/case-studies/mt-sinai/</ext-link><year>Oct. 8 2014</year></element-citation></ref><ref id="bb0070"><label>14</label><element-citation publication-type="other" id="rf0170"><article-title>AWS case study: New York University Langone Medical Center</article-title><ext-link ext-link-type="uri" xlink:href="http://aws.amazon.com/solutions/case-studies/new-york-university/" id="ir0230">http://aws.amazon.com/solutions/case-studies/new-york-university/</ext-link><year>Oct. 8 2014</year></element-citation></ref><ref id="bb0075"><label>15</label><element-citation publication-type="other" id="rf0175"><article-title>AWS case study: Penn State Biological Engineering Department</article-title><ext-link ext-link-type="uri" xlink:href="http://aws.amazon.com/solutions/case-studies/penn-state/" id="ir0235">http://aws.amazon.com/solutions/case-studies/penn-state/</ext-link><year>Oct. 8 2014</year></element-citation></ref><ref id="bb0080"><label>16</label><element-citation publication-type="other" id="rf0180"><article-title>AWS case study: University of California Berkeley AMP Lab's Genomics Research Project</article-title><ext-link ext-link-type="uri" xlink:href="http://aws.amazon.com/solutions/case-studies/university-of-california-berkeley-amp-lab-genomics-research/" id="ir0240">http://aws.amazon.com/solutions/case-studies/university-of-california-berkeley-amp-lab-genomics-research/</ext-link><year>Oct. 8 2014</year></element-citation></ref><ref id="bb0085"><label>17</label><element-citation publication-type="journal" id="rf0035"><person-group person-group-type="author"><name><surname>Dudley</surname><given-names>J.T.</given-names></name><name><surname>Pouliot</surname><given-names>Y.</given-names></name><name><surname>Chen</surname><given-names>R.</given-names></name><name><surname>Morgan</surname><given-names>A.A.</given-names></name><name><surname>Butte</surname><given-names>A.J.</given-names></name></person-group><article-title>Translational bioinformatics in the cloud: an affordable alternative</article-title><source>Genome Med</source><volume>2</volume><year>2010</year><fpage>51</fpage><pub-id pub-id-type="pmid">20691073</pub-id></element-citation></ref><ref id="bb0090"><label>18</label><element-citation publication-type="book" id="rf0185"><person-group person-group-type="author"><name><surname>Sulakhe</surname><given-names>D.</given-names></name><name><surname>Rodriguez</surname><given-names>A.</given-names></name><name><surname>Prozorovsky</surname><given-names>N.</given-names></name><name><surname>Kavthekar</surname><given-names>N.</given-names></name><name><surname>Madduri</surname><given-names>R.</given-names></name><name><surname>Parikh</surname><given-names>A.</given-names></name></person-group><chapter-title>Distributed tools deployment and management for multiple galaxy instances in globus, genomics</chapter-title><year>2013</year><fpage>106</fpage><lpage>111</lpage></element-citation></ref><ref id="bb0095"><label>19</label><element-citation publication-type="other" id="rf0190"><article-title>Cloud computing service models</article-title><ext-link ext-link-type="uri" xlink:href="http://en.wikipedia.org/wiki/Cloud_computing#Service_models" id="ir0245">http://en.wikipedia.org/wiki/Cloud_computing#Service_models</ext-link><year>Oct. 10 2014</year></element-citation></ref><ref id="bb0100"><label>20</label><element-citation publication-type="journal" id="rf0040"><person-group person-group-type="author"><name><surname>Reid</surname><given-names>J.G.</given-names></name><name><surname>Carroll</surname><given-names>A.</given-names></name><name><surname>Veeraraghavan</surname><given-names>N.</given-names></name><name><surname>Dahdouli</surname><given-names>M.</given-names></name><name><surname>Sundquist</surname><given-names>A.</given-names></name><name><surname>English</surname><given-names>A.</given-names></name></person-group><article-title>Launching genomics into the cloud: deployment of Mercury, a next generation sequence analysis pipeline</article-title><source>BMC Bioinforma</source><volume>15</volume><year>2014</year><fpage>30</fpage></element-citation></ref><ref id="bb0105"><label>21</label><element-citation publication-type="other" id="rf0195"><article-title>DNAnexus</article-title><ext-link ext-link-type="uri" xlink:href="https://www.dnanexus.com/" id="ir0250">https://www.dnanexus.com/</ext-link><year>June 30 2014</year></element-citation></ref><ref id="bb0110"><label>22</label><element-citation publication-type="book" id="rf0200"><person-group person-group-type="author"><name><surname>Madduri</surname><given-names>R.K.</given-names></name><name><surname>Sulakhe</surname><given-names>D.</given-names></name><name><surname>Lacinski</surname><given-names>L.</given-names></name><name><surname>Liu</surname><given-names>B.</given-names></name><name><surname>Rodriguez</surname><given-names>A.</given-names></name><name><surname>Chard</surname><given-names>K.</given-names></name></person-group><chapter-title>Experiences building Globus Genomics: a next-generation sequencing analysis service using Galaxy, Globus, and Amazon Web Services</chapter-title><year>2014</year><publisher-name>Concurrency and Computation: Practice and Experience: n/a-n/a</publisher-name></element-citation></ref><ref id="bb0115"><label>23</label><element-citation publication-type="other" id="rf0205"><article-title>Partek Flow for NGS Analysis</article-title><ext-link ext-link-type="uri" xlink:href="http://www.partek.com/" id="ir0255">http://www.partek.com/</ext-link><year>June 30 2014</year></element-citation></ref><ref id="bb0120"><label>24</label><element-citation publication-type="other" id="rf0210"><article-title>CLC Genomics Workbench</article-title><ext-link ext-link-type="uri" xlink:href="http://www.clcbio.com/products/clc-genomics-workbench/" id="ir0260">http://www.clcbio.com/products/clc-genomics-workbench/</ext-link><year>June 30 2014</year></element-citation></ref><ref id="bb0125"><label>25</label><element-citation publication-type="other" id="rf0215"><article-title>DNASTAR Lasergene Genomics Suite</article-title><ext-link ext-link-type="uri" xlink:href="http://www.dnastar.com/t-nextgenhome.aspx" id="ir0265">http://www.dnastar.com/t-nextgenhome.aspx</ext-link><year>June 30 2014</year></element-citation></ref><ref id="bb0130"><label>26</label><element-citation publication-type="other" id="rf0220"><article-title>Maverix Biomics</article-title><ext-link ext-link-type="uri" xlink:href="http://www.maverixbio.com/" id="ir0270">http://www.maverixbio.com/</ext-link><year>June 30 2014</year></element-citation></ref><ref id="bb0135"><label>27</label><element-citation publication-type="other" id="rf0225"><article-title>Seven Bridges Genomics</article-title><ext-link ext-link-type="uri" xlink:href="https://www.sbgenomics.com/" id="ir0275">https://www.sbgenomics.com/</ext-link><year>June 30 2014</year></element-citation></ref><ref id="bb0140"><label>28</label><element-citation publication-type="other" id="rf0230"><article-title>Golden Helix SNP &#x00026; Variation Suite 8</article-title><ext-link ext-link-type="uri" xlink:href="http://www.goldenhelix.com/SNP_Variation/index.html" id="ir0280">http://www.goldenhelix.com/SNP_Variation/index.html</ext-link><year>June 30 2014</year></element-citation></ref><ref id="bb0145"><label>29</label><element-citation publication-type="journal" id="rf0045"><person-group person-group-type="author"><name><surname>Blankenberg</surname><given-names>D.</given-names></name><name><surname>Gordon</surname><given-names>A.</given-names></name><name><surname>Von Kuster</surname><given-names>G.</given-names></name><name><surname>Coraor</surname><given-names>N.</given-names></name><name><surname>Taylor</surname><given-names>J.</given-names></name><name><surname>Nekrutenko</surname><given-names>A.</given-names></name></person-group><article-title>Manipulation of FASTQ data with Galaxy</article-title><source>Bioinformatics</source><volume>26</volume><year>2010</year><fpage>1783</fpage><lpage>1785</lpage><pub-id pub-id-type="pmid">20562416</pub-id></element-citation></ref><ref id="bb0150"><label>30</label><element-citation publication-type="journal" id="rf0050"><person-group person-group-type="author"><name><surname>Blankenberg</surname><given-names>D.</given-names></name><name><surname>Hillman-Jackson</surname><given-names>J.</given-names></name></person-group><article-title>Analysis of next-generation sequencing data using Galaxy</article-title><source>Methods Mol Biol</source><volume>1150</volume><year>2014</year><fpage>21</fpage><lpage>43</lpage><pub-id pub-id-type="pmid">24743989</pub-id></element-citation></ref><ref id="bb0155"><label>31</label><element-citation publication-type="other" id="rf0235"><article-title>Galaxy tool shed</article-title><ext-link ext-link-type="uri" xlink:href="https://wiki.galaxyproject.org/Toolshed" id="ir0285">https://wiki.galaxyproject.org/Toolshed</ext-link><year>June 30 2014</year></element-citation></ref><ref id="bb0160"><label>32</label><element-citation publication-type="other" id="rf0240"><article-title>Galaxy</article-title><ext-link ext-link-type="uri" xlink:href="https://usegalaxy.org/" id="ir0290">https://usegalaxy.org/</ext-link><year>June 30 2014</year></element-citation></ref><ref id="bb0165"><label>33</label><element-citation publication-type="journal" id="rf0245"><person-group person-group-type="author"><name><surname>Afgan</surname><given-names>E.</given-names></name><name><surname>Baker</surname><given-names>D.</given-names></name><name><surname>Coraor</surname><given-names>N.</given-names></name><name><surname>Chapman</surname><given-names>B.</given-names></name><name><surname>Nekrutenko</surname><given-names>A.</given-names></name></person-group><article-title>Galaxy CloudMan: delivering cloud compute clusters</article-title><source>BMC Bioinforma</source><volume>11</volume><issue>Suppl. 12</issue><year>2010</year><fpage>S4</fpage></element-citation></ref><ref id="bb0170"><label>34</label><element-citation publication-type="book" id="rf0250"><person-group person-group-type="author"><name><surname>Madduri</surname><given-names>Ravi K.</given-names></name><name><surname>Dave</surname><given-names>Paul</given-names></name><name><surname>Sulakhe</surname><given-names>Dinnanath</given-names></name><name><surname>Lacinski</surname><given-names>Lukasz</given-names></name><name><surname>Liu</surname><given-names>Bo</given-names></name><name><surname>Foster</surname><given-names>Ian T.</given-names></name></person-group><chapter-title>Experiences in building a next-generation sequencing analysis service using galaxy, globus online and Amazon web service</chapter-title><year>2013</year><publisher-name>ACM</publisher-name><publisher-loc>New York</publisher-loc></element-citation></ref><ref id="bb0175"><label>35</label><element-citation publication-type="other" id="rf0255"><article-title>Amazon instance types</article-title><ext-link ext-link-type="uri" xlink:href="http://aws.amazon.com/ec2/instance-types/" id="ir0295">http://aws.amazon.com/ec2/instance-types/</ext-link><year>June 30 2014</year></element-citation></ref><ref id="bb0180"><label>36</label><element-citation publication-type="journal" id="rf0055"><person-group person-group-type="author"><name><surname>Marx</surname><given-names>V.</given-names></name></person-group><article-title>Genomics in the clouds</article-title><source>Nat Methods</source><volume>10</volume><year>2013</year><fpage>941</fpage><lpage>945</lpage><pub-id pub-id-type="pmid">24076987</pub-id></element-citation></ref><ref id="bb0185"><label>37</label><element-citation publication-type="journal" id="rf0060"><person-group person-group-type="author"><name><surname>Li</surname><given-names>H.</given-names></name><name><surname>Durbin</surname><given-names>R.</given-names></name></person-group><article-title>Fast and accurate short read alignment with Burrows&#x02013;Wheeler transform</article-title><source>Bioinformatics</source><volume>25</volume><year>2009</year><fpage>1754</fpage><lpage>1760</lpage><pub-id pub-id-type="pmid">19451168</pub-id></element-citation></ref><ref id="bb0190"><label>38</label><mixed-citation publication-type="other" id="or0130">Amazon spot instances <ext-link ext-link-type="uri" xlink:href="http://www.aws.amazon.com/ec2/purchasing-options/spot-instances/" id="ir2000">http://aws.amazon.com/ec2/purchasing-options/spot-instances/</ext-link></mixed-citation></ref><ref id="bb0195"><label>39</label><mixed-citation publication-type="other" id="or0135">Autoscaling.</mixed-citation></ref><ref id="bb0200"><label>40</label><element-citation publication-type="book" id="rf0260"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>B.</given-names></name><name><surname>Sotomayor</surname><given-names>B.</given-names></name><name><surname>Madduri</surname><given-names>R.</given-names></name><name><surname>Chard</surname><given-names>K.</given-names></name><name><surname>Foster</surname><given-names>I.</given-names></name></person-group><chapter-title>Deploying bioinformatics workflows on clouds with Galaxy and Globus Provision</chapter-title><source>High Performance Computing, Networking, Storage and Analysis (SCC), 2012 SC Companion</source><year>2012</year><fpage>1087</fpage><lpage>1095</lpage></element-citation></ref><ref id="bb0205"><label>41</label><element-citation publication-type="book" id="rf0065"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>Bryce</given-names></name><name><surname>Bresnahan</surname><given-names>John</given-names></name><name><surname>Childers</surname><given-names>Lisa</given-names></name><name><surname>Foster</surname><given-names>Ian</given-names></name><name><surname>Kandaswamy</surname><given-names>Gopi</given-names></name><name><surname>Kettimuthu</surname><given-names>Raj</given-names></name></person-group><chapter-title>Software as a service for data scientists</chapter-title><year>2012</year><publisher-name>Communications of the ACM: ACM</publisher-name></element-citation></ref><ref id="bb0210"><label>42</label><element-citation publication-type="book" id="rf0265"><person-group person-group-type="author"><name><surname>Ananthakrishnan RB</surname><given-names>J.</given-names></name><name><surname>Chard</surname><given-names>K.</given-names></name><name><surname>Foster</surname><given-names>I.</given-names></name><name><surname>Howe</surname><given-names>T.</given-names></name><name><surname>Lidman</surname><given-names>M.</given-names></name><name><surname>Tuecke</surname><given-names>S.</given-names></name></person-group><chapter-title>Globus Nexus: an identity, profile, and group management platform for science gateways and other collaborative science applications</chapter-title><year>Sep.23&#x02013;27 2013</year><publisher-name>IEEE</publisher-name></element-citation></ref><ref id="bb0215"><label>43</label><element-citation publication-type="book" id="rf0270"><person-group person-group-type="author"><name><surname>Allcock</surname><given-names>W.</given-names></name><name><surname>Bresnahan</surname><given-names>J.</given-names></name><name><surname>Kettimuthu</surname><given-names>R.</given-names></name><name><surname>Link</surname><given-names>M.</given-names></name></person-group><chapter-title>The Globus striped GridFTP framework and server</chapter-title><year>2005</year><comment>[54-54]</comment></element-citation></ref><ref id="bb0220"><label>44</label><element-citation publication-type="book" id="rf0275"><person-group person-group-type="author"><name><surname>Allcock</surname><given-names>W.</given-names></name></person-group><chapter-title>GridFTP: Protocol Extensions to FTP for the Grid</chapter-title><source>Global Grid Forum GFD-R-P.020</source><year>2003</year></element-citation></ref><ref id="bb0225"><label>45</label><element-citation publication-type="book" id="rf0280"><person-group person-group-type="author"><name><surname>Brightwell</surname><given-names>P.</given-names></name></person-group><chapter-title>High performance file transfer over IP networks</chapter-title><source>EBU Tech Rev</source><year>2010</year><comment>[(<ext-link ext-link-type="uri" xlink:href="http://www.tech.ebu.ch/techreview" id="ir2005">http://tech.ebu.ch/techreview</ext-link>): BBC <ext-link ext-link-type="uri" xlink:href="http://www.downloads.bbc.co.uk/rd/pubs/whp/whp-pdf-files/WHP183.pdf" id="ir1005">http://downloads.bbc.co.uk/rd/pubs/whp/whp-pdf-files/WHP183.pdf</ext-link>]</comment></element-citation></ref><ref id="bb0230"><label>46</label><element-citation publication-type="book" id="rf0070"><person-group person-group-type="author"><name><surname>Mattmann</surname><given-names>C.A.</given-names></name><name><surname>Kelly</surname><given-names>S.</given-names></name><name><surname>Crichton</surname><given-names>D.J.</given-names></name><name><surname>Hughes</surname><given-names>J.S.</given-names></name><name><surname>Hardman</surname><given-names>S.</given-names></name><name><surname>Ramirez</surname><given-names>P.</given-names></name></person-group><chapter-title>A classification andevaluation of data movement technologies for the delivery of highly voluminous scientific data products</chapter-title><source>NASA/IEE Conference on Mass Storage Systems and Technologies (MST 2006)</source><year>2006</year><publisher-name>Jet Propulsion Laboratory, National Aeronautics and Space Administration</publisher-name><publisher-loc>Pasadena, CA</publisher-loc></element-citation></ref><ref id="bb0235"><label>47</label><element-citation publication-type="book" id="rf0075"><person-group person-group-type="author"><name><surname>Esposito</surname><given-names>R.</given-names></name><name><surname>PM</surname></name><name><surname>Tortone</surname><given-names>G.</given-names></name><name><surname>Taurino</surname><given-names>F.M.</given-names></name></person-group><chapter-title>Standard FTP and GridFTP protocols for international data transfer in Pamela Satellite Space Experiment; Computing in High Energy and Nuclear Physics 2003 Conference Proceedings</chapter-title><year>2003 24-28 March</year><publisher-name>La Jolla</publisher-name><publisher-loc>San Diego, California</publisher-loc></element-citation></ref><ref id="bb0240"><label>48</label><element-citation publication-type="other" id="rf0285"><article-title>The Extreme Science and Engineering Discovery Environment (XSEDE)</article-title><ext-link ext-link-type="uri" xlink:href="https://www.xsede.org/overview" id="ir0305">https://www.xsede.org/overview</ext-link><year>June 30 2014</year></element-citation></ref><ref id="bb0245"><label>49</label><element-citation publication-type="other" id="rf0290"><article-title>KBase</article-title><ext-link ext-link-type="uri" xlink:href="http://kbase.us/about/about/" id="ir0310">http://kbase.us/about/about/</ext-link><year>June 30 2014</year></element-citation></ref><ref id="bb0250"><label>50</label><element-citation publication-type="other" id="rf0295"><article-title>Users of Globus for data movement</article-title><ext-link ext-link-type="uri" xlink:href="https://www.globus.org/case-studies" id="ir0315">https://www.globus.org/case-studies</ext-link><year>Oct. 10 2014</year></element-citation></ref><ref id="bb0255"><label>51</label><element-citation publication-type="other" id="rf0300"><article-title>The 1000 Genomes project now offers their FTP site as data transfer point through the Globus Transfer service</article-title><ext-link ext-link-type="uri" xlink:href="http://www.1000genomes.org/announcements/1000-genomes-ftp-site-now-available-through-globus-online-2014-06-17" id="ir0320">http://www.1000genomes.org/announcements/1000-genomes-ftp-site-now-available-through-globus-online-2014-06-17</ext-link><year>Oct. 17 2014</year></element-citation></ref><ref id="bb0260"><label>52</label><element-citation publication-type="other" id="rf0305"><article-title>FAQ: Can I access 1000 genomes data with Globus Online?</article-title><ext-link ext-link-type="uri" xlink:href="http://www.1000genomes.org/faq/can-i-access-1000-genomes-data-globus-online" id="ir0325">http://www.1000genomes.org/faq/can-i-access-1000-genomes-data-globus-online</ext-link><year>Oct. 17 2014</year></element-citation></ref><ref id="bb0265"><label>53</label><element-citation publication-type="book" id="rf1000"><chapter-title>Read data through Globus GridFTP</chapter-title><year>2014</year><comment><ext-link ext-link-type="uri" xlink:href="http://www.ebi.ac.uk/about/news/service-news/read-data-through-globus-gridftp" id="ir2010">http://www.ebi.ac.uk/about/news/service-news/read-data-through-globus-gridftp</ext-link></comment></element-citation></ref><ref id="bb0270"><label>54</label><element-citation publication-type="book" id="rf0080"><person-group person-group-type="author"><name><surname>Dubey</surname><given-names>A.</given-names></name><name><surname>Wagle</surname><given-names>D.</given-names></name></person-group><chapter-title>Delivering software as a service</chapter-title><year>1-12 May 2007</year><publisher-name>The McKinsey Quarterly</publisher-name><publisher-loc>Web Exclusive</publisher-loc></element-citation></ref><ref id="bb0275"><label>55</label><element-citation publication-type="journal" id="rf0085"><person-group person-group-type="author"><name><surname>Trapnell</surname><given-names>C.</given-names></name><name><surname>Pachter</surname><given-names>L.</given-names></name><name><surname>Salzberg</surname><given-names>S.L.</given-names></name></person-group><article-title>TopHat: discovering splice junctions with RNA-Seq</article-title><source>Bioinformatics</source><volume>25</volume><year>2009</year><fpage>1105</fpage><lpage>1111</lpage><pub-id pub-id-type="pmid">19289445</pub-id></element-citation></ref><ref id="bb0280"><label>56</label><element-citation publication-type="journal" id="rf0090"><person-group person-group-type="author"><name><surname>Trapnell</surname><given-names>C.</given-names></name><name><surname>Williams</surname><given-names>B.A.</given-names></name><name><surname>Pertea</surname><given-names>G.</given-names></name><name><surname>Mortazavi</surname><given-names>A.</given-names></name><name><surname>Kwan</surname><given-names>G.</given-names></name><name><surname>van Baren</surname><given-names>M.J.</given-names></name></person-group><article-title>Transcript assembly and quantification by RNA-Seq reveals unannotated transcripts and isoform switching during cell differentiation</article-title><source>Nat Biotechnol</source><volume>28</volume><year>2010</year><fpage>511</fpage><lpage>515</lpage><pub-id pub-id-type="pmid">20436464</pub-id></element-citation></ref><ref id="bb0285"><label>57</label><element-citation publication-type="journal" id="rf0095"><person-group person-group-type="author"><name><surname>Li</surname><given-names>B.</given-names></name><name><surname>Dewey</surname><given-names>C.N.</given-names></name></person-group><article-title>RSEM: accurate transcript quantification from RNA-Seq data with or without a reference genome</article-title><source>BMC Bioinforma</source><volume>12</volume><year>2011</year><fpage>323</fpage></element-citation></ref><ref id="bb0290"><label>58</label><element-citation publication-type="journal" id="rf0100"><person-group person-group-type="author"><name><surname>McKenna</surname><given-names>A.</given-names></name><name><surname>Hanna</surname><given-names>M.</given-names></name><name><surname>Banks</surname><given-names>E.</given-names></name><name><surname>Sivachenko</surname><given-names>A.</given-names></name><name><surname>Cibulskis</surname><given-names>K.</given-names></name><name><surname>Kernytsky</surname><given-names>A.</given-names></name></person-group><article-title>The Genome Analysis Toolkit: a MapReduce framework for analyzing next-generationDNA sequencing data</article-title><source>Genome Res</source><volume>20</volume><year>2010</year><fpage>1297</fpage><lpage>1303</lpage><pub-id pub-id-type="pmid">20644199</pub-id></element-citation></ref><ref id="bb0295"><label>59</label><element-citation publication-type="journal" id="rf0105"><person-group person-group-type="author"><name><surname>Li</surname><given-names>H.</given-names></name><name><surname>Handsaker</surname><given-names>B.</given-names></name><name><surname>Wysoker</surname><given-names>A.</given-names></name><name><surname>Fennell</surname><given-names>T.</given-names></name><name><surname>Ruan</surname><given-names>J.</given-names></name><name><surname>Homer</surname><given-names>N.</given-names></name></person-group><article-title>The Sequence Alignment/Map format and SAMtools</article-title><source>Bioinformatics</source><volume>25</volume><year>2009</year><fpage>2078</fpage><lpage>2079</lpage><pub-id pub-id-type="pmid">19505943</pub-id></element-citation></ref><ref id="bb0300"><label>60</label><element-citation publication-type="journal" id="rf0110"><person-group person-group-type="author"><name><surname>Pabinger</surname><given-names>S.</given-names></name><name><surname>Dander</surname><given-names>A.</given-names></name><name><surname>Fischer</surname><given-names>M.</given-names></name><name><surname>Snajder</surname><given-names>R.</given-names></name><name><surname>Sperk</surname><given-names>M.</given-names></name><name><surname>Efremova</surname><given-names>M.</given-names></name></person-group><article-title>A survey of tools for variant analysis of next-generation genome sequencing data</article-title><source>Brief Bioinform</source><volume>15</volume><year>2014</year><fpage>256</fpage><lpage>278</lpage><pub-id pub-id-type="pmid">23341494</pub-id></element-citation></ref><ref id="bb0305"><label>61</label><element-citation publication-type="journal" id="rf0115"><person-group person-group-type="author"><name><surname>Del Fabbro</surname><given-names>C.</given-names></name><name><surname>Scalabrin</surname><given-names>S.</given-names></name><name><surname>Morgante</surname><given-names>M.</given-names></name><name><surname>Giorgi</surname><given-names>F.M.</given-names></name></person-group><article-title>An extensive evaluation of read trimming effects on Illumina NGS data analysis</article-title><source>PLoS One</source><volume>8</volume><year>2013</year><fpage>e85024</fpage><pub-id pub-id-type="pmid">24376861</pub-id></element-citation></ref><ref id="bb0310"><label>62</label><element-citation publication-type="other" id="rf0310"><article-title>Sickle &#x02014; Windowed Adaptive Trimming for fastq files using quality</article-title><ext-link ext-link-type="uri" xlink:href="https://github.com/najoshi/sickle" id="ir0330">https://github.com/najoshi/sickle</ext-link><year>June 30 2014</year></element-citation></ref><ref id="bb0315"><label>63</label><element-citation publication-type="journal" id="rf0120"><person-group person-group-type="author"><name><surname>Langmead</surname><given-names>B.</given-names></name><name><surname>Salzberg</surname><given-names>S.L.</given-names></name></person-group><article-title>Fast gapped-read alignment with Bowtie 2</article-title><source>Nat Methods</source><volume>9</volume><year>2012</year><fpage>357</fpage><lpage>359</lpage><pub-id pub-id-type="pmid">22388286</pub-id></element-citation></ref><ref id="bb0320"><label>64</label><element-citation publication-type="other" id="rf0315"><article-title>Picard</article-title><ext-link ext-link-type="uri" xlink:href="http://picard.sourceforge.net" id="ir0335">http://picard.sourceforge.net</ext-link></element-citation></ref><ref id="bb0325"><label>65</label><element-citation publication-type="journal" id="rf0125"><person-group person-group-type="author"><name><surname>Danecek</surname><given-names>P.</given-names></name><name><surname>Auton</surname><given-names>A.</given-names></name><name><surname>Abecasis</surname><given-names>G.</given-names></name><name><surname>Albers</surname><given-names>C.A.</given-names></name><name><surname>Banks</surname><given-names>E.</given-names></name><name><surname>DePristo</surname><given-names>M.A.</given-names></name></person-group><article-title>The variant call format and VCFtools</article-title><source>Bioinformatics</source><volume>27</volume><year>2011</year><fpage>2156</fpage><lpage>2158</lpage><pub-id pub-id-type="pmid">21653522</pub-id></element-citation></ref><ref id="bb0330"><label>66</label><element-citation publication-type="other" id="rf1320"><article-title>Lung Cancer Sequencing Project Exome sequencing of lung adenocarcinomas and their normal counterparts</article-title><comment>ERP001575</comment><ext-link ext-link-type="uri" xlink:href="http://www.ebi.ac.uk/ena/data/view/ERP001575" id="ir0340">http://www.ebi.ac.uk/ena/data/view/ERP001575</ext-link><year>July 1 2014</year></element-citation></ref><ref id="bb0335"><label>67</label><element-citation publication-type="other" id="rf0320"><article-title>Amazon EBS</article-title><ext-link ext-link-type="uri" xlink:href="http://aws.amazon.com/ebs/" id="ir2340">http://aws.amazon.com/ebs/</ext-link><year>July 1 2014</year></element-citation></ref><ref id="bb0340"><label>68</label><element-citation publication-type="other" id="rf0325"><article-title>Cancer Genomics Hub</article-title><ext-link ext-link-type="uri" xlink:href="https://cghub.ucsc.edu/" id="ir0345">https://cghub.ucsc.edu/</ext-link><year>June 30 2014</year></element-citation></ref><ref id="bb0345"><label>69</label><element-citation publication-type="journal" id="rf0330"><person-group person-group-type="author"><name><surname>Trubetskoy</surname><given-names>V.</given-names></name><name><surname>Rodriguez</surname><given-names>A.</given-names></name><name><surname>Dave</surname><given-names>U.</given-names></name><name><surname>Campbell</surname><given-names>N.</given-names></name><name><surname>Crawford</surname><given-names>E.L.</given-names></name><name><surname>Cook</surname><given-names>E.H.</given-names></name></person-group><article-title>Consensus Genotyper for Exome Sequencing (CGES): improving the quality of exome variant genotypes</article-title><source>Bioinformatics</source><year>2014</year></element-citation></ref><ref id="bb0350"><label>70</label><element-citation publication-type="book" id="rf0335"><person-group person-group-type="author"><name><surname>Zheng TW</surname><given-names>Y.</given-names></name><name><surname>Yoshimatsu</surname><given-names>F.</given-names></name><name><surname>Lee</surname><given-names>M.</given-names></name><name><surname>Gulsuner</surname><given-names>S.</given-names></name><name><surname>Casadei</surname><given-names>S.</given-names></name><name><surname>Rodriguez</surname><given-names>A.</given-names></name></person-group><chapter-title>A profileof inherited predisposition to breast cancer among Nigerian women</chapter-title><source>64thAnnual Meeting of the American Society of Human Genetics</source><year>2014</year><publisher-name>SanDiego Convention Center (SDCC) in San Diego</publisher-name><publisher-loc>California</publisher-loc></element-citation></ref><ref id="bb0355"><label>71</label><element-citation publication-type="other" id="rf0340"><article-title>Pediatric brain research laboratory uses Globus Genomics to overcome IT hurdles</article-title><ext-link ext-link-type="uri" xlink:href="https://www.globus.org/genomics/resources/case-study-dobyns-pediatric-brain-research-lab.pdf" id="ir0350">https://www.globus.org/genomics/resources/case-study-dobyns-pediatric-brain-research-lab.pdf</ext-link><year>Oct. 10 2014</year></element-citation></ref><ref id="bb0360"><label>72</label><element-citation publication-type="book" id="rf0130"><person-group person-group-type="author"><name><surname>Rama Raghavan</surname><given-names>D.V.</given-names></name><name><surname>Fridley</surname><given-names>Brooke L.</given-names></name></person-group><chapter-title>Globus Genomics: A medical center's bioinformatics core perspective</chapter-title><year>2014</year><publisher-name>Globus World</publisher-name><publisher-loc>Chicago</publisher-loc></element-citation></ref><ref id="bb0365"><label>73</label><element-citation publication-type="other" id="rf0345"><article-title>Globus Genomics NGS Analysis</article-title><ext-link ext-link-type="uri" xlink:href="http://www.bumc.bu.edu/gsi/next-generation-sequencing/globus-genomics/" id="ir0355">http://www.bumc.bu.edu/gsi/next-generation-sequencing/globus-genomics/</ext-link><year>Oct. 10 2014</year></element-citation></ref><ref id="bb0370"><label>74</label><element-citation publication-type="book" id="rf0350"><person-group person-group-type="author"><name><surname>Litzkow</surname><given-names>M.J.</given-names></name><name><surname>Livny</surname><given-names>M.</given-names></name><name><surname>Mutka</surname><given-names>M.W.</given-names></name></person-group><chapter-title>Condor &#x02014; a hunter of idle workstations</chapter-title><source>8th International Conference on Distributed Computing Systems</source><year>1988</year><fpage>104</fpage><lpage>111</lpage></element-citation></ref></ref-list><ack id="ac0005"><title>Acknowledgments</title><p>We thank Globus Genomics users for their invaluable feedback and contributions. We thank Dr. Laura Sheahan for editing the manuscript.</p></ack></back><floats-group><fig id="f0005"><label>Fig. 1</label><caption><p>Architecture of the Globus Genomics system. The orange colored components indicate the three distinct components of the system (at a higher level), and the pink colored components are additional features added by the Globus Genomics team.</p></caption><graphic xlink:href="gr1"/></fig><fig id="f0010"><label>Fig. 2</label><caption><p>How to run a ready-made NGS workflow in the Globus Genomics system.</p></caption><graphic xlink:href="gr2"/></fig><fig id="f0015"><label>Fig. 3</label><caption><p>a. Schematic diagram of the whole Genome and whole exome analysis workflow.</p><p>b. Whole genome and exome analysis workflow inside the Globus Genomics system.</p></caption><graphic xlink:href="gr3"/></fig><fig id="f0020"><label>Fig. 4</label><caption><p>a. Schematic diagram of the whole transcriptome (RNA-seq) analysis workflow.</p><p>b. Whole transcriptome (RNA-seq) analysis workflow inside the Globus Genomics system.</p></caption><graphic xlink:href="gr4"/></fig><fig id="f0025"><label>Fig. 5</label><caption><p>Summary for analysis of 78 lung cancer samples through the exome-seq workflow. Execution time was not optimal due to the high nature of I/O in the workflow.</p><p>"Spot Price" as mentioned in the figure key refers to the price of the AWS spot instance <xref rid="bb0190" ref-type="bibr">[38]</xref>.</p></caption><graphic xlink:href="gr5"/></fig><fig id="f0030"><label>Fig. 6</label><caption><p>Summary of the 78 lung cancer samples in an I/O optimized server.</p><p>&#x0201c;Spot price&#x0201d; refers to the price of the AWS spot instance <xref rid="bb0190" ref-type="bibr">[38]</xref>.</p></caption><graphic xlink:href="gr6"/></fig><fig id="f0035"><label>Fig. 7</label><caption><p>Summary for RNA-Seq Analysis of 21 TCGA samples of varying input sizes.</p><p>&#x0201c;Spot price&#x0201d; refers to the price of the AWS spot instance <xref rid="bb0190" ref-type="bibr">[38]</xref>.</p></caption><graphic xlink:href="gr7"/></fig><table-wrap id="t0005" position="float"><label>Table&#x000a0;1</label><caption><p>Sample workflow run costs including compute, temporal storage and outbound I/O<xref rid="tf0005" ref-type="table-fn">a</xref>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Workflow</th><th align="left">Input data size</th><th align="left">Storage size reqs (GBs)</th><th align="left">Amazon storage costs</th><th align="left">Compute requirement (node hours)</th><th align="left">Amazon compute costs</th><th align="left">Data download (GBs)</th><th align="left">Amazon outbound I/O costs</th><th align="left">Total amazon costs</th></tr></thead><tbody><tr><td align="left">DNA copy number</td><td align="left">.070&#x000a0;GB</td><td align="char">0.03</td><td align="char">&#x0003c;$0.01</td><td align="char">0.15</td><td align="char">$0.05</td><td align="char">0.003</td><td align="char">&#x0003c;$0.01</td><td align="char">$0.05</td></tr><tr><td align="left">microRNA Seq</td><td align="left">0.3&#x000a0;GB</td><td align="char">1</td><td align="char">&#x0003c;$0.01</td><td align="char">0.5</td><td align="char">$0.17</td><td align="char">0.1</td><td align="char">$0.01</td><td align="char">$0.18</td></tr><tr><td align="left">RNA Seq</td><td align="left">10&#x000a0;GB (~&#x000a0;5&#x000a0;Gbp)</td><td align="char">70</td><td align="char">$0.12</td><td align="char">20</td><td align="char">$6.80</td><td align="char">7</td><td align="char">$0.70</td><td align="char">$7.62</td></tr><tr><td align="left">WES</td><td align="left">6&#x000a0;GB (~&#x000a0;5&#x000a0;Gbp)</td><td align="char">50</td><td align="char">$0.08</td><td align="char">6</td><td align="char">$2.04</td><td align="char">5</td><td align="char">$0.50</td><td align="char">$2.62</td></tr><tr><td align="left">WGS</td><td align="left">72&#x000a0;GB (~&#x000a0;35&#x000a0;Gbp)</td><td align="char">320</td><td align="char">$0.53</td><td align="char">30</td><td align="char">$10.20</td><td align="char">32</td><td align="char">$3.20</td><td align="char">$13.93</td></tr></tbody></table><table-wrap-foot><fn id="tf0005"><label>a</label><p id="np0010">The analysis presented in <xref rid="t0005" ref-type="table">Table&#x000a0;1</xref> was carried out under the following assumptions: (a)Input data are compressed in GZ format, paired-end Illumina reads (b)RNA-seq analysis includes variant analysis as well: Sickle QC, RSEM (singleton and paired), sort, rmdup, fixmate, picard reorder, picard add or replace groups, GATK Unified Genotyper, GATK recalibration, and GATK variant filtering (c)WES analysis includes: BWA, sort, rmdup, fixmate, picard reorder, picard add or replace groups, GATK Unified Genotyper, GATK recalibration, and GATK variant filtering (d)WGS analysis includes: Bowtie2, sort, rmdup, fixmate, picard reorder, picard add or replace groups, and GATK Unified Genotyper (e)Reference genome used for all analyses is hg19.</p></fn></table-wrap-foot></table-wrap></floats-group></article>